{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sample \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39msample.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      2\u001b[0m column_names \u001b[39m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstart_date\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstart_time\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreverseDelta\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTMac\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhostMac\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTIP\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTIP_int\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m      4\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhostIP\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhostIP_int\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mipProto\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTPort\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhostPort\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPacketCount\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBytesCount\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreversePacketCount\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUDP_others\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myear_month\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m ]\n\u001b[1;32m     12\u001b[0m sample\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m column_names\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample.csv'"
     ]
    }
   ],
   "source": [
    "sample = pd.read_csv(\"sample.csv\")\n",
    "column_names = [\n",
    "    \"dataset\", \"start_date\", \"start_time\", \"duration\", \"reverseDelta\", \"IoTMac\", \"hostMac\", \"IoTIP\", \"IoTIP_int\",\n",
    "    \"hostIP\", \"hostIP_int\", \"ipProto\", \"IoTPort\", \"hostPort\", \"PacketCount\", \"BytesCount\", \"reversePacketCount\",\n",
    "    \"reverseBytesCount\", \"SmallPktCount\", \"LargePktCount\", \"NonEmptyPktCount\", \"DataByteCount\", \"AvgIAT\",\n",
    "    \"FirstNonEmptyPktSize\", \"MaxPktSize\", \"StdevPayloadSize\", \"StdevIAT\", \"AvgPacketSize\", \"reverseSmallPktCount\",\n",
    "    \"reverseLargePktCount\", \"reverseNonEmptyPktCount\", \"reverseDataByteCount\", \"reverseAvgIAT\",\n",
    "    \"reverseFirstNonEmptyPktSize\", \"reverseMaxPktSize\", \"reverseStdevPayloadSize\", \"reverseStdevIAT\",\n",
    "    \"reverseAvgPacketSize\", \"reverseFlowExists\", \"remote\", \"broadcast\", \"HTTP\", \"HTTPS\", \"DNS\", \"NTP\", \"TCP_others\",\n",
    "    \"UDP_others\", \"year_month\"\n",
    "]\n",
    "sample.columns = column_names\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9999, 48)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['planex_camera_one_shot!_2019_09.csv', '2019-09-25', '06:50:15.934',\n",
       "       '0', '0.1', '00:1b:c7:fa:c3:e6:', '01:00:5e:7f:ff:fa:', '192.168.1.236',\n",
       "       '3232236012', '239.255.255.250', '4026531834', '17', '33033', '1900',\n",
       "       '1', '294', '0.2', '0.3', '0.4', '1.1', '1.2', '266', '0.5', '266.1',\n",
       "       '266.2', '0.6', '0.7', '266.3', '0.8', '0.9', '0.10', '0.11', '0.12',\n",
       "       '0.13', '0.14', '0.15', '0.16', '0.17', '0.18', '1.3', '0.19', '0.20',\n",
       "       '0.21', '0.22', '0.23', '0.24', '1.4', '2019_09'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\n",
    "    \"dataset\", \"start_date\", \"start_time\", \"duration\", \"reverseDelta\", \"IoTMac\", \"hostMac\", \"IoTIP\", \"IoTIP_int\",\n",
    "    \"hostIP\", \"hostIP_int\", \"ipProto\", \"IoTPort\", \"hostPort\", \"PacketCount\", \"BytesCount\", \"reversePacketCount\",\n",
    "    \"reverseBytesCount\", \"SmallPktCount\", \"LargePktCount\", \"NonEmptyPktCount\", \"DataByteCount\", \"AvgIAT\",\n",
    "    \"FirstNonEmptyPktSize\", \"MaxPktSize\", \"StdevPayloadSize\", \"StdevIAT\", \"AvgPacketSize\", \"reverseSmallPktCount\",\n",
    "    \"reverseLargePktCount\", \"reverseNonEmptyPktCount\", \"reverseDataByteCount\", \"reverseAvgIAT\",\n",
    "    \"reverseFirstNonEmptyPktSize\", \"reverseMaxPktSize\", \"reverseStdevPayloadSize\", \"reverseStdevIAT\",\n",
    "    \"reverseAvgPacketSize\", \"reverseFlowExists\", \"remote\", \"broadcast\", \"HTTP\", \"HTTPS\", \"DNS\", \"NTP\", \"TCP_others\",\n",
    "    \"UDP_others\", \"year_month\"\n",
    "]\n",
    "sample.columns = column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>IoTMac</th>\n",
       "      <th>hostMac</th>\n",
       "      <th>IoTIP</th>\n",
       "      <th>IoTIP_int</th>\n",
       "      <th>hostIP</th>\n",
       "      <th>hostIP_int</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>hostPort</th>\n",
       "      <th>PacketCount</th>\n",
       "      <th>BytesCount</th>\n",
       "      <th>reversePacketCount</th>\n",
       "      <th>reverseBytesCount</th>\n",
       "      <th>SmallPktCount</th>\n",
       "      <th>LargePktCount</th>\n",
       "      <th>NonEmptyPktCount</th>\n",
       "      <th>DataByteCount</th>\n",
       "      <th>AvgIAT</th>\n",
       "      <th>FirstNonEmptyPktSize</th>\n",
       "      <th>MaxPktSize</th>\n",
       "      <th>StdevPayloadSize</th>\n",
       "      <th>StdevIAT</th>\n",
       "      <th>AvgPacketSize</th>\n",
       "      <th>reverseSmallPktCount</th>\n",
       "      <th>reverseLargePktCount</th>\n",
       "      <th>reverseNonEmptyPktCount</th>\n",
       "      <th>reverseDataByteCount</th>\n",
       "      <th>reverseAvgIAT</th>\n",
       "      <th>reverseFirstNonEmptyPktSize</th>\n",
       "      <th>reverseMaxPktSize</th>\n",
       "      <th>reverseStdevPayloadSize</th>\n",
       "      <th>reverseStdevIAT</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google_home_gen1_2019_08.csv</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>21:01:27.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>48:d6:d5:92:96:a2:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.184</td>\n",
       "      <td>3232235960</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>33789</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>planex_camera_one_shot!_2019_09.csv</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>06:31:15.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>3232236012</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>4026531834</td>\n",
       "      <td>17</td>\n",
       "      <td>46713</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sony_bravia_2019_08.csv</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>02:58:57.694</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.012</td>\n",
       "      <td>04:5d:4b:a4:d0:2e:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.124</td>\n",
       "      <td>3232235900</td>\n",
       "      <td>74.125.102.41</td>\n",
       "      <td>1249732137</td>\n",
       "      <td>6</td>\n",
       "      <td>53460</td>\n",
       "      <td>443</td>\n",
       "      <td>18</td>\n",
       "      <td>1986</td>\n",
       "      <td>18</td>\n",
       "      <td>18612</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1030</td>\n",
       "      <td>21</td>\n",
       "      <td>188</td>\n",
       "      <td>685</td>\n",
       "      <td>253</td>\n",
       "      <td>54</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17668</td>\n",
       "      <td>24</td>\n",
       "      <td>1396</td>\n",
       "      <td>2792</td>\n",
       "      <td>803</td>\n",
       "      <td>55</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>planex_camera_one_shot!_2019_07.csv</td>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>03:03:10.832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>3232236012</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>4026531834</td>\n",
       "      <td>17</td>\n",
       "      <td>48008</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jvc_kenwood_cu-hb1_2019_07.csv</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>16:02:39.688</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>00:a2:b2:b9:09:87:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.186</td>\n",
       "      <td>3232235962</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>39289</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dataset  start_date    start_time  duration  \\\n",
       "0         google_home_gen1_2019_08.csv  2019-08-12   21:01:27.25     0.000   \n",
       "1  planex_camera_one_shot!_2019_09.csv  2019-09-19  06:31:15.204     0.000   \n",
       "2              sony_bravia_2019_08.csv  2019-08-16  02:58:57.694     0.434   \n",
       "3  planex_camera_one_shot!_2019_07.csv  2019-07-29  03:03:10.832     0.000   \n",
       "4       jvc_kenwood_cu-hb1_2019_07.csv  2019-07-10  16:02:39.688     0.001   \n",
       "\n",
       "   reverseDelta              IoTMac             hostMac          IoTIP  \\\n",
       "0         0.000  48:d6:d5:92:96:a2:  38:d5:47:0c:25:d4:  192.168.1.184   \n",
       "1         0.000  00:1b:c7:fa:c3:e6:  01:00:5e:7f:ff:fa:  192.168.1.236   \n",
       "2         0.012  04:5d:4b:a4:d0:2e:  38:d5:47:0c:25:d4:  192.168.1.124   \n",
       "3         0.000  00:1b:c7:fa:c3:e6:  01:00:5e:7f:ff:fa:  192.168.1.236   \n",
       "4         0.001  00:a2:b2:b9:09:87:  38:d5:47:0c:25:d4:  192.168.1.186   \n",
       "\n",
       "    IoTIP_int           hostIP  hostIP_int  ipProto  IoTPort  hostPort  \\\n",
       "0  3232235960      192.168.1.1  3232235777       17    33789        53   \n",
       "1  3232236012  239.255.255.250  4026531834       17    46713      1900   \n",
       "2  3232235900    74.125.102.41  1249732137        6    53460       443   \n",
       "3  3232236012  239.255.255.250  4026531834       17    48008      1900   \n",
       "4  3232235962      192.168.1.1  3232235777       17    39289        53   \n",
       "\n",
       "   PacketCount  BytesCount  reversePacketCount  reverseBytesCount  \\\n",
       "0            1          75                   0                  0   \n",
       "1            1         294                   0                  0   \n",
       "2           18        1986                  18              18612   \n",
       "3            1         294                   0                  0   \n",
       "4            1          71                   1                170   \n",
       "\n",
       "   SmallPktCount  LargePktCount  NonEmptyPktCount  DataByteCount  AvgIAT  \\\n",
       "0              1              0                 1             47       0   \n",
       "1              0              1                 1            266       0   \n",
       "2              1              1                 4           1030      21   \n",
       "3              0              1                 1            266       0   \n",
       "4              1              0                 1             43       0   \n",
       "\n",
       "   FirstNonEmptyPktSize  MaxPktSize  StdevPayloadSize  StdevIAT  \\\n",
       "0                    47          47                 0         0   \n",
       "1                   266         266                 0         0   \n",
       "2                   188         685               253        54   \n",
       "3                   266         266                 0         0   \n",
       "4                    43          43                 0         0   \n",
       "\n",
       "   AvgPacketSize  reverseSmallPktCount  reverseLargePktCount  \\\n",
       "0             47                     0                     0   \n",
       "1            266                     0                     0   \n",
       "2            257                     0                    13   \n",
       "3            266                     0                     0   \n",
       "4             43                     0                     0   \n",
       "\n",
       "   reverseNonEmptyPktCount  reverseDataByteCount  reverseAvgIAT  \\\n",
       "0                        0                     0              0   \n",
       "1                        0                     0              0   \n",
       "2                       13                 17668             24   \n",
       "3                        0                     0              0   \n",
       "4                        1                   142              0   \n",
       "\n",
       "   reverseFirstNonEmptyPktSize  reverseMaxPktSize  reverseStdevPayloadSize  \\\n",
       "0                            0                  0                        0   \n",
       "1                            0                  0                        0   \n",
       "2                         1396               2792                      803   \n",
       "3                            0                  0                        0   \n",
       "4                          142                142                        0   \n",
       "\n",
       "   reverseStdevIAT  reverseAvgPacketSize  reverseFlowExists  remote  \\\n",
       "0                0                     0                  0       0   \n",
       "1                0                     0                  0       1   \n",
       "2               55                  1359                  1       1   \n",
       "3                0                     0                  0       1   \n",
       "4                0                   142                  1       0   \n",
       "\n",
       "   broadcast  HTTP  HTTPS  DNS  NTP  TCP_others  UDP_others year_month  \n",
       "0          0     0      0    1    0           0           0    2019_08  \n",
       "1          0     0      0    0    0           0           1    2019_09  \n",
       "2          0     0      1    0    0           1           0    2019_08  \n",
       "3          0     0      0    0    0           0           1    2019_07  \n",
       "4          0     0      0    1    0           0           0    2019_07  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 48 columns):\n",
      " #   Column                       Non-Null Count  Dtype  \n",
      "---  ------                       --------------  -----  \n",
      " 0   dataset                      9999 non-null   object \n",
      " 1   start_date                   9999 non-null   object \n",
      " 2   start_time                   9999 non-null   object \n",
      " 3   duration                     9999 non-null   float64\n",
      " 4   reverseDelta                 9999 non-null   float64\n",
      " 5   IoTMac                       9999 non-null   object \n",
      " 6   hostMac                      9999 non-null   object \n",
      " 7   IoTIP                        9999 non-null   object \n",
      " 8   IoTIP_int                    9999 non-null   int64  \n",
      " 9   hostIP                       9999 non-null   object \n",
      " 10  hostIP_int                   9999 non-null   int64  \n",
      " 11  ipProto                      9999 non-null   int64  \n",
      " 12  IoTPort                      9999 non-null   int64  \n",
      " 13  hostPort                     9999 non-null   int64  \n",
      " 14  PacketCount                  9999 non-null   int64  \n",
      " 15  BytesCount                   9999 non-null   int64  \n",
      " 16  reversePacketCount           9999 non-null   int64  \n",
      " 17  reverseBytesCount            9999 non-null   int64  \n",
      " 18  SmallPktCount                9999 non-null   int64  \n",
      " 19  LargePktCount                9999 non-null   int64  \n",
      " 20  NonEmptyPktCount             9999 non-null   int64  \n",
      " 21  DataByteCount                9999 non-null   int64  \n",
      " 22  AvgIAT                       9999 non-null   int64  \n",
      " 23  FirstNonEmptyPktSize         9999 non-null   int64  \n",
      " 24  MaxPktSize                   9999 non-null   int64  \n",
      " 25  StdevPayloadSize             9999 non-null   int64  \n",
      " 26  StdevIAT                     9999 non-null   int64  \n",
      " 27  AvgPacketSize                9999 non-null   int64  \n",
      " 28  reverseSmallPktCount         9999 non-null   int64  \n",
      " 29  reverseLargePktCount         9999 non-null   int64  \n",
      " 30  reverseNonEmptyPktCount      9999 non-null   int64  \n",
      " 31  reverseDataByteCount         9999 non-null   int64  \n",
      " 32  reverseAvgIAT                9999 non-null   int64  \n",
      " 33  reverseFirstNonEmptyPktSize  9999 non-null   int64  \n",
      " 34  reverseMaxPktSize            9999 non-null   int64  \n",
      " 35  reverseStdevPayloadSize      9999 non-null   int64  \n",
      " 36  reverseStdevIAT              9999 non-null   int64  \n",
      " 37  reverseAvgPacketSize         9999 non-null   int64  \n",
      " 38  reverseFlowExists            9999 non-null   int64  \n",
      " 39  remote                       9999 non-null   int64  \n",
      " 40  broadcast                    9999 non-null   int64  \n",
      " 41  HTTP                         9999 non-null   int64  \n",
      " 42  HTTPS                        9999 non-null   int64  \n",
      " 43  DNS                          9999 non-null   int64  \n",
      " 44  NTP                          9999 non-null   int64  \n",
      " 45  TCP_others                   9999 non-null   int64  \n",
      " 46  UDP_others                   9999 non-null   int64  \n",
      " 47  year_month                   9999 non-null   object \n",
      "dtypes: float64(2), int64(38), object(8)\n",
      "memory usage: 3.7+ MB\n"
     ]
    }
   ],
   "source": [
    "sample.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>IoTIP_int</th>\n",
       "      <th>hostIP_int</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>hostPort</th>\n",
       "      <th>PacketCount</th>\n",
       "      <th>BytesCount</th>\n",
       "      <th>reversePacketCount</th>\n",
       "      <th>...</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9.999000e+03</td>\n",
       "      <td>9.999000e+03</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.00000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "      <td>9999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>33.074645</td>\n",
       "      <td>0.120314</td>\n",
       "      <td>3.232122e+09</td>\n",
       "      <td>2.366004e+09</td>\n",
       "      <td>14.398140</td>\n",
       "      <td>45221.791879</td>\n",
       "      <td>8936.497850</td>\n",
       "      <td>5.152415</td>\n",
       "      <td>763.707171</td>\n",
       "      <td>3.112311</td>\n",
       "      <td>...</td>\n",
       "      <td>213.603460</td>\n",
       "      <td>0.387839</td>\n",
       "      <td>0.465947</td>\n",
       "      <td>0.00060</td>\n",
       "      <td>0.022702</td>\n",
       "      <td>0.026703</td>\n",
       "      <td>0.604360</td>\n",
       "      <td>0.004500</td>\n",
       "      <td>0.201320</td>\n",
       "      <td>0.158516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>213.159435</td>\n",
       "      <td>9.303840</td>\n",
       "      <td>6.584691e+06</td>\n",
       "      <td>1.457970e+09</td>\n",
       "      <td>4.747748</td>\n",
       "      <td>11327.295153</td>\n",
       "      <td>18159.014138</td>\n",
       "      <td>38.097998</td>\n",
       "      <td>5059.712141</td>\n",
       "      <td>35.375522</td>\n",
       "      <td>...</td>\n",
       "      <td>425.053187</td>\n",
       "      <td>0.487282</td>\n",
       "      <td>0.498864</td>\n",
       "      <td>0.02449</td>\n",
       "      <td>0.148960</td>\n",
       "      <td>0.161221</td>\n",
       "      <td>0.489012</td>\n",
       "      <td>0.066938</td>\n",
       "      <td>0.401007</td>\n",
       "      <td>0.365242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.852044e+09</td>\n",
       "      <td>2.624320e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>1.347441e+08</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>38727.500000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>46261.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>53732.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>449.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>142.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1800.000000</td>\n",
       "      <td>924.189000</td>\n",
       "      <td>3.232236e+09</td>\n",
       "      <td>4.026532e+09</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>65223.000000</td>\n",
       "      <td>65209.000000</td>\n",
       "      <td>2917.000000</td>\n",
       "      <td>248429.000000</td>\n",
       "      <td>2962.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2198.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          duration  reverseDelta     IoTIP_int    hostIP_int      ipProto  \\\n",
       "count  9999.000000   9999.000000  9.999000e+03  9.999000e+03  9999.000000   \n",
       "mean     33.074645      0.120314  3.232122e+09  2.366004e+09    14.398140   \n",
       "std     213.159435      9.303840  6.584691e+06  1.457970e+09     4.747748   \n",
       "min       0.000000      0.000000  2.852044e+09  2.624320e+05     1.000000   \n",
       "25%       0.000000      0.000000  3.232236e+09  1.347441e+08    17.000000   \n",
       "50%       0.000000      0.000000  3.232236e+09  3.232236e+09    17.000000   \n",
       "75%       0.008000      0.001000  3.232236e+09  3.232236e+09    17.000000   \n",
       "max    1800.000000    924.189000  3.232236e+09  4.026532e+09    17.000000   \n",
       "\n",
       "            IoTPort      hostPort  PacketCount     BytesCount  \\\n",
       "count   9999.000000   9999.000000  9999.000000    9999.000000   \n",
       "mean   45221.791879   8936.497850     5.152415     763.707171   \n",
       "std    11327.295153  18159.014138    38.097998    5059.712141   \n",
       "min        3.000000      0.000000     1.000000      36.000000   \n",
       "25%    38727.500000     53.000000     1.000000      65.000000   \n",
       "50%    46261.000000     53.000000     1.000000     122.000000   \n",
       "75%    53732.000000   1900.000000     5.000000     449.000000   \n",
       "max    65223.000000  65209.000000  2917.000000  248429.000000   \n",
       "\n",
       "       reversePacketCount  ...  reverseAvgPacketSize  reverseFlowExists  \\\n",
       "count         9999.000000  ...           9999.000000        9999.000000   \n",
       "mean             3.112311  ...            213.603460           0.387839   \n",
       "std             35.375522  ...            425.053187           0.487282   \n",
       "min              0.000000  ...              0.000000           0.000000   \n",
       "25%              0.000000  ...              0.000000           0.000000   \n",
       "50%              0.000000  ...              0.000000           0.000000   \n",
       "75%              2.000000  ...            142.000000           1.000000   \n",
       "max           2962.000000  ...           2198.000000           1.000000   \n",
       "\n",
       "            remote   broadcast         HTTP        HTTPS          DNS  \\\n",
       "count  9999.000000  9999.00000  9999.000000  9999.000000  9999.000000   \n",
       "mean      0.465947     0.00060     0.022702     0.026703     0.604360   \n",
       "std       0.498864     0.02449     0.148960     0.161221     0.489012   \n",
       "min       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.00000     0.000000     0.000000     0.000000   \n",
       "50%       0.000000     0.00000     0.000000     0.000000     1.000000   \n",
       "75%       1.000000     0.00000     0.000000     0.000000     1.000000   \n",
       "max       1.000000     1.00000     1.000000     1.000000     1.000000   \n",
       "\n",
       "               NTP   TCP_others   UDP_others  \n",
       "count  9999.000000  9999.000000  9999.000000  \n",
       "mean      0.004500     0.201320     0.158516  \n",
       "std       0.066938     0.401007     0.365242  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000  \n",
       "50%       0.000000     0.000000     0.000000  \n",
       "75%       0.000000     0.000000     0.000000  \n",
       "max       1.000000     1.000000     1.000000  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropped = sample.drop[\"dataset\"]\n",
    "data = sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>IoTMac</th>\n",
       "      <th>hostMac</th>\n",
       "      <th>IoTIP</th>\n",
       "      <th>IoTIP_int</th>\n",
       "      <th>hostIP</th>\n",
       "      <th>hostIP_int</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>hostPort</th>\n",
       "      <th>PacketCount</th>\n",
       "      <th>BytesCount</th>\n",
       "      <th>reversePacketCount</th>\n",
       "      <th>reverseBytesCount</th>\n",
       "      <th>SmallPktCount</th>\n",
       "      <th>LargePktCount</th>\n",
       "      <th>NonEmptyPktCount</th>\n",
       "      <th>DataByteCount</th>\n",
       "      <th>AvgIAT</th>\n",
       "      <th>FirstNonEmptyPktSize</th>\n",
       "      <th>MaxPktSize</th>\n",
       "      <th>StdevPayloadSize</th>\n",
       "      <th>StdevIAT</th>\n",
       "      <th>AvgPacketSize</th>\n",
       "      <th>reverseSmallPktCount</th>\n",
       "      <th>reverseLargePktCount</th>\n",
       "      <th>reverseNonEmptyPktCount</th>\n",
       "      <th>reverseDataByteCount</th>\n",
       "      <th>reverseAvgIAT</th>\n",
       "      <th>reverseFirstNonEmptyPktSize</th>\n",
       "      <th>reverseMaxPktSize</th>\n",
       "      <th>reverseStdevPayloadSize</th>\n",
       "      <th>reverseStdevIAT</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "      <th>year_month</th>\n",
       "      <th>datetime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>21:01:27.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>48:d6:d5:92:96:a2:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.184</td>\n",
       "      <td>3232235960</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>33789</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_08</td>\n",
       "      <td>2019-08-12 21:01:27.250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>06:31:15.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>3232236012</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>4026531834</td>\n",
       "      <td>17</td>\n",
       "      <td>46713</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019_09</td>\n",
       "      <td>2019-09-19 06:31:15.204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>87</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>02:58:57.694</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.012</td>\n",
       "      <td>04:5d:4b:a4:d0:2e:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.124</td>\n",
       "      <td>3232235900</td>\n",
       "      <td>74.125.102.41</td>\n",
       "      <td>1249732137</td>\n",
       "      <td>6</td>\n",
       "      <td>53460</td>\n",
       "      <td>443</td>\n",
       "      <td>18</td>\n",
       "      <td>1986</td>\n",
       "      <td>18</td>\n",
       "      <td>18612</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1030</td>\n",
       "      <td>21</td>\n",
       "      <td>188</td>\n",
       "      <td>685</td>\n",
       "      <td>253</td>\n",
       "      <td>54</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17668</td>\n",
       "      <td>24</td>\n",
       "      <td>1396</td>\n",
       "      <td>2792</td>\n",
       "      <td>803</td>\n",
       "      <td>55</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_08</td>\n",
       "      <td>2019-08-16 02:58:57.694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>03:03:10.832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>3232236012</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>4026531834</td>\n",
       "      <td>17</td>\n",
       "      <td>48008</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019_07</td>\n",
       "      <td>2019-07-29 03:03:10.832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>16:02:39.688</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>00:a2:b2:b9:09:87:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.186</td>\n",
       "      <td>3232235962</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>39289</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_07</td>\n",
       "      <td>2019-07-10 16:02:39.688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  start_date    start_time  duration  reverseDelta  \\\n",
       "0       23  2019-08-12   21:01:27.25     0.000         0.000   \n",
       "1       67  2019-09-19  06:31:15.204     0.000         0.000   \n",
       "2       87  2019-08-16  02:58:57.694     0.434         0.012   \n",
       "3       65  2019-07-29  03:03:10.832     0.000         0.000   \n",
       "4       33  2019-07-10  16:02:39.688     0.001         0.001   \n",
       "\n",
       "               IoTMac             hostMac          IoTIP   IoTIP_int  \\\n",
       "0  48:d6:d5:92:96:a2:  38:d5:47:0c:25:d4:  192.168.1.184  3232235960   \n",
       "1  00:1b:c7:fa:c3:e6:  01:00:5e:7f:ff:fa:  192.168.1.236  3232236012   \n",
       "2  04:5d:4b:a4:d0:2e:  38:d5:47:0c:25:d4:  192.168.1.124  3232235900   \n",
       "3  00:1b:c7:fa:c3:e6:  01:00:5e:7f:ff:fa:  192.168.1.236  3232236012   \n",
       "4  00:a2:b2:b9:09:87:  38:d5:47:0c:25:d4:  192.168.1.186  3232235962   \n",
       "\n",
       "            hostIP  hostIP_int  ipProto  IoTPort  hostPort  PacketCount  \\\n",
       "0      192.168.1.1  3232235777       17    33789        53            1   \n",
       "1  239.255.255.250  4026531834       17    46713      1900            1   \n",
       "2    74.125.102.41  1249732137        6    53460       443           18   \n",
       "3  239.255.255.250  4026531834       17    48008      1900            1   \n",
       "4      192.168.1.1  3232235777       17    39289        53            1   \n",
       "\n",
       "   BytesCount  reversePacketCount  reverseBytesCount  SmallPktCount  \\\n",
       "0          75                   0                  0              1   \n",
       "1         294                   0                  0              0   \n",
       "2        1986                  18              18612              1   \n",
       "3         294                   0                  0              0   \n",
       "4          71                   1                170              1   \n",
       "\n",
       "   LargePktCount  NonEmptyPktCount  DataByteCount  AvgIAT  \\\n",
       "0              0                 1             47       0   \n",
       "1              1                 1            266       0   \n",
       "2              1                 4           1030      21   \n",
       "3              1                 1            266       0   \n",
       "4              0                 1             43       0   \n",
       "\n",
       "   FirstNonEmptyPktSize  MaxPktSize  StdevPayloadSize  StdevIAT  \\\n",
       "0                    47          47                 0         0   \n",
       "1                   266         266                 0         0   \n",
       "2                   188         685               253        54   \n",
       "3                   266         266                 0         0   \n",
       "4                    43          43                 0         0   \n",
       "\n",
       "   AvgPacketSize  reverseSmallPktCount  reverseLargePktCount  \\\n",
       "0             47                     0                     0   \n",
       "1            266                     0                     0   \n",
       "2            257                     0                    13   \n",
       "3            266                     0                     0   \n",
       "4             43                     0                     0   \n",
       "\n",
       "   reverseNonEmptyPktCount  reverseDataByteCount  reverseAvgIAT  \\\n",
       "0                        0                     0              0   \n",
       "1                        0                     0              0   \n",
       "2                       13                 17668             24   \n",
       "3                        0                     0              0   \n",
       "4                        1                   142              0   \n",
       "\n",
       "   reverseFirstNonEmptyPktSize  reverseMaxPktSize  reverseStdevPayloadSize  \\\n",
       "0                            0                  0                        0   \n",
       "1                            0                  0                        0   \n",
       "2                         1396               2792                      803   \n",
       "3                            0                  0                        0   \n",
       "4                          142                142                        0   \n",
       "\n",
       "   reverseStdevIAT  reverseAvgPacketSize  reverseFlowExists  remote  \\\n",
       "0                0                     0                  0       0   \n",
       "1                0                     0                  0       1   \n",
       "2               55                  1359                  1       1   \n",
       "3                0                     0                  0       1   \n",
       "4                0                   142                  1       0   \n",
       "\n",
       "   broadcast  HTTP  HTTPS  DNS  NTP  TCP_others  UDP_others year_month  \\\n",
       "0          0     0      0    1    0           0           0    2019_08   \n",
       "1          0     0      0    0    0           0           1    2019_09   \n",
       "2          0     0      1    0    0           1           0    2019_08   \n",
       "3          0     0      0    0    0           0           1    2019_07   \n",
       "4          0     0      0    1    0           0           0    2019_07   \n",
       "\n",
       "                 datetime  \n",
       "0 2019-08-12 21:01:27.250  \n",
       "1 2019-09-19 06:31:15.204  \n",
       "2 2019-08-16 02:58:57.694  \n",
       "3 2019-07-29 03:03:10.832  \n",
       "4 2019-07-10 16:02:39.688  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['dataset'] = data['dataset'].astype('category').cat.codes\n",
    "data['datetime'] = pd.to_datetime(data['start_date'] + ' ' + data['start_time'], errors='coerce')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the row limit\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Remove the column limit\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Remove the width limit for better horizontal scrolling\n",
    "pd.set_option('display.width', None)\n",
    "\n",
    "# Optional: Set column width limit for wider cells (helps with long text)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '05:37:31.427'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/1z/8gdr4m5s3vnglmy5m5q4vrzh0000gn/T/ipykernel_21286/919303488.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Separate features and target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             return_tuple = (\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1094\u001b[0m                 )\n\u001b[1;32m   1095\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1096\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1097\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    874\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m         \"\"\"\n\u001b[1;32m    876\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[1;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m                 )\n\u001b[1;32m   1472\u001b[0m             ):\n\u001b[0;32m-> 1473\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m             \u001b[0mFitted\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    912\u001b[0m         \"\"\"\n\u001b[1;32m    913\u001b[0m         \u001b[0mfirst_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         X = self._validate_data(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1011\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1014\u001b[0;31m                 raise ValueError(\n\u001b[0m\u001b[1;32m   1015\u001b[0m                     \u001b[0;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m                 ) from complex_warning\n\u001b[1;32m   1017\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_array_api.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[1;32m    741\u001b[0m         \u001b[0;31m# Use NumPy API to support order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 745\u001b[0;31m             \u001b[0marray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    746\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m         \u001b[0;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \u001b[0;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, dtype, copy)\u001b[0m\n\u001b[1;32m   2149\u001b[0m     def __array__(\n\u001b[1;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2151\u001b[0m     ) -> np.ndarray:\n\u001b[1;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2153\u001b[0;31m         \u001b[0marr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2154\u001b[0m         if (\n\u001b[1;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2156\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: '05:37:31.427'"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target\n",
    "X = sample.drop('dataset', axis=1)\n",
    "y = sample['dataset']\n",
    "\n",
    "# Drop the original 'start_date' column if no longer needed\n",
    "X = X.drop(columns=['start_date'])\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for models that require it\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Let's assume 'X' is your scaled features DataFrame without the target 'dataset' column\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m# Initialize and fit K-Means\u001b[39;00m\n\u001b[1;32m      8\u001b[0m kmeans \u001b[39m=\u001b[39m KMeans(n_clusters\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)  \u001b[39m# Adjust n_clusters based on your dataset\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m sample[\u001b[39m'\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mfit_predict(X)\n\u001b[1;32m     11\u001b[0m \u001b[39m# Check the number of samples in each cluster\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39mprint\u001b[39m(sample[\u001b[39m'\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalue_counts())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Let's assume 'X' is your scaled features DataFrame without the target 'dataset' column\n",
    "# Initialize and fit K-Means\n",
    "kmeans = KMeans(n_clusters=5, random_state=42)  # Adjust n_clusters based on your dataset\n",
    "sample['cluster'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Check the number of samples in each cluster\n",
    "print(sample['cluster'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 7 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   start_date  9999 non-null   object\n",
      " 1   start_time  9999 non-null   object\n",
      " 2   IoTMac      9999 non-null   object\n",
      " 3   hostMac     9999 non-null   object\n",
      " 4   IoTIP       9999 non-null   object\n",
      " 5   hostIP      9999 non-null   object\n",
      " 6   year_month  9999 non-null   object\n",
      "dtypes: object(7)\n",
      "memory usage: 546.9+ KB\n"
     ]
    }
   ],
   "source": [
    "strings = sample.select_dtypes(include=['object', 'string'])\n",
    "strings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 42 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   dataset                      9999 non-null   int8          \n",
      " 1   duration                     9999 non-null   float64       \n",
      " 2   reverseDelta                 9999 non-null   float64       \n",
      " 3   IoTIP_int                    9999 non-null   int64         \n",
      " 4   hostIP_int                   9999 non-null   int64         \n",
      " 5   ipProto                      9999 non-null   int64         \n",
      " 6   IoTPort                      9999 non-null   int64         \n",
      " 7   hostPort                     9999 non-null   int64         \n",
      " 8   PacketCount                  9999 non-null   int64         \n",
      " 9   BytesCount                   9999 non-null   int64         \n",
      " 10  reversePacketCount           9999 non-null   int64         \n",
      " 11  reverseBytesCount            9999 non-null   int64         \n",
      " 12  SmallPktCount                9999 non-null   int64         \n",
      " 13  LargePktCount                9999 non-null   int64         \n",
      " 14  NonEmptyPktCount             9999 non-null   int64         \n",
      " 15  DataByteCount                9999 non-null   int64         \n",
      " 16  AvgIAT                       9999 non-null   int64         \n",
      " 17  FirstNonEmptyPktSize         9999 non-null   int64         \n",
      " 18  MaxPktSize                   9999 non-null   int64         \n",
      " 19  StdevPayloadSize             9999 non-null   int64         \n",
      " 20  StdevIAT                     9999 non-null   int64         \n",
      " 21  AvgPacketSize                9999 non-null   int64         \n",
      " 22  reverseSmallPktCount         9999 non-null   int64         \n",
      " 23  reverseLargePktCount         9999 non-null   int64         \n",
      " 24  reverseNonEmptyPktCount      9999 non-null   int64         \n",
      " 25  reverseDataByteCount         9999 non-null   int64         \n",
      " 26  reverseAvgIAT                9999 non-null   int64         \n",
      " 27  reverseFirstNonEmptyPktSize  9999 non-null   int64         \n",
      " 28  reverseMaxPktSize            9999 non-null   int64         \n",
      " 29  reverseStdevPayloadSize      9999 non-null   int64         \n",
      " 30  reverseStdevIAT              9999 non-null   int64         \n",
      " 31  reverseAvgPacketSize         9999 non-null   int64         \n",
      " 32  reverseFlowExists            9999 non-null   int64         \n",
      " 33  remote                       9999 non-null   int64         \n",
      " 34  broadcast                    9999 non-null   int64         \n",
      " 35  HTTP                         9999 non-null   int64         \n",
      " 36  HTTPS                        9999 non-null   int64         \n",
      " 37  DNS                          9999 non-null   int64         \n",
      " 38  NTP                          9999 non-null   int64         \n",
      " 39  TCP_others                   9999 non-null   int64         \n",
      " 40  UDP_others                   9999 non-null   int64         \n",
      " 41  datetime                     9989 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(38), int8(1)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "other = sample.select_dtypes(exclude=['object', 'string'])\n",
    "other.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "DTypePromotionError",
     "evalue": "The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mDTypePromotionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[39m# Scale features for models that require it\u001b[39;00m\n\u001b[1;32m     12\u001b[0m scaler \u001b[39m=\u001b[39m StandardScaler()\n\u001b[0;32m---> 13\u001b[0m X_train \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39;49mfit_transform(X_train)\n\u001b[1;32m     14\u001b[0m X_test \u001b[39m=\u001b[39m scaler\u001b[39m.\u001b[39mtransform(X_test)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/_set_output.py:316\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39m@wraps\u001b[39m(f)\n\u001b[1;32m    315\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped\u001b[39m(\u001b[39mself\u001b[39m, X, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 316\u001b[0m     data_to_wrap \u001b[39m=\u001b[39m f(\u001b[39mself\u001b[39;49m, X, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    317\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(data_to_wrap, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    318\u001b[0m         \u001b[39m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    319\u001b[0m         return_tuple \u001b[39m=\u001b[39m (\n\u001b[1;32m    320\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[39m0\u001b[39m], X, \u001b[39mself\u001b[39m),\n\u001b[1;32m    321\u001b[0m             \u001b[39m*\u001b[39mdata_to_wrap[\u001b[39m1\u001b[39m:],\n\u001b[1;32m    322\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1098\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m   1083\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m   1084\u001b[0m             (\n\u001b[1;32m   1085\u001b[0m                 \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThis object (\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m) has a `transform`\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1093\u001b[0m             \u001b[39mUserWarning\u001b[39;00m,\n\u001b[1;32m   1094\u001b[0m         )\n\u001b[1;32m   1096\u001b[0m \u001b[39mif\u001b[39;00m y \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1097\u001b[0m     \u001b[39m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m-> 1098\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit(X, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\u001b[39m.\u001b[39mtransform(X)\n\u001b[1;32m   1099\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1100\u001b[0m     \u001b[39m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m   1101\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit(X, y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\u001b[39m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py:878\u001b[0m, in \u001b[0;36mStandardScaler.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[39m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[0;32m--> 878\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpartial_fit(X, y, sample_weight)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_data.py:914\u001b[0m, in \u001b[0;36mStandardScaler.partial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[1;32m    883\u001b[0m \n\u001b[1;32m    884\u001b[0m \u001b[39mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[39m    Fitted scaler.\u001b[39;00m\n\u001b[1;32m    912\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    913\u001b[0m first_call \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mn_samples_seen_\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 914\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(\n\u001b[1;32m    915\u001b[0m     X,\n\u001b[1;32m    916\u001b[0m     accept_sparse\u001b[39m=\u001b[39;49m(\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mcsc\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m    917\u001b[0m     dtype\u001b[39m=\u001b[39;49mFLOAT_DTYPES,\n\u001b[1;32m    918\u001b[0m     force_all_finite\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mallow-nan\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    919\u001b[0m     reset\u001b[39m=\u001b[39;49mfirst_call,\n\u001b[1;32m    920\u001b[0m )\n\u001b[1;32m    921\u001b[0m n_features \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m    923\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:633\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[1;32m    631\u001b[0m         out \u001b[39m=\u001b[39m X, y\n\u001b[1;32m    632\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 633\u001b[0m     out \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mX\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcheck_params)\n\u001b[1;32m    634\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n\u001b[1;32m    635\u001b[0m     out \u001b[39m=\u001b[39m _check_y(y, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/validation.py:887\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m    883\u001b[0m pandas_requires_conversion \u001b[39m=\u001b[39m \u001b[39many\u001b[39m(\n\u001b[1;32m    884\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m dtypes_orig\n\u001b[1;32m    885\u001b[0m )\n\u001b[1;32m    886\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(dtype_iter, np\u001b[39m.\u001b[39mdtype) \u001b[39mfor\u001b[39;00m dtype_iter \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[0;32m--> 887\u001b[0m     dtype_orig \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mresult_type(\u001b[39m*\u001b[39;49mdtypes_orig)\n\u001b[1;32m    888\u001b[0m \u001b[39melif\u001b[39;00m pandas_requires_conversion \u001b[39mand\u001b[39;00m \u001b[39many\u001b[39m(d \u001b[39m==\u001b[39m \u001b[39mobject\u001b[39m \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m dtypes_orig):\n\u001b[1;32m    889\u001b[0m     \u001b[39m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[1;32m    890\u001b[0m     dtype_orig \u001b[39m=\u001b[39m \u001b[39mobject\u001b[39m\n",
      "\u001b[0;31mDTypePromotionError\u001b[0m: The DType <class 'numpy.dtypes.DateTime64DType'> could not be promoted by <class 'numpy.dtypes.Float64DType'>. This means that no common DType exists for the given inputs. For example they cannot be stored in a single array unless the dtype is `object`. The full list of DTypes is: (<class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Float64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.Int64DType'>, <class 'numpy.dtypes.DateTime64DType'>)"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Separate features and target\n",
    "X = other.drop('dataset', axis=1)\n",
    "y = other['dataset']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale features for models that require it\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"[''] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m# print(\"Non-numeric columns:\", non_numeric_columns)\u001b[39;00m\n\u001b[1;32m      3\u001b[0m non_numeric_columns\n\u001b[0;32m----> 4\u001b[0m new \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39;49mdrop(columns\u001b[39m=\u001b[39;49m[\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m])\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5582\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5583\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5584\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5585\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5586\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5587\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5588\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5589\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4790\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"[''] not found in axis\""
     ]
    }
   ],
   "source": [
    "non_numeric_columns = X.select_dtypes(include=['object', 'string']).columns\n",
    "# print(\"Non-numeric columns:\", non_numeric_columns)\n",
    "non_numeric_columns\n",
    "new = X.drop(columns=[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 9999 entries, 0 to 9998\n",
      "Data columns (total 41 columns):\n",
      " #   Column                       Non-Null Count  Dtype         \n",
      "---  ------                       --------------  -----         \n",
      " 0   duration                     9999 non-null   float64       \n",
      " 1   reverseDelta                 9999 non-null   float64       \n",
      " 2   IoTIP_int                    9999 non-null   int64         \n",
      " 3   hostIP_int                   9999 non-null   int64         \n",
      " 4   ipProto                      9999 non-null   int64         \n",
      " 5   IoTPort                      9999 non-null   int64         \n",
      " 6   hostPort                     9999 non-null   int64         \n",
      " 7   PacketCount                  9999 non-null   int64         \n",
      " 8   BytesCount                   9999 non-null   int64         \n",
      " 9   reversePacketCount           9999 non-null   int64         \n",
      " 10  reverseBytesCount            9999 non-null   int64         \n",
      " 11  SmallPktCount                9999 non-null   int64         \n",
      " 12  LargePktCount                9999 non-null   int64         \n",
      " 13  NonEmptyPktCount             9999 non-null   int64         \n",
      " 14  DataByteCount                9999 non-null   int64         \n",
      " 15  AvgIAT                       9999 non-null   int64         \n",
      " 16  FirstNonEmptyPktSize         9999 non-null   int64         \n",
      " 17  MaxPktSize                   9999 non-null   int64         \n",
      " 18  StdevPayloadSize             9999 non-null   int64         \n",
      " 19  StdevIAT                     9999 non-null   int64         \n",
      " 20  AvgPacketSize                9999 non-null   int64         \n",
      " 21  reverseSmallPktCount         9999 non-null   int64         \n",
      " 22  reverseLargePktCount         9999 non-null   int64         \n",
      " 23  reverseNonEmptyPktCount      9999 non-null   int64         \n",
      " 24  reverseDataByteCount         9999 non-null   int64         \n",
      " 25  reverseAvgIAT                9999 non-null   int64         \n",
      " 26  reverseFirstNonEmptyPktSize  9999 non-null   int64         \n",
      " 27  reverseMaxPktSize            9999 non-null   int64         \n",
      " 28  reverseStdevPayloadSize      9999 non-null   int64         \n",
      " 29  reverseStdevIAT              9999 non-null   int64         \n",
      " 30  reverseAvgPacketSize         9999 non-null   int64         \n",
      " 31  reverseFlowExists            9999 non-null   int64         \n",
      " 32  remote                       9999 non-null   int64         \n",
      " 33  broadcast                    9999 non-null   int64         \n",
      " 34  HTTP                         9999 non-null   int64         \n",
      " 35  HTTPS                        9999 non-null   int64         \n",
      " 36  DNS                          9999 non-null   int64         \n",
      " 37  NTP                          9999 non-null   int64         \n",
      " 38  TCP_others                   9999 non-null   int64         \n",
      " 39  UDP_others                   9999 non-null   int64         \n",
      " 40  datetime                     9989 non-null   datetime64[ns]\n",
      "dtypes: datetime64[ns](1), float64(2), int64(38)\n",
      "memory usage: 3.1 MB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>IoTMac</th>\n",
       "      <th>hostMac</th>\n",
       "      <th>IoTIP</th>\n",
       "      <th>IoTIP_int</th>\n",
       "      <th>hostIP</th>\n",
       "      <th>hostIP_int</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>hostPort</th>\n",
       "      <th>PacketCount</th>\n",
       "      <th>BytesCount</th>\n",
       "      <th>reversePacketCount</th>\n",
       "      <th>reverseBytesCount</th>\n",
       "      <th>SmallPktCount</th>\n",
       "      <th>LargePktCount</th>\n",
       "      <th>NonEmptyPktCount</th>\n",
       "      <th>DataByteCount</th>\n",
       "      <th>AvgIAT</th>\n",
       "      <th>FirstNonEmptyPktSize</th>\n",
       "      <th>MaxPktSize</th>\n",
       "      <th>StdevPayloadSize</th>\n",
       "      <th>StdevIAT</th>\n",
       "      <th>AvgPacketSize</th>\n",
       "      <th>reverseSmallPktCount</th>\n",
       "      <th>reverseLargePktCount</th>\n",
       "      <th>reverseNonEmptyPktCount</th>\n",
       "      <th>reverseDataByteCount</th>\n",
       "      <th>reverseAvgIAT</th>\n",
       "      <th>reverseFirstNonEmptyPktSize</th>\n",
       "      <th>reverseMaxPktSize</th>\n",
       "      <th>reverseStdevPayloadSize</th>\n",
       "      <th>reverseStdevIAT</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "      <th>year_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google_home_gen1_2019_08.csv</td>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>21:01:27.25</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>48:d6:d5:92:96:a2:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.184</td>\n",
       "      <td>3232235960</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>33789</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>planex_camera_one_shot!_2019_09.csv</td>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>06:31:15.204</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>3232236012</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>4026531834</td>\n",
       "      <td>17</td>\n",
       "      <td>46713</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019_09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sony_bravia_2019_08.csv</td>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>02:58:57.694</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.012</td>\n",
       "      <td>04:5d:4b:a4:d0:2e:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.124</td>\n",
       "      <td>3232235900</td>\n",
       "      <td>74.125.102.41</td>\n",
       "      <td>1249732137</td>\n",
       "      <td>6</td>\n",
       "      <td>53460</td>\n",
       "      <td>443</td>\n",
       "      <td>18</td>\n",
       "      <td>1986</td>\n",
       "      <td>18</td>\n",
       "      <td>18612</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1030</td>\n",
       "      <td>21</td>\n",
       "      <td>188</td>\n",
       "      <td>685</td>\n",
       "      <td>253</td>\n",
       "      <td>54</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17668</td>\n",
       "      <td>24</td>\n",
       "      <td>1396</td>\n",
       "      <td>2792</td>\n",
       "      <td>803</td>\n",
       "      <td>55</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>planex_camera_one_shot!_2019_07.csv</td>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>03:03:10.832</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>3232236012</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>4026531834</td>\n",
       "      <td>17</td>\n",
       "      <td>48008</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019_07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jvc_kenwood_cu-hb1_2019_07.csv</td>\n",
       "      <td>2019-07-10</td>\n",
       "      <td>16:02:39.688</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>00:a2:b2:b9:09:87:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.186</td>\n",
       "      <td>3232235962</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>39289</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>142</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2019_07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               dataset  start_date    start_time  duration  \\\n",
       "0         google_home_gen1_2019_08.csv  2019-08-12   21:01:27.25     0.000   \n",
       "1  planex_camera_one_shot!_2019_09.csv  2019-09-19  06:31:15.204     0.000   \n",
       "2              sony_bravia_2019_08.csv  2019-08-16  02:58:57.694     0.434   \n",
       "3  planex_camera_one_shot!_2019_07.csv  2019-07-29  03:03:10.832     0.000   \n",
       "4       jvc_kenwood_cu-hb1_2019_07.csv  2019-07-10  16:02:39.688     0.001   \n",
       "\n",
       "   reverseDelta              IoTMac             hostMac          IoTIP  \\\n",
       "0         0.000  48:d6:d5:92:96:a2:  38:d5:47:0c:25:d4:  192.168.1.184   \n",
       "1         0.000  00:1b:c7:fa:c3:e6:  01:00:5e:7f:ff:fa:  192.168.1.236   \n",
       "2         0.012  04:5d:4b:a4:d0:2e:  38:d5:47:0c:25:d4:  192.168.1.124   \n",
       "3         0.000  00:1b:c7:fa:c3:e6:  01:00:5e:7f:ff:fa:  192.168.1.236   \n",
       "4         0.001  00:a2:b2:b9:09:87:  38:d5:47:0c:25:d4:  192.168.1.186   \n",
       "\n",
       "    IoTIP_int           hostIP  hostIP_int  ipProto  IoTPort  hostPort  \\\n",
       "0  3232235960      192.168.1.1  3232235777       17    33789        53   \n",
       "1  3232236012  239.255.255.250  4026531834       17    46713      1900   \n",
       "2  3232235900    74.125.102.41  1249732137        6    53460       443   \n",
       "3  3232236012  239.255.255.250  4026531834       17    48008      1900   \n",
       "4  3232235962      192.168.1.1  3232235777       17    39289        53   \n",
       "\n",
       "   PacketCount  BytesCount  reversePacketCount  reverseBytesCount  \\\n",
       "0            1          75                   0                  0   \n",
       "1            1         294                   0                  0   \n",
       "2           18        1986                  18              18612   \n",
       "3            1         294                   0                  0   \n",
       "4            1          71                   1                170   \n",
       "\n",
       "   SmallPktCount  LargePktCount  NonEmptyPktCount  DataByteCount  AvgIAT  \\\n",
       "0              1              0                 1             47       0   \n",
       "1              0              1                 1            266       0   \n",
       "2              1              1                 4           1030      21   \n",
       "3              0              1                 1            266       0   \n",
       "4              1              0                 1             43       0   \n",
       "\n",
       "   FirstNonEmptyPktSize  MaxPktSize  StdevPayloadSize  StdevIAT  \\\n",
       "0                    47          47                 0         0   \n",
       "1                   266         266                 0         0   \n",
       "2                   188         685               253        54   \n",
       "3                   266         266                 0         0   \n",
       "4                    43          43                 0         0   \n",
       "\n",
       "   AvgPacketSize  reverseSmallPktCount  reverseLargePktCount  \\\n",
       "0             47                     0                     0   \n",
       "1            266                     0                     0   \n",
       "2            257                     0                    13   \n",
       "3            266                     0                     0   \n",
       "4             43                     0                     0   \n",
       "\n",
       "   reverseNonEmptyPktCount  reverseDataByteCount  reverseAvgIAT  \\\n",
       "0                        0                     0              0   \n",
       "1                        0                     0              0   \n",
       "2                       13                 17668             24   \n",
       "3                        0                     0              0   \n",
       "4                        1                   142              0   \n",
       "\n",
       "   reverseFirstNonEmptyPktSize  reverseMaxPktSize  reverseStdevPayloadSize  \\\n",
       "0                            0                  0                        0   \n",
       "1                            0                  0                        0   \n",
       "2                         1396               2792                      803   \n",
       "3                            0                  0                        0   \n",
       "4                          142                142                        0   \n",
       "\n",
       "   reverseStdevIAT  reverseAvgPacketSize  reverseFlowExists  remote  \\\n",
       "0                0                     0                  0       0   \n",
       "1                0                     0                  0       1   \n",
       "2               55                  1359                  1       1   \n",
       "3                0                     0                  0       1   \n",
       "4                0                   142                  1       0   \n",
       "\n",
       "   broadcast  HTTP  HTTPS  DNS  NTP  TCP_others  UDP_others year_month  \n",
       "0          0     0      0    1    0           0           0    2019_08  \n",
       "1          0     0      0    0    0           0           1    2019_09  \n",
       "2          0     0      1    0    0           1           0    2019_08  \n",
       "3          0     0      0    0    0           0           1    2019_07  \n",
       "4          0     0      0    1    0           0           0    2019_07  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['dataset'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# new = sample.select_dtypes(include=['object', 'string'])\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m heads \u001b[39m=\u001b[39m sample\u001b[39m.\u001b[39;49mdrop(columns \u001b[39m=\u001b[39;49m [\u001b[39m'\u001b[39;49m\u001b[39mdataset\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mstart_date\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mstart_time\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mIoTMac\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mIoTIP\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[1;32m      3\u001b[0m heads\u001b[39m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5433\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdrop\u001b[39m(\n\u001b[1;32m   5434\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   5435\u001b[0m     labels: IndexLabel \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mraise\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   5443\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   5444\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   5445\u001b[0m \u001b[39m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5446\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5579\u001b[0m \u001b[39m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5580\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5581\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mdrop(\n\u001b[1;32m   5582\u001b[0m         labels\u001b[39m=\u001b[39;49mlabels,\n\u001b[1;32m   5583\u001b[0m         axis\u001b[39m=\u001b[39;49maxis,\n\u001b[1;32m   5584\u001b[0m         index\u001b[39m=\u001b[39;49mindex,\n\u001b[1;32m   5585\u001b[0m         columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   5586\u001b[0m         level\u001b[39m=\u001b[39;49mlevel,\n\u001b[1;32m   5587\u001b[0m         inplace\u001b[39m=\u001b[39;49minplace,\n\u001b[1;32m   5588\u001b[0m         errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   5589\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4786\u001b[0m \u001b[39mfor\u001b[39;00m axis, labels \u001b[39min\u001b[39;00m axes\u001b[39m.\u001b[39mitems():\n\u001b[1;32m   4787\u001b[0m     \u001b[39mif\u001b[39;00m labels \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4788\u001b[0m         obj \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39;49m_drop_axis(labels, axis, level\u001b[39m=\u001b[39;49mlevel, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4790\u001b[0m \u001b[39mif\u001b[39;00m inplace:\n\u001b[1;32m   4791\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4828\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mdrop(labels, level\u001b[39m=\u001b[39mlevel, errors\u001b[39m=\u001b[39merrors)\n\u001b[1;32m   4829\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 4830\u001b[0m         new_axis \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39;49mdrop(labels, errors\u001b[39m=\u001b[39;49merrors)\n\u001b[1;32m   4831\u001b[0m     indexer \u001b[39m=\u001b[39m axis\u001b[39m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4833\u001b[0m \u001b[39m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4834\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/core/indexes/base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   7068\u001b[0m \u001b[39mif\u001b[39;00m mask\u001b[39m.\u001b[39many():\n\u001b[1;32m   7069\u001b[0m     \u001b[39mif\u001b[39;00m errors \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m-> 7070\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mlabels[mask]\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m not found in axis\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   7071\u001b[0m     indexer \u001b[39m=\u001b[39m indexer[\u001b[39m~\u001b[39mmask]\n\u001b[1;32m   7072\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['dataset'] not found in axis\""
     ]
    }
   ],
   "source": [
    "# new = sample.select_dtypes(include=['object', 'string'])\n",
    "heads = sample.drop(columns = ['dataset', 'start_date', 'start_time', 'IoTMac', 'IoTIP'])\n",
    "heads.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.get_dummies(heads)\n",
    "data.shape\n",
    "data.head()\n",
    "classes = sample['dataset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>IoTMac</th>\n",
       "      <th>hostMac</th>\n",
       "      <th>IoTIP</th>\n",
       "      <th>hostIP</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>...</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>06:50:15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>33033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>21:01:27</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>48:d6:d5:92:96:a2:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.184</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>17</td>\n",
       "      <td>33789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>06:31:15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>46713</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>02:58:57</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.012</td>\n",
       "      <td>04:5d:4b:a4:d0:2e:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.124</td>\n",
       "      <td>74.125.102.41</td>\n",
       "      <td>6</td>\n",
       "      <td>53460</td>\n",
       "      <td>...</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>03:03:10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>48008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date start_time  duration  reverseDelta              IoTMac  \\\n",
       "0  2019-09-25   06:50:15     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "1  2019-08-12   21:01:27     0.000         0.000  48:d6:d5:92:96:a2:   \n",
       "2  2019-09-19   06:31:15     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "3  2019-08-16   02:58:57     0.434         0.012  04:5d:4b:a4:d0:2e:   \n",
       "4  2019-07-29   03:03:10     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "\n",
       "              hostMac          IoTIP           hostIP  ipProto  IoTPort  ...  \\\n",
       "0  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    33033  ...   \n",
       "1  38:d5:47:0c:25:d4:  192.168.1.184      192.168.1.1       17    33789  ...   \n",
       "2  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    46713  ...   \n",
       "3  38:d5:47:0c:25:d4:  192.168.1.124    74.125.102.41        6    53460  ...   \n",
       "4  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    48008  ...   \n",
       "\n",
       "   reverseAvgPacketSize  reverseFlowExists  remote  broadcast  HTTP  HTTPS  \\\n",
       "0                     0                  0       1          0     0      0   \n",
       "1                     0                  0       0          0     0      0   \n",
       "2                     0                  0       1          0     0      0   \n",
       "3                  1359                  1       1          0     0      1   \n",
       "4                     0                  0       1          0     0      0   \n",
       "\n",
       "   DNS  NTP  TCP_others  UDP_others  \n",
       "0    0    0           0           1  \n",
       "1    1    0           0           0  \n",
       "2    0    0           0           1  \n",
       "3    0    0           1           0  \n",
       "4    0    0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newSample = pd.read_csv(\"newSample.csv\") #0.935\n",
    "newSample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly classified elements vs all: 1880 2000\n",
      "correct divide all: 0.94\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x1000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sample = pd.read_csv(\"newSample.csv\")\n",
    "\n",
    "# heads = sample.drop(columns = ['start_date', 'start_time', 'IoTMac', 'IoTIP', 'IoTPort', 'hostMac', 'hostIP'])\n",
    "heads = sample.drop(columns = ['start_date', 'start_time', 'IoTMac', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "data = pd.get_dummies(heads)\n",
    "classes = sample['IoTMac']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=0.2, random_state=42)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = knn_classifier.predict(X_test)\n",
    "\n",
    "labels = sorted(set(y_train) | set(y_test))\n",
    "\n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "\n",
    "\n",
    "correct_classifications = cm.diagonal().sum()\n",
    "all = cm.sum()\n",
    "print(\"Number of correctly classified elements vs all:\", correct_classifications, all)\n",
    "print(\"correct divide all:\", correct_classifications/all)\n",
    "\n",
    "\n",
    "\n",
    "# Display the confusion matrix\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn_classifier.classes_)\n",
    "plt.figure(figsize=(10, 10))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "disp.plot(cmap='Blues')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sample.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Dropped dataset, IoTIP_int, hostIP_int, year_month\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[39m# df = pd.read_csv('sample.csv')\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39msample.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m     11\u001b[0m column_names \u001b[39m=\u001b[39m [\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mdataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstart_date\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mstart_time\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mduration\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreverseDelta\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTMac\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhostMac\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTIP\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTIP_int\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mhostIP\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhostIP_int\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mipProto\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mIoTPort\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mhostPort\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mPacketCount\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mBytesCount\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mreversePacketCount\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mUDP_others\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39myear_month\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     20\u001b[0m ]\n\u001b[1;32m     21\u001b[0m df\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m column_names\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[39m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    622\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1881\u001b[0m     f,\n\u001b[1;32m   1882\u001b[0m     mode,\n\u001b[1;32m   1883\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1884\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1885\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1886\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1887\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1888\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1889\u001b[0m )\n\u001b[1;32m   1890\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    876\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    877\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    878\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sample.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dropped dataset, IoTIP_int, hostIP_int, year_month\n",
    "# df = pd.read_csv('sample.csv')\n",
    "df = pd.read_csv(\"sample.csv\")\n",
    "column_names = [\n",
    "    \"dataset\", \"start_date\", \"start_time\", \"duration\", \"reverseDelta\", \"IoTMac\", \"hostMac\", \"IoTIP\", \"IoTIP_int\",\n",
    "    \"hostIP\", \"hostIP_int\", \"ipProto\", \"IoTPort\", \"hostPort\", \"PacketCount\", \"BytesCount\", \"reversePacketCount\",\n",
    "    \"reverseBytesCount\", \"SmallPktCount\", \"LargePktCount\", \"NonEmptyPktCount\", \"DataByteCount\", \"AvgIAT\",\n",
    "    \"FirstNonEmptyPktSize\", \"MaxPktSize\", \"StdevPayloadSize\", \"StdevIAT\", \"AvgPacketSize\", \"reverseSmallPktCount\",\n",
    "    \"reverseLargePktCount\", \"reverseNonEmptyPktCount\", \"reverseDataByteCount\", \"reverseAvgIAT\",\n",
    "    \"reverseFirstNonEmptyPktSize\", \"reverseMaxPktSize\", \"reverseStdevPayloadSize\", \"reverseStdevIAT\",\n",
    "    \"reverseAvgPacketSize\", \"reverseFlowExists\", \"remote\", \"broadcast\", \"HTTP\", \"HTTPS\", \"DNS\", \"NTP\", \"TCP_others\",\n",
    "    \"UDP_others\", \"year_month\"\n",
    "]\n",
    "df.columns = column_names\n",
    "df.head()\n",
    "X = df.drop(columns=['IoTMac'])\n",
    "y = df['IoTMac']\n",
    "\n",
    "# Defines categorical variables\n",
    "categories = ['IoTMac', 'hostMac', 'IoTIP', 'hostIP', 'ipProto', 'reverseFlowExists', 'remote', 'broadcast', 'HTTP', 'HTTPS', 'DNS', 'NTP', 'TCP_others', 'UDP_others']\n",
    "for var in categories:\n",
    "    df[var] = df[var].astype('category')\n",
    "\n",
    "X = pd.get_dummies(X, drop_first=True)\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.2, random_state=10)\n",
    "\n",
    "# Fits the model on the training data using Naive Bayes\n",
    "model = GaussianNB()\n",
    "model.fit(XTrain, yTrain)\n",
    "\n",
    "yPred = model.predict(XTest)\n",
    "print(classification_report(yTest, yPred, zero_division=0))\n",
    "\n",
    "# Shows true positives, true negatives, false positives, false negatives\n",
    "confusionMatrix = confusion_matrix(yTest, yPred)\n",
    "correct_classifications = confusionMatrix.diagonal().sum()\n",
    "all = confusionMatrix.sum()\n",
    "print(\"Number of correctly classified elements:\", correct_classifications)\n",
    "print(\"correct divide all:\", correct_classifications/all)\n",
    "# Heatmap visualisation of the Confusion Matrix\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(confusionMatrix, annot=True, fmt='d', cmap='Blues', xticklabels=model.classes_, yticklabels=model.classes_)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>IoTMac</th>\n",
       "      <th>hostMac</th>\n",
       "      <th>IoTIP</th>\n",
       "      <th>hostIP</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>...</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>06:50:15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>33033</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>21:01:27</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>48:d6:d5:92:96:a2:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.184</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>17</td>\n",
       "      <td>33789</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>06:31:15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>46713</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>02:58:57</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.012</td>\n",
       "      <td>04:5d:4b:a4:d0:2e:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.124</td>\n",
       "      <td>74.125.102.41</td>\n",
       "      <td>6</td>\n",
       "      <td>53460</td>\n",
       "      <td>...</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>03:03:10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>48008</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date start_time  duration  reverseDelta              IoTMac  \\\n",
       "0  2019-09-25   06:50:15     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "1  2019-08-12   21:01:27     0.000         0.000  48:d6:d5:92:96:a2:   \n",
       "2  2019-09-19   06:31:15     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "3  2019-08-16   02:58:57     0.434         0.012  04:5d:4b:a4:d0:2e:   \n",
       "4  2019-07-29   03:03:10     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "\n",
       "              hostMac          IoTIP           hostIP  ipProto  IoTPort  ...  \\\n",
       "0  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    33033  ...   \n",
       "1  38:d5:47:0c:25:d4:  192.168.1.184      192.168.1.1       17    33789  ...   \n",
       "2  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    46713  ...   \n",
       "3  38:d5:47:0c:25:d4:  192.168.1.124    74.125.102.41        6    53460  ...   \n",
       "4  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    48008  ...   \n",
       "\n",
       "   reverseAvgPacketSize  reverseFlowExists  remote  broadcast  HTTP  HTTPS  \\\n",
       "0                     0                  0       1          0     0      0   \n",
       "1                     0                  0       0          0     0      0   \n",
       "2                     0                  0       1          0     0      0   \n",
       "3                  1359                  1       1          0     0      1   \n",
       "4                     0                  0       1          0     0      0   \n",
       "\n",
       "   DNS  NTP  TCP_others  UDP_others  \n",
       "0    0    0           0           1  \n",
       "1    1    0           0           0  \n",
       "2    0    0           0           1  \n",
       "3    0    0           1           0  \n",
       "4    0    0           0           1  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "newSample = pd.read_csv(\"newSample.csv\")\n",
    "newSample.head()\n",
    "# newSample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sample = pd.read_csv(\"newSample.csv\")\n",
    "\n",
    "# heads = sample.drop(columns = ['start_date', 'start_time', 'IoTMac', 'IoTIP', 'IoTPort', 'hostMac', 'hostIP'])\n",
    "heads = sample.drop(columns = ['start_date', 'start_time', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "data = pd.get_dummies(heads)\n",
    "classes = sample['IoTMac']\n",
    "\n",
    "# data.head()\n",
    "correlation_matrix = data.corr()\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(10, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm')\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count                  10000\n",
       "unique                    24\n",
       "top       48:d6:d5:92:96:a2:\n",
       "freq                    3176\n",
       "Name: IoTMac, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"newSample.csv\")\n",
    "sample.IoTMac.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiran/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.5167 - loss: 1.7672 - val_accuracy: 0.6127 - val_loss: 1.1758\n",
      "Epoch 2/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.6430 - loss: 1.1203 - val_accuracy: 0.7053 - val_loss: 0.9350\n",
      "Epoch 3/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.7070 - loss: 0.8901 - val_accuracy: 0.7880 - val_loss: 0.7973\n",
      "Epoch 4/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.7750 - loss: 0.7648 - val_accuracy: 0.7927 - val_loss: 0.7467\n",
      "Epoch 5/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7906 - loss: 0.6969 - val_accuracy: 0.7953 - val_loss: 0.7438\n",
      "Epoch 6/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.7919 - loss: 0.6836 - val_accuracy: 0.8147 - val_loss: 0.7304\n",
      "Epoch 7/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8042 - loss: 0.6351 - val_accuracy: 0.7980 - val_loss: 0.7188\n",
      "Epoch 8/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.7944 - loss: 0.6389 - val_accuracy: 0.7787 - val_loss: 0.7123\n",
      "Epoch 9/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7899 - loss: 0.6281 - val_accuracy: 0.7887 - val_loss: 0.7559\n",
      "Epoch 10/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 918us/step - accuracy: 0.8044 - loss: 0.6025 - val_accuracy: 0.8060 - val_loss: 0.7503\n",
      "Epoch 11/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8074 - loss: 0.5979 - val_accuracy: 0.8020 - val_loss: 0.7245\n",
      "Epoch 12/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.8109 - loss: 0.5677 - val_accuracy: 0.8133 - val_loss: 0.7243\n",
      "Epoch 13/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.8144 - loss: 0.5525 - val_accuracy: 0.8080 - val_loss: 0.7579\n",
      "Epoch 14/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8162 - loss: 0.5627 - val_accuracy: 0.8133 - val_loss: 0.7130\n",
      "Epoch 15/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8186 - loss: 0.5522 - val_accuracy: 0.8127 - val_loss: 0.7365\n",
      "Epoch 16/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.8182 - loss: 0.5525 - val_accuracy: 0.8173 - val_loss: 0.7053\n",
      "Epoch 17/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8185 - loss: 0.5472 - val_accuracy: 0.8180 - val_loss: 0.6891\n",
      "Epoch 18/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8167 - loss: 0.5339 - val_accuracy: 0.8280 - val_loss: 0.7009\n",
      "Epoch 19/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.8263 - loss: 0.5362 - val_accuracy: 0.8207 - val_loss: 0.7274\n",
      "Epoch 20/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8392 - loss: 0.5089 - val_accuracy: 0.8347 - val_loss: 0.6886\n",
      "Epoch 21/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.8246 - loss: 0.5281 - val_accuracy: 0.8327 - val_loss: 0.6968\n",
      "Epoch 22/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8335 - loss: 0.4987 - val_accuracy: 0.8300 - val_loss: 0.7282\n",
      "Epoch 23/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8364 - loss: 0.4950 - val_accuracy: 0.8327 - val_loss: 0.7590\n",
      "Epoch 24/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.8425 - loss: 0.4805 - val_accuracy: 0.8380 - val_loss: 0.8623\n",
      "Epoch 25/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.8510 - loss: 0.4736 - val_accuracy: 0.8367 - val_loss: 0.7473\n",
      "Epoch 26/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 761us/step - accuracy: 0.8505 - loss: 0.4668 - val_accuracy: 0.8353 - val_loss: 0.6990\n",
      "Epoch 27/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.8540 - loss: 0.4445 - val_accuracy: 0.8347 - val_loss: 0.7252\n",
      "Epoch 28/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.8534 - loss: 0.4620 - val_accuracy: 0.8427 - val_loss: 0.7678\n",
      "Epoch 29/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.8436 - loss: 0.4657 - val_accuracy: 0.8447 - val_loss: 0.8106\n",
      "Epoch 30/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.8440 - loss: 0.4761 - val_accuracy: 0.8153 - val_loss: 0.8851\n",
      "Epoch 31/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.8539 - loss: 0.4671 - val_accuracy: 0.8600 - val_loss: 0.7146\n",
      "Epoch 32/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.8566 - loss: 0.4511 - val_accuracy: 0.8673 - val_loss: 0.7904\n",
      "Epoch 33/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8591 - loss: 0.4492 - val_accuracy: 0.8627 - val_loss: 0.7665\n",
      "Epoch 34/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.8714 - loss: 0.4169 - val_accuracy: 0.8707 - val_loss: 0.7778\n",
      "Epoch 35/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 824us/step - accuracy: 0.8664 - loss: 0.4371 - val_accuracy: 0.8607 - val_loss: 0.8250\n",
      "Epoch 36/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.8732 - loss: 0.4227 - val_accuracy: 0.8587 - val_loss: 0.8891\n",
      "Epoch 37/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8775 - loss: 0.4108 - val_accuracy: 0.8640 - val_loss: 0.8166\n",
      "Epoch 38/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 974us/step - accuracy: 0.8669 - loss: 0.4230 - val_accuracy: 0.8713 - val_loss: 0.8752\n",
      "Epoch 39/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 976us/step - accuracy: 0.8657 - loss: 0.4258 - val_accuracy: 0.8667 - val_loss: 0.8500\n",
      "Epoch 40/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.3823 - val_accuracy: 0.8633 - val_loss: 0.9084\n",
      "Epoch 41/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 912us/step - accuracy: 0.8737 - loss: 0.4009 - val_accuracy: 0.8700 - val_loss: 0.8848\n",
      "Epoch 42/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 927us/step - accuracy: 0.8733 - loss: 0.4090 - val_accuracy: 0.8607 - val_loss: 0.9314\n",
      "Epoch 43/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.8774 - loss: 0.3878 - val_accuracy: 0.8633 - val_loss: 0.9469\n",
      "Epoch 44/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8757 - loss: 0.4070 - val_accuracy: 0.8540 - val_loss: 0.9821\n",
      "Epoch 45/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.8629 - loss: 0.4568 - val_accuracy: 0.8667 - val_loss: 1.0494\n",
      "Epoch 46/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8785 - loss: 0.4347 - val_accuracy: 0.8607 - val_loss: 0.9338\n",
      "Epoch 47/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.8693 - loss: 0.4294 - val_accuracy: 0.8740 - val_loss: 0.8928\n",
      "Epoch 48/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.8697 - loss: 0.4101 - val_accuracy: 0.8673 - val_loss: 0.8924\n",
      "Epoch 49/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 825us/step - accuracy: 0.8672 - loss: 0.4177 - val_accuracy: 0.8647 - val_loss: 0.9548\n",
      "Epoch 50/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.8641 - loss: 0.3971 - val_accuracy: 0.8733 - val_loss: 0.9700\n",
      "Epoch 51/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 841us/step - accuracy: 0.8777 - loss: 0.3938 - val_accuracy: 0.8627 - val_loss: 1.1256\n",
      "Epoch 52/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 909us/step - accuracy: 0.8784 - loss: 0.3803 - val_accuracy: 0.8647 - val_loss: 1.1597\n",
      "Epoch 53/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8766 - loss: 0.4013 - val_accuracy: 0.8713 - val_loss: 1.0187\n",
      "Epoch 54/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8751 - loss: 0.4631 - val_accuracy: 0.8720 - val_loss: 0.9896\n",
      "Epoch 55/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.8745 - loss: 0.3856 - val_accuracy: 0.8667 - val_loss: 1.0646\n",
      "Epoch 56/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.8776 - loss: 0.4038 - val_accuracy: 0.8773 - val_loss: 1.1453\n",
      "Epoch 57/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8748 - loss: 0.3899 - val_accuracy: 0.8760 - val_loss: 1.1586\n",
      "Epoch 58/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.8847 - loss: 0.3695 - val_accuracy: 0.8767 - val_loss: 1.0549\n",
      "Epoch 59/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.8804 - loss: 0.3569 - val_accuracy: 0.8767 - val_loss: 1.1329\n",
      "Epoch 60/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.8846 - loss: 0.3610 - val_accuracy: 0.8647 - val_loss: 1.2013\n",
      "Epoch 61/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.8726 - loss: 0.3911 - val_accuracy: 0.8593 - val_loss: 1.1734\n",
      "Epoch 62/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8703 - loss: 0.3988 - val_accuracy: 0.8753 - val_loss: 1.1958\n",
      "Epoch 63/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3695 - val_accuracy: 0.8800 - val_loss: 1.2177\n",
      "Epoch 64/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.8865 - loss: 0.3656 - val_accuracy: 0.8800 - val_loss: 1.1680\n",
      "Epoch 65/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.8721 - loss: 0.4109 - val_accuracy: 0.8753 - val_loss: 1.2268\n",
      "Epoch 66/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 953us/step - accuracy: 0.8826 - loss: 0.3693 - val_accuracy: 0.8653 - val_loss: 1.3267\n",
      "Epoch 67/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.8807 - loss: 0.3709 - val_accuracy: 0.8400 - val_loss: 1.3591\n",
      "Epoch 68/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.8713 - loss: 0.4127 - val_accuracy: 0.8693 - val_loss: 1.4368\n",
      "Epoch 69/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8817 - loss: 0.3675 - val_accuracy: 0.8673 - val_loss: 1.7781\n",
      "Epoch 70/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.8775 - loss: 0.3836 - val_accuracy: 0.8747 - val_loss: 1.6693\n",
      "Epoch 71/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.8771 - loss: 0.4039 - val_accuracy: 0.8760 - val_loss: 1.7002\n",
      "Epoch 72/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.8861 - loss: 0.4225 - val_accuracy: 0.8647 - val_loss: 1.5225\n",
      "Epoch 73/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 879us/step - accuracy: 0.8690 - loss: 0.4142 - val_accuracy: 0.8740 - val_loss: 1.3863\n",
      "Epoch 74/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 823us/step - accuracy: 0.8853 - loss: 0.3709 - val_accuracy: 0.8740 - val_loss: 1.2083\n",
      "Epoch 75/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8783 - loss: 0.4646 - val_accuracy: 0.8707 - val_loss: 1.1955\n",
      "Epoch 76/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.8702 - loss: 0.4445 - val_accuracy: 0.8547 - val_loss: 1.1393\n",
      "Epoch 77/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.8676 - loss: 0.4172 - val_accuracy: 0.8533 - val_loss: 1.2190\n",
      "Epoch 78/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.8737 - loss: 0.4125 - val_accuracy: 0.8693 - val_loss: 1.0433\n",
      "Epoch 79/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.8749 - loss: 0.3955 - val_accuracy: 0.8787 - val_loss: 1.0364\n",
      "Epoch 80/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.8747 - loss: 0.3946 - val_accuracy: 0.8767 - val_loss: 1.0457\n",
      "Epoch 81/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.8792 - loss: 0.4024 - val_accuracy: 0.8620 - val_loss: 1.0673\n",
      "Epoch 82/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.8796 - loss: 0.3804 - val_accuracy: 0.8733 - val_loss: 1.0481\n",
      "Epoch 83/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 744us/step - accuracy: 0.8868 - loss: 0.3523 - val_accuracy: 0.8720 - val_loss: 1.0031\n",
      "Epoch 84/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 725us/step - accuracy: 0.8848 - loss: 0.3644 - val_accuracy: 0.8767 - val_loss: 0.9756\n",
      "Epoch 85/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.8744 - loss: 0.3774 - val_accuracy: 0.8780 - val_loss: 1.1223\n",
      "Epoch 86/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.8891 - loss: 0.3602 - val_accuracy: 0.8667 - val_loss: 1.1000\n",
      "Epoch 87/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8866 - loss: 0.3574 - val_accuracy: 0.8660 - val_loss: 1.1004\n",
      "Epoch 88/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8915 - loss: 0.3361 - val_accuracy: 0.8780 - val_loss: 1.0829\n",
      "Epoch 89/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 814us/step - accuracy: 0.8860 - loss: 0.3640 - val_accuracy: 0.8700 - val_loss: 1.4442\n",
      "Epoch 90/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.8674 - loss: 0.4208 - val_accuracy: 0.8727 - val_loss: 1.0795\n",
      "Epoch 91/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.8663 - loss: 0.3975 - val_accuracy: 0.8780 - val_loss: 1.0541\n",
      "Epoch 92/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.8851 - loss: 0.3705 - val_accuracy: 0.8680 - val_loss: 1.1667\n",
      "Epoch 93/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.8770 - loss: 0.3779 - val_accuracy: 0.8660 - val_loss: 1.1756\n",
      "Epoch 94/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.8826 - loss: 0.3592 - val_accuracy: 0.8807 - val_loss: 1.1282\n",
      "Epoch 95/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.8863 - loss: 0.3580 - val_accuracy: 0.8760 - val_loss: 1.1536\n",
      "Epoch 96/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.8902 - loss: 0.3423 - val_accuracy: 0.8713 - val_loss: 1.2350\n",
      "Epoch 97/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8903 - loss: 0.3932 - val_accuracy: 0.8747 - val_loss: 1.3571\n",
      "Epoch 98/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 811us/step - accuracy: 0.8633 - loss: 0.4689 - val_accuracy: 0.8487 - val_loss: 1.3610\n",
      "Epoch 99/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.8690 - loss: 0.4223 - val_accuracy: 0.8827 - val_loss: 1.2207\n",
      "Epoch 100/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.8884 - loss: 0.3452 - val_accuracy: 0.8793 - val_loss: 1.2699\n",
      "Epoch 101/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 760us/step - accuracy: 0.8815 - loss: 0.3653 - val_accuracy: 0.8820 - val_loss: 1.1908\n",
      "Epoch 102/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.8831 - loss: 0.3641 - val_accuracy: 0.8727 - val_loss: 1.2117\n",
      "Epoch 103/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8827 - loss: 0.3632 - val_accuracy: 0.8813 - val_loss: 1.1574\n",
      "Epoch 104/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.8751 - loss: 0.4029 - val_accuracy: 0.8840 - val_loss: 1.2652\n",
      "Epoch 105/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8819 - loss: 0.3643 - val_accuracy: 0.8840 - val_loss: 1.2242\n",
      "Epoch 106/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.8879 - loss: 0.3423 - val_accuracy: 0.8647 - val_loss: 1.3755\n",
      "Epoch 107/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.8911 - loss: 0.3375 - val_accuracy: 0.8820 - val_loss: 1.2338\n",
      "Epoch 108/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.8811 - loss: 0.3708 - val_accuracy: 0.8760 - val_loss: 1.2416\n",
      "Epoch 109/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8905 - loss: 0.3364 - val_accuracy: 0.8787 - val_loss: 1.2574\n",
      "Epoch 110/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.8814 - loss: 0.3592 - val_accuracy: 0.8613 - val_loss: 1.3828\n",
      "Epoch 111/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.8787 - loss: 0.3994 - val_accuracy: 0.8800 - val_loss: 1.2887\n",
      "Epoch 112/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.8881 - loss: 0.3416 - val_accuracy: 0.8893 - val_loss: 1.2314\n",
      "Epoch 113/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8860 - loss: 0.3631 - val_accuracy: 0.8827 - val_loss: 1.4529\n",
      "Epoch 114/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.3902 - val_accuracy: 0.8713 - val_loss: 1.6279\n",
      "Epoch 115/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.8828 - loss: 0.3971 - val_accuracy: 0.8707 - val_loss: 1.8831\n",
      "Epoch 116/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 730us/step - accuracy: 0.8751 - loss: 0.4232 - val_accuracy: 0.8680 - val_loss: 1.7459\n",
      "Epoch 117/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.8832 - loss: 0.3693 - val_accuracy: 0.8820 - val_loss: 1.7133\n",
      "Epoch 118/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.8945 - loss: 0.3299 - val_accuracy: 0.8713 - val_loss: 1.7188\n",
      "Epoch 119/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8857 - loss: 0.3613 - val_accuracy: 0.8813 - val_loss: 1.7794\n",
      "Epoch 120/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.8904 - loss: 0.3307 - val_accuracy: 0.8853 - val_loss: 1.7376\n",
      "Epoch 121/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.8952 - loss: 0.3288 - val_accuracy: 0.8867 - val_loss: 1.8106\n",
      "Epoch 122/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8872 - loss: 0.3386 - val_accuracy: 0.8787 - val_loss: 1.7709\n",
      "Epoch 123/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.8411 - loss: 0.5518 - val_accuracy: 0.8787 - val_loss: 1.8652\n",
      "Epoch 124/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 742us/step - accuracy: 0.8825 - loss: 0.3663 - val_accuracy: 0.8780 - val_loss: 1.9507\n",
      "Epoch 125/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8866 - loss: 0.3517 - val_accuracy: 0.8813 - val_loss: 1.7793\n",
      "Epoch 126/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.8916 - loss: 0.3377 - val_accuracy: 0.8827 - val_loss: 1.7711\n",
      "Epoch 127/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.8892 - loss: 0.3439 - val_accuracy: 0.8793 - val_loss: 1.8535\n",
      "Epoch 128/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.8938 - loss: 0.3144 - val_accuracy: 0.8773 - val_loss: 1.8140\n",
      "Epoch 129/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 766us/step - accuracy: 0.8955 - loss: 0.3120 - val_accuracy: 0.8780 - val_loss: 1.8041\n",
      "Epoch 130/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 770us/step - accuracy: 0.8875 - loss: 0.3473 - val_accuracy: 0.8867 - val_loss: 1.8542\n",
      "Epoch 131/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.8952 - loss: 0.3268 - val_accuracy: 0.8827 - val_loss: 1.9242\n",
      "Epoch 132/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.8936 - loss: 0.3207 - val_accuracy: 0.8860 - val_loss: 1.9073\n",
      "Epoch 133/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.8898 - loss: 0.3605 - val_accuracy: 0.8813 - val_loss: 1.8622\n",
      "Epoch 134/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 808us/step - accuracy: 0.8873 - loss: 0.3484 - val_accuracy: 0.8900 - val_loss: 1.8691\n",
      "Epoch 135/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 789us/step - accuracy: 0.8852 - loss: 0.3598 - val_accuracy: 0.8747 - val_loss: 2.1124\n",
      "Epoch 136/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 915us/step - accuracy: 0.8878 - loss: 0.3395 - val_accuracy: 0.8887 - val_loss: 2.0409\n",
      "Epoch 137/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.8932 - loss: 0.3297 - val_accuracy: 0.8740 - val_loss: 2.0330\n",
      "Epoch 138/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.8832 - loss: 0.3390 - val_accuracy: 0.7787 - val_loss: 2.3621\n",
      "Epoch 139/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8627 - loss: 0.4128 - val_accuracy: 0.8847 - val_loss: 2.2664\n",
      "Epoch 140/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.8741 - loss: 0.4050 - val_accuracy: 0.8900 - val_loss: 2.2143\n",
      "Epoch 141/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 777us/step - accuracy: 0.8825 - loss: 0.3773 - val_accuracy: 0.8867 - val_loss: 2.2793\n",
      "Epoch 142/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 746us/step - accuracy: 0.8813 - loss: 0.3717 - val_accuracy: 0.8700 - val_loss: 2.1284\n",
      "Epoch 143/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.8781 - loss: 0.3443 - val_accuracy: 0.8793 - val_loss: 2.1593\n",
      "Epoch 144/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.8783 - loss: 0.3715 - val_accuracy: 0.8920 - val_loss: 2.0430\n",
      "Epoch 145/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.8828 - loss: 0.3686 - val_accuracy: 0.8840 - val_loss: 2.1030\n",
      "Epoch 146/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 799us/step - accuracy: 0.8905 - loss: 0.3309 - val_accuracy: 0.8853 - val_loss: 2.1470\n",
      "Epoch 147/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.8905 - loss: 0.3302 - val_accuracy: 0.8800 - val_loss: 2.0489\n",
      "Epoch 148/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 945us/step - accuracy: 0.8893 - loss: 0.3263 - val_accuracy: 0.8893 - val_loss: 2.0462\n",
      "Epoch 149/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 800us/step - accuracy: 0.8923 - loss: 0.3246 - val_accuracy: 0.8820 - val_loss: 2.0951\n",
      "Epoch 150/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.8843 - loss: 0.3431 - val_accuracy: 0.8727 - val_loss: 2.1092\n",
      "Epoch 151/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.8924 - loss: 0.3284 - val_accuracy: 0.8847 - val_loss: 2.1263\n",
      "Epoch 152/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.8820 - loss: 0.3534 - val_accuracy: 0.8873 - val_loss: 2.1346\n",
      "Epoch 153/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 778us/step - accuracy: 0.8918 - loss: 0.3216 - val_accuracy: 0.8893 - val_loss: 2.0835\n",
      "Epoch 154/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 750us/step - accuracy: 0.8827 - loss: 0.3393 - val_accuracy: 0.8767 - val_loss: 2.1778\n",
      "Epoch 155/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.8533 - loss: 0.5118 - val_accuracy: 0.8907 - val_loss: 2.1873\n",
      "Epoch 156/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.8919 - loss: 0.3291 - val_accuracy: 0.8893 - val_loss: 2.2064\n",
      "Epoch 157/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8844 - loss: 0.3437 - val_accuracy: 0.8787 - val_loss: 2.3304\n",
      "Epoch 158/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.8874 - loss: 0.3503 - val_accuracy: 0.8900 - val_loss: 2.6884\n",
      "Epoch 159/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8824 - loss: 0.3813 - val_accuracy: 0.8813 - val_loss: 2.2576\n",
      "Epoch 160/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8852 - loss: 0.3400 - val_accuracy: 0.8860 - val_loss: 2.1034\n",
      "Epoch 161/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.8825 - loss: 0.3596 - val_accuracy: 0.8860 - val_loss: 2.1266\n",
      "Epoch 162/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.8824 - loss: 0.3527 - val_accuracy: 0.8887 - val_loss: 1.9900\n",
      "Epoch 163/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 784us/step - accuracy: 0.8870 - loss: 0.3414 - val_accuracy: 0.8867 - val_loss: 2.0310\n",
      "Epoch 164/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8827 - loss: 0.3505 - val_accuracy: 0.8867 - val_loss: 2.1071\n",
      "Epoch 165/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.8934 - loss: 0.3362 - val_accuracy: 0.8920 - val_loss: 2.0911\n",
      "Epoch 166/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.8901 - loss: 0.3415 - val_accuracy: 0.8880 - val_loss: 2.1501\n",
      "Epoch 167/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 922us/step - accuracy: 0.8905 - loss: 0.3313 - val_accuracy: 0.8800 - val_loss: 2.1832\n",
      "Epoch 168/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8693 - loss: 0.4448 - val_accuracy: 0.8880 - val_loss: 2.1805\n",
      "Epoch 169/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 900us/step - accuracy: 0.8913 - loss: 0.3358 - val_accuracy: 0.8907 - val_loss: 2.0403\n",
      "Epoch 170/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 861us/step - accuracy: 0.8926 - loss: 0.3376 - val_accuracy: 0.8900 - val_loss: 2.1346\n",
      "Epoch 171/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8875 - loss: 0.3381 - val_accuracy: 0.8900 - val_loss: 2.2434\n",
      "Epoch 172/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.8829 - loss: 0.3416 - val_accuracy: 0.8907 - val_loss: 2.2462\n",
      "Epoch 173/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.8922 - loss: 0.3249 - val_accuracy: 0.8927 - val_loss: 2.2014\n",
      "Epoch 174/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.8890 - loss: 0.3406 - val_accuracy: 0.8873 - val_loss: 2.2070\n",
      "Epoch 175/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.8974 - loss: 0.3091 - val_accuracy: 0.8900 - val_loss: 2.2270\n",
      "Epoch 176/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.8942 - loss: 0.3283 - val_accuracy: 0.8887 - val_loss: 2.2350\n",
      "Epoch 177/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8867 - loss: 0.3393 - val_accuracy: 0.8880 - val_loss: 2.3562\n",
      "Epoch 178/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8828 - loss: 0.3598 - val_accuracy: 0.8927 - val_loss: 2.3573\n",
      "Epoch 179/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.8948 - loss: 0.3411 - val_accuracy: 0.8880 - val_loss: 2.1511\n",
      "Epoch 180/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.8831 - loss: 0.3590 - val_accuracy: 0.8873 - val_loss: 2.0710\n",
      "Epoch 181/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 759us/step - accuracy: 0.8873 - loss: 0.3444 - val_accuracy: 0.8920 - val_loss: 2.1088\n",
      "Epoch 182/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 973us/step - accuracy: 0.8810 - loss: 0.3651 - val_accuracy: 0.8667 - val_loss: 2.2904\n",
      "Epoch 183/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 863us/step - accuracy: 0.8816 - loss: 0.3956 - val_accuracy: 0.8980 - val_loss: 2.0579\n",
      "Epoch 184/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.8877 - loss: 0.3357 - val_accuracy: 0.8913 - val_loss: 2.1286\n",
      "Epoch 185/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.8912 - loss: 0.3336 - val_accuracy: 0.8907 - val_loss: 2.1176\n",
      "Epoch 186/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 805us/step - accuracy: 0.8831 - loss: 0.3492 - val_accuracy: 0.8873 - val_loss: 2.1680\n",
      "Epoch 187/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 802us/step - accuracy: 0.8771 - loss: 0.3731 - val_accuracy: 0.8813 - val_loss: 2.3434\n",
      "Epoch 188/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.8910 - loss: 0.3288 - val_accuracy: 0.8893 - val_loss: 2.3891\n",
      "Epoch 189/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.8863 - loss: 0.3458 - val_accuracy: 0.8747 - val_loss: 2.2449\n",
      "Epoch 190/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 756us/step - accuracy: 0.8907 - loss: 0.3523 - val_accuracy: 0.8847 - val_loss: 2.0962\n",
      "Epoch 191/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.8846 - loss: 0.3549 - val_accuracy: 0.8833 - val_loss: 2.1506\n",
      "Epoch 192/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8779 - loss: 0.3563 - val_accuracy: 0.8860 - val_loss: 2.2235\n",
      "Epoch 193/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 944us/step - accuracy: 0.8894 - loss: 0.3373 - val_accuracy: 0.8920 - val_loss: 2.1665\n",
      "Epoch 194/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8928 - loss: 0.3487 - val_accuracy: 0.8867 - val_loss: 2.1517\n",
      "Epoch 195/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.8947 - loss: 0.3240 - val_accuracy: 0.8887 - val_loss: 2.2125\n",
      "Epoch 196/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.9006 - loss: 0.3007 - val_accuracy: 0.8840 - val_loss: 2.2460\n",
      "Epoch 197/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 771us/step - accuracy: 0.8878 - loss: 0.3651 - val_accuracy: 0.8953 - val_loss: 2.3143\n",
      "Epoch 198/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 765us/step - accuracy: 0.8869 - loss: 0.3542 - val_accuracy: 0.8793 - val_loss: 2.1979\n",
      "Epoch 199/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 786us/step - accuracy: 0.8766 - loss: 0.4555 - val_accuracy: 0.8820 - val_loss: 2.4519\n",
      "Epoch 200/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.8893 - loss: 0.3343 - val_accuracy: 0.8760 - val_loss: 2.5682\n",
      "Epoch 201/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 905us/step - accuracy: 0.8864 - loss: 0.3594 - val_accuracy: 0.8793 - val_loss: 2.4656\n",
      "Epoch 202/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.8957 - loss: 0.3146 - val_accuracy: 0.8840 - val_loss: 2.3063\n",
      "Epoch 203/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 782us/step - accuracy: 0.8885 - loss: 0.3334 - val_accuracy: 0.8947 - val_loss: 2.3718\n",
      "Epoch 204/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 931us/step - accuracy: 0.8973 - loss: 0.3158 - val_accuracy: 0.8853 - val_loss: 2.3508\n",
      "Epoch 205/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.8927 - loss: 0.3264 - val_accuracy: 0.8687 - val_loss: 2.4596\n",
      "Epoch 206/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 831us/step - accuracy: 0.8849 - loss: 0.3568 - val_accuracy: 0.8933 - val_loss: 2.2919\n",
      "Epoch 207/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.8845 - loss: 0.4614 - val_accuracy: 0.8540 - val_loss: 3.3677\n",
      "Epoch 208/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.8557 - loss: 0.5129 - val_accuracy: 0.8727 - val_loss: 2.9629\n",
      "Epoch 209/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.8762 - loss: 0.4794 - val_accuracy: 0.8627 - val_loss: 2.0003\n",
      "Epoch 210/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8758 - loss: 0.4361 - val_accuracy: 0.8900 - val_loss: 1.6760\n",
      "Epoch 211/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.8807 - loss: 0.3730 - val_accuracy: 0.8873 - val_loss: 1.3084\n",
      "Epoch 212/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 934us/step - accuracy: 0.8921 - loss: 0.3408 - val_accuracy: 0.8800 - val_loss: 1.4735\n",
      "Epoch 213/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.8694 - loss: 0.4125 - val_accuracy: 0.8833 - val_loss: 1.4009\n",
      "Epoch 214/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 807us/step - accuracy: 0.8909 - loss: 0.3418 - val_accuracy: 0.8847 - val_loss: 1.4432\n",
      "Epoch 215/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.8884 - loss: 0.3372 - val_accuracy: 0.8793 - val_loss: 1.4258\n",
      "Epoch 216/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.8809 - loss: 0.3592 - val_accuracy: 0.8880 - val_loss: 1.5513\n",
      "Epoch 217/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 783us/step - accuracy: 0.8864 - loss: 0.3500 - val_accuracy: 0.8773 - val_loss: 1.4059\n",
      "Epoch 218/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 780us/step - accuracy: 0.8868 - loss: 0.3510 - val_accuracy: 0.8853 - val_loss: 1.4107\n",
      "Epoch 219/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.8869 - loss: 0.3467 - val_accuracy: 0.8820 - val_loss: 1.4663\n",
      "Epoch 220/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 842us/step - accuracy: 0.8753 - loss: 0.3777 - val_accuracy: 0.8833 - val_loss: 1.4014\n",
      "Epoch 221/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.8906 - loss: 0.3426 - val_accuracy: 0.8753 - val_loss: 1.4570\n",
      "Epoch 222/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 819us/step - accuracy: 0.8913 - loss: 0.3350 - val_accuracy: 0.8893 - val_loss: 1.4081\n",
      "Epoch 223/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.8870 - loss: 0.3432 - val_accuracy: 0.8740 - val_loss: 1.4474\n",
      "Epoch 224/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 793us/step - accuracy: 0.8878 - loss: 0.3381 - val_accuracy: 0.8787 - val_loss: 1.5011\n",
      "Epoch 225/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.8835 - loss: 0.3584 - val_accuracy: 0.8827 - val_loss: 1.4433\n",
      "Epoch 226/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8900 - loss: 0.3486 - val_accuracy: 0.8860 - val_loss: 1.4420\n",
      "Epoch 227/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 947us/step - accuracy: 0.8828 - loss: 0.3509 - val_accuracy: 0.8860 - val_loss: 1.4302\n",
      "Epoch 228/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 806us/step - accuracy: 0.8884 - loss: 0.3426 - val_accuracy: 0.8827 - val_loss: 1.5772\n",
      "Epoch 229/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 768us/step - accuracy: 0.8931 - loss: 0.3278 - val_accuracy: 0.8873 - val_loss: 1.6118\n",
      "Epoch 230/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.8682 - loss: 0.3879 - val_accuracy: 0.8840 - val_loss: 1.6368\n",
      "Epoch 231/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 798us/step - accuracy: 0.8893 - loss: 0.3390 - val_accuracy: 0.8753 - val_loss: 1.6233\n",
      "Epoch 232/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.8772 - loss: 0.3498 - val_accuracy: 0.8807 - val_loss: 1.6084\n",
      "Epoch 233/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.8873 - loss: 0.3417 - val_accuracy: 0.8820 - val_loss: 1.6855\n",
      "Epoch 234/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.8897 - loss: 0.3569 - val_accuracy: 0.8867 - val_loss: 1.4012\n",
      "Epoch 235/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 792us/step - accuracy: 0.8824 - loss: 0.3659 - val_accuracy: 0.8807 - val_loss: 1.3951\n",
      "Epoch 236/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.8749 - loss: 0.3529 - val_accuracy: 0.8727 - val_loss: 1.5404\n",
      "Epoch 237/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.8880 - loss: 0.3752 - val_accuracy: 0.8713 - val_loss: 1.5647\n",
      "Epoch 238/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.8878 - loss: 0.3503 - val_accuracy: 0.8853 - val_loss: 1.5729\n",
      "Epoch 239/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.8857 - loss: 0.3562 - val_accuracy: 0.8893 - val_loss: 1.7095\n",
      "Epoch 240/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8828 - loss: 0.3710 - val_accuracy: 0.8113 - val_loss: 1.9177\n",
      "Epoch 241/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.8750 - loss: 0.3693 - val_accuracy: 0.8900 - val_loss: 1.8400\n",
      "Epoch 242/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8856 - loss: 0.3526 - val_accuracy: 0.8860 - val_loss: 1.7322\n",
      "Epoch 243/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.8875 - loss: 0.3426 - val_accuracy: 0.8893 - val_loss: 1.8215\n",
      "Epoch 244/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.8913 - loss: 0.3359 - val_accuracy: 0.8887 - val_loss: 1.8081\n",
      "Epoch 245/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.8805 - loss: 0.3675 - val_accuracy: 0.8820 - val_loss: 1.8355\n",
      "Epoch 246/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 796us/step - accuracy: 0.8857 - loss: 0.3417 - val_accuracy: 0.8967 - val_loss: 1.7455\n",
      "Epoch 247/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 820us/step - accuracy: 0.8893 - loss: 0.3629 - val_accuracy: 0.8940 - val_loss: 1.6880\n",
      "Epoch 248/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.8848 - loss: 0.3538 - val_accuracy: 0.8853 - val_loss: 1.7339\n",
      "Epoch 249/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 795us/step - accuracy: 0.8909 - loss: 0.3365 - val_accuracy: 0.8427 - val_loss: 1.8510\n",
      "Epoch 250/250\n",
      "\u001b[1m70/70\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 767us/step - accuracy: 0.8581 - loss: 0.4755 - val_accuracy: 0.8907 - val_loss: 1.7606\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377us/step - accuracy: 0.8854 - loss: 0.7500\n",
      "Test Loss: 0.798322856426239, Test Accuracy: 0.8820000290870667\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load and preprocess data\n",
    "sample = pd.read_csv(\"data/newSample.csv\")\n",
    "data = sample.drop(columns=['start_date', 'start_time', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "x = data.drop(columns=['IoTMac'])\n",
    "y = data['IoTMac']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(x)\n",
    "\n",
    "# Encode the target variable (y) for multi-class classification\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y_encoded, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the ANN model for multi-class classification\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Nadam(learning_rate=0.015), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=25, min_lr=1e-6, verbose=1)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=250, batch_size=100)\n",
    "                    # , callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Train the model\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=64, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.3583 - loss: 3.4384 - val_accuracy: 0.5753 - val_loss: 2.1426 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.5787 - loss: 2.0821 - val_accuracy: 0.5913 - val_loss: 1.8145 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.5929 - loss: 1.7660 - val_accuracy: 0.5920 - val_loss: 1.6566 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 680us/step - accuracy: 0.5927 - loss: 1.6463 - val_accuracy: 0.5973 - val_loss: 1.5530 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 674us/step - accuracy: 0.5941 - loss: 1.5552 - val_accuracy: 0.5920 - val_loss: 1.4987 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.5918 - loss: 1.5034 - val_accuracy: 0.6027 - val_loss: 1.4559 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.5891 - loss: 1.4827 - val_accuracy: 0.6033 - val_loss: 1.4294 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.5944 - loss: 1.4400 - val_accuracy: 0.6027 - val_loss: 1.4029 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.6004 - loss: 1.4040 - val_accuracy: 0.6173 - val_loss: 1.3887 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 706us/step - accuracy: 0.6049 - loss: 1.3983 - val_accuracy: 0.6087 - val_loss: 1.3688 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 687us/step - accuracy: 0.5997 - loss: 1.3792 - val_accuracy: 0.6027 - val_loss: 1.3563 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 693us/step - accuracy: 0.6002 - loss: 1.3682 - val_accuracy: 0.6040 - val_loss: 1.3407 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 671us/step - accuracy: 0.6006 - loss: 1.3659 - val_accuracy: 0.6187 - val_loss: 1.3383 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.6054 - loss: 1.3530 - val_accuracy: 0.6293 - val_loss: 1.3230 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 651us/step - accuracy: 0.6101 - loss: 1.3314 - val_accuracy: 0.6213 - val_loss: 1.3174 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6208 - loss: 1.3258 - val_accuracy: 0.6153 - val_loss: 1.3147 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.6120 - loss: 1.3229 - val_accuracy: 0.6113 - val_loss: 1.3045 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 618us/step - accuracy: 0.5997 - loss: 1.3285 - val_accuracy: 0.6253 - val_loss: 1.3059 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 625us/step - accuracy: 0.6152 - loss: 1.3147 - val_accuracy: 0.6267 - val_loss: 1.2974 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 654us/step - accuracy: 0.6147 - loss: 1.3123 - val_accuracy: 0.6287 - val_loss: 1.2918 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 645us/step - accuracy: 0.6187 - loss: 1.2970 - val_accuracy: 0.6173 - val_loss: 1.2823 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 631us/step - accuracy: 0.6111 - loss: 1.3206 - val_accuracy: 0.6333 - val_loss: 1.2851 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 735us/step - accuracy: 0.6287 - loss: 1.2797 - val_accuracy: 0.6180 - val_loss: 1.2866 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 635us/step - accuracy: 0.6224 - loss: 1.2878 - val_accuracy: 0.6400 - val_loss: 1.2703 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.6252 - loss: 1.2839 - val_accuracy: 0.6287 - val_loss: 1.2662 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 682us/step - accuracy: 0.6285 - loss: 1.2712 - val_accuracy: 0.6400 - val_loss: 1.2676 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 758us/step - accuracy: 0.6401 - loss: 1.2404 - val_accuracy: 0.6400 - val_loss: 1.2579 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 700us/step - accuracy: 0.6366 - loss: 1.2419 - val_accuracy: 0.6233 - val_loss: 1.2590 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.6361 - loss: 1.2560 - val_accuracy: 0.6220 - val_loss: 1.2590 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.6289 - loss: 1.2609 - val_accuracy: 0.6267 - val_loss: 1.2527 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 637us/step - accuracy: 0.6324 - loss: 1.2545 - val_accuracy: 0.6307 - val_loss: 1.2495 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.6276 - loss: 1.2592 - val_accuracy: 0.6507 - val_loss: 1.2336 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 755us/step - accuracy: 0.6419 - loss: 1.2389 - val_accuracy: 0.6440 - val_loss: 1.2323 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 662us/step - accuracy: 0.6368 - loss: 1.2434 - val_accuracy: 0.6380 - val_loss: 1.2356 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.6393 - loss: 1.2296 - val_accuracy: 0.6320 - val_loss: 1.2307 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.6321 - loss: 1.2414 - val_accuracy: 0.6513 - val_loss: 1.2211 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 733us/step - accuracy: 0.6509 - loss: 1.2120 - val_accuracy: 0.6473 - val_loss: 1.2229 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 803us/step - accuracy: 0.6431 - loss: 1.2116 - val_accuracy: 0.6467 - val_loss: 1.2239 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 714us/step - accuracy: 0.6423 - loss: 1.2051 - val_accuracy: 0.6467 - val_loss: 1.2148 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.6340 - loss: 1.2434 - val_accuracy: 0.6500 - val_loss: 1.2088 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.6387 - loss: 1.2247 - val_accuracy: 0.6480 - val_loss: 1.2055 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.6455 - loss: 1.2199 - val_accuracy: 0.6520 - val_loss: 1.2043 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.6437 - loss: 1.2085 - val_accuracy: 0.6480 - val_loss: 1.2110 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 667us/step - accuracy: 0.6449 - loss: 1.2187 - val_accuracy: 0.6473 - val_loss: 1.2016 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.6640 - loss: 1.1762 - val_accuracy: 0.6793 - val_loss: 1.1901 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 666us/step - accuracy: 0.6578 - loss: 1.1899 - val_accuracy: 0.6293 - val_loss: 1.1912 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 660us/step - accuracy: 0.6498 - loss: 1.2028 - val_accuracy: 0.6453 - val_loss: 1.1905 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 679us/step - accuracy: 0.6464 - loss: 1.2207 - val_accuracy: 0.6460 - val_loss: 1.1990 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 952us/step - accuracy: 0.6745 - loss: 1.1801 - val_accuracy: 0.6533 - val_loss: 1.1777 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 642us/step - accuracy: 0.6524 - loss: 1.1778 - val_accuracy: 0.6880 - val_loss: 1.1825 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.6605 - loss: 1.1804 - val_accuracy: 0.6880 - val_loss: 1.1807 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 677us/step - accuracy: 0.6682 - loss: 1.1613 - val_accuracy: 0.7007 - val_loss: 1.1704 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.6689 - loss: 1.1851 - val_accuracy: 0.6693 - val_loss: 1.1685 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.6794 - loss: 1.1585 - val_accuracy: 0.6720 - val_loss: 1.1614 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.6824 - loss: 1.1524 - val_accuracy: 0.7027 - val_loss: 1.1753 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 670us/step - accuracy: 0.6765 - loss: 1.1646 - val_accuracy: 0.7173 - val_loss: 1.1592 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 681us/step - accuracy: 0.6849 - loss: 1.1514 - val_accuracy: 0.6733 - val_loss: 1.1465 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 702us/step - accuracy: 0.6815 - loss: 1.1486 - val_accuracy: 0.6960 - val_loss: 1.1482 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 675us/step - accuracy: 0.6867 - loss: 1.1715 - val_accuracy: 0.7187 - val_loss: 1.1491 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.6949 - loss: 1.1400 - val_accuracy: 0.7020 - val_loss: 1.1392 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.6813 - loss: 1.1443 - val_accuracy: 0.6933 - val_loss: 1.1361 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932us/step - accuracy: 0.6936 - loss: 1.1410 - val_accuracy: 0.7033 - val_loss: 1.1377 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 801us/step - accuracy: 0.6945 - loss: 1.1265 - val_accuracy: 0.7233 - val_loss: 1.1342 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 751us/step - accuracy: 0.6982 - loss: 1.1478 - val_accuracy: 0.7160 - val_loss: 1.1351 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 752us/step - accuracy: 0.6928 - loss: 1.1481 - val_accuracy: 0.7187 - val_loss: 1.1407 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 745us/step - accuracy: 0.6954 - loss: 1.1273 - val_accuracy: 0.6873 - val_loss: 1.1309 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.6943 - loss: 1.1266 - val_accuracy: 0.6980 - val_loss: 1.1288 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 704us/step - accuracy: 0.6998 - loss: 1.1203 - val_accuracy: 0.7240 - val_loss: 1.1213 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7036 - loss: 1.1091 - val_accuracy: 0.7047 - val_loss: 1.1390 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 720us/step - accuracy: 0.6971 - loss: 1.1152 - val_accuracy: 0.7207 - val_loss: 1.1275 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 791us/step - accuracy: 0.7000 - loss: 1.1220 - val_accuracy: 0.7160 - val_loss: 1.1167 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.6983 - loss: 1.1115 - val_accuracy: 0.7060 - val_loss: 1.1129 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.6904 - loss: 1.1208 - val_accuracy: 0.7087 - val_loss: 1.1209 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7052 - loss: 1.1015 - val_accuracy: 0.7080 - val_loss: 1.1222 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 691us/step - accuracy: 0.7018 - loss: 1.1033 - val_accuracy: 0.7093 - val_loss: 1.1235 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 817us/step - accuracy: 0.6974 - loss: 1.1008 - val_accuracy: 0.7187 - val_loss: 1.1034 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7020 - loss: 1.0917 - val_accuracy: 0.7267 - val_loss: 1.1003 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 788us/step - accuracy: 0.7075 - loss: 1.0950 - val_accuracy: 0.7233 - val_loss: 1.1018 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 743us/step - accuracy: 0.6949 - loss: 1.1047 - val_accuracy: 0.7313 - val_loss: 1.0988 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 787us/step - accuracy: 0.6987 - loss: 1.1032 - val_accuracy: 0.7240 - val_loss: 1.0882 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 708us/step - accuracy: 0.7019 - loss: 1.1052 - val_accuracy: 0.7060 - val_loss: 1.0970 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 847us/step - accuracy: 0.7033 - loss: 1.1002 - val_accuracy: 0.7233 - val_loss: 1.1129 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 684us/step - accuracy: 0.6915 - loss: 1.1032 - val_accuracy: 0.7207 - val_loss: 1.0947 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 779us/step - accuracy: 0.6947 - loss: 1.1065 - val_accuracy: 0.7207 - val_loss: 1.0888 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 701us/step - accuracy: 0.7007 - loss: 1.0974 - val_accuracy: 0.7160 - val_loss: 1.0885 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 794us/step - accuracy: 0.7044 - loss: 1.0747 - val_accuracy: 0.7147 - val_loss: 1.0863 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 707us/step - accuracy: 0.6991 - loss: 1.0847 - val_accuracy: 0.7127 - val_loss: 1.0803 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 940us/step - accuracy: 0.6978 - loss: 1.0843 - val_accuracy: 0.7140 - val_loss: 1.0851 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 689us/step - accuracy: 0.7054 - loss: 1.0727 - val_accuracy: 0.7220 - val_loss: 1.0810 - learning_rate: 0.0010\n",
      "Epoch 90/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 688us/step - accuracy: 0.7109 - loss: 1.0652 - val_accuracy: 0.7187 - val_loss: 1.0862 - learning_rate: 0.0010\n",
      "Epoch 91/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 697us/step - accuracy: 0.7107 - loss: 1.0619 - val_accuracy: 0.7207 - val_loss: 1.0808 - learning_rate: 0.0010\n",
      "Epoch 92/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 647us/step - accuracy: 0.7037 - loss: 1.0794 - val_accuracy: 0.7053 - val_loss: 1.0856 - learning_rate: 0.0010\n",
      "Epoch 93/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.7053 - loss: 1.0581 - val_accuracy: 0.7227 - val_loss: 1.0679 - learning_rate: 0.0010\n",
      "Epoch 94/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 757us/step - accuracy: 0.7058 - loss: 1.0606 - val_accuracy: 0.7267 - val_loss: 1.0733 - learning_rate: 0.0010\n",
      "Epoch 95/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 640us/step - accuracy: 0.6977 - loss: 1.1102 - val_accuracy: 0.7000 - val_loss: 1.0724 - learning_rate: 0.0010\n",
      "Epoch 96/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 658us/step - accuracy: 0.6928 - loss: 1.0955 - val_accuracy: 0.7220 - val_loss: 1.0755 - learning_rate: 0.0010\n",
      "Epoch 97/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 716us/step - accuracy: 0.7082 - loss: 1.0587 - val_accuracy: 0.7260 - val_loss: 1.0736 - learning_rate: 0.0010\n",
      "Epoch 98/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 764us/step - accuracy: 0.7113 - loss: 1.0516 - val_accuracy: 0.7073 - val_loss: 1.0717 - learning_rate: 0.0010\n",
      "Epoch 99/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 695us/step - accuracy: 0.7081 - loss: 1.0547 - val_accuracy: 0.7240 - val_loss: 1.0613 - learning_rate: 0.0010\n",
      "Epoch 100/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 774us/step - accuracy: 0.7115 - loss: 1.0402 - val_accuracy: 0.7167 - val_loss: 1.0667 - learning_rate: 0.0010\n",
      "Epoch 101/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 676us/step - accuracy: 0.6997 - loss: 1.0519 - val_accuracy: 0.7193 - val_loss: 1.0579 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 711us/step - accuracy: 0.7011 - loss: 1.0573 - val_accuracy: 0.7147 - val_loss: 1.0822 - learning_rate: 0.0010\n",
      "Epoch 103/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 724us/step - accuracy: 0.7065 - loss: 1.0497 - val_accuracy: 0.7173 - val_loss: 1.0567 - learning_rate: 0.0010\n",
      "Epoch 104/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 753us/step - accuracy: 0.7144 - loss: 1.0264 - val_accuracy: 0.7313 - val_loss: 1.0505 - learning_rate: 0.0010\n",
      "Epoch 105/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 980us/step - accuracy: 0.7093 - loss: 1.0565 - val_accuracy: 0.7167 - val_loss: 1.0705 - learning_rate: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 729us/step - accuracy: 0.7188 - loss: 1.0365 - val_accuracy: 0.7200 - val_loss: 1.0472 - learning_rate: 0.0010\n",
      "Epoch 107/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 665us/step - accuracy: 0.7119 - loss: 1.0517 - val_accuracy: 0.7127 - val_loss: 1.0496 - learning_rate: 0.0010\n",
      "Epoch 108/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 763us/step - accuracy: 0.7078 - loss: 1.0405 - val_accuracy: 0.7227 - val_loss: 1.0663 - learning_rate: 0.0010\n",
      "Epoch 109/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.7102 - loss: 1.0413 - val_accuracy: 0.7113 - val_loss: 1.0487 - learning_rate: 0.0010\n",
      "Epoch 110/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 772us/step - accuracy: 0.6874 - loss: 1.0665 - val_accuracy: 0.7167 - val_loss: 1.0658 - learning_rate: 0.0010\n",
      "Epoch 111/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 630us/step - accuracy: 0.7067 - loss: 1.0381 - val_accuracy: 0.7247 - val_loss: 1.0616 - learning_rate: 0.0010\n",
      "Epoch 112/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 690us/step - accuracy: 0.7163 - loss: 1.0217 - val_accuracy: 0.7220 - val_loss: 1.0548 - learning_rate: 0.0010\n",
      "Epoch 113/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 717us/step - accuracy: 0.7058 - loss: 1.0297 - val_accuracy: 0.7247 - val_loss: 1.0517 - learning_rate: 0.0010\n",
      "Epoch 114/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 773us/step - accuracy: 0.7190 - loss: 1.0118 - val_accuracy: 0.7207 - val_loss: 1.0553 - learning_rate: 0.0010\n",
      "Epoch 115/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 718us/step - accuracy: 0.7083 - loss: 1.0414 - val_accuracy: 0.7213 - val_loss: 1.0527 - learning_rate: 0.0010\n",
      "Epoch 116/200\n",
      "\u001b[1m 99/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 540us/step - accuracy: 0.7044 - loss: 1.0543\n",
      "Epoch 116: ReduceLROnPlateau reducing learning rate to 0.0009000000427477062.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 754us/step - accuracy: 0.7050 - loss: 1.0514 - val_accuracy: 0.7200 - val_loss: 1.0606 - learning_rate: 0.0010\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 373us/step - accuracy: 0.6892 - loss: 1.1349\n",
      "Test Loss: 1.0896672010421753, Test Accuracy: 0.7020000219345093\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Build the ANN model for multi-class classification with regularization\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)))  # L2 regularization with a penalty factor of 0.01\n",
    "# model.add(Dropout(0.1))  # 50% dropout rate\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))  # Another L2 regularization\n",
    "# model.add(Dropout(0.5))  # Another dropout layer with a 50% dropout rate\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Nadam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and learning rate reduction to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=10, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Train the model with the callbacks\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=64, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.2153 - loss: 4.6334 - val_accuracy: 0.5540 - val_loss: 2.7474 - learning_rate: 0.0010\n",
      "Epoch 2/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.4740 - loss: 2.8625 - val_accuracy: 0.5573 - val_loss: 2.1635 - learning_rate: 0.0010\n",
      "Epoch 3/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.4937 - loss: 2.3870 - val_accuracy: 0.5607 - val_loss: 1.9261 - learning_rate: 0.0010\n",
      "Epoch 4/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 815us/step - accuracy: 0.4997 - loss: 2.1394 - val_accuracy: 0.5800 - val_loss: 1.7960 - learning_rate: 0.0010\n",
      "Epoch 5/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.5066 - loss: 2.0255 - val_accuracy: 0.5593 - val_loss: 1.7108 - learning_rate: 0.0010\n",
      "Epoch 6/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 822us/step - accuracy: 0.5183 - loss: 1.9374 - val_accuracy: 0.5793 - val_loss: 1.6629 - learning_rate: 0.0010\n",
      "Epoch 7/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.5367 - loss: 1.8484 - val_accuracy: 0.5847 - val_loss: 1.6335 - learning_rate: 0.0010\n",
      "Epoch 8/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 928us/step - accuracy: 0.5417 - loss: 1.8159 - val_accuracy: 0.5800 - val_loss: 1.6159 - learning_rate: 0.0010\n",
      "Epoch 9/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 804us/step - accuracy: 0.5382 - loss: 1.7814 - val_accuracy: 0.5847 - val_loss: 1.5934 - learning_rate: 0.0010\n",
      "Epoch 10/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.5284 - loss: 1.7990 - val_accuracy: 0.5587 - val_loss: 1.5835 - learning_rate: 0.0010\n",
      "Epoch 11/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 790us/step - accuracy: 0.5359 - loss: 1.7633 - val_accuracy: 0.5600 - val_loss: 1.5739 - learning_rate: 0.0010\n",
      "Epoch 12/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 828us/step - accuracy: 0.5429 - loss: 1.7595 - val_accuracy: 0.5660 - val_loss: 1.5625 - learning_rate: 0.0010\n",
      "Epoch 13/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.5358 - loss: 1.7660 - val_accuracy: 0.5887 - val_loss: 1.5409 - learning_rate: 0.0010\n",
      "Epoch 14/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 810us/step - accuracy: 0.5430 - loss: 1.7320 - val_accuracy: 0.5687 - val_loss: 1.5439 - learning_rate: 0.0010\n",
      "Epoch 15/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.5422 - loss: 1.6950 - val_accuracy: 0.5687 - val_loss: 1.5435 - learning_rate: 0.0010\n",
      "Epoch 16/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 880us/step - accuracy: 0.5582 - loss: 1.6684 - val_accuracy: 0.5667 - val_loss: 1.5198 - learning_rate: 0.0010\n",
      "Epoch 17/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.5450 - loss: 1.6707 - val_accuracy: 0.5953 - val_loss: 1.5179 - learning_rate: 0.0010\n",
      "Epoch 18/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.5500 - loss: 1.6618 - val_accuracy: 0.5900 - val_loss: 1.5017 - learning_rate: 0.0010\n",
      "Epoch 19/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5479 - loss: 1.6715 - val_accuracy: 0.5920 - val_loss: 1.4899 - learning_rate: 0.0010\n",
      "Epoch 20/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 970us/step - accuracy: 0.5603 - loss: 1.6328 - val_accuracy: 0.5940 - val_loss: 1.4803 - learning_rate: 0.0010\n",
      "Epoch 21/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 816us/step - accuracy: 0.5566 - loss: 1.6317 - val_accuracy: 0.5953 - val_loss: 1.4851 - learning_rate: 0.0010\n",
      "Epoch 22/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.5648 - loss: 1.6381 - val_accuracy: 0.5740 - val_loss: 1.4648 - learning_rate: 0.0010\n",
      "Epoch 23/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.5580 - loss: 1.6231 - val_accuracy: 0.5953 - val_loss: 1.4583 - learning_rate: 0.0010\n",
      "Epoch 24/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 826us/step - accuracy: 0.5622 - loss: 1.6204 - val_accuracy: 0.6107 - val_loss: 1.4553 - learning_rate: 0.0010\n",
      "Epoch 25/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 875us/step - accuracy: 0.5747 - loss: 1.5669 - val_accuracy: 0.6427 - val_loss: 1.4451 - learning_rate: 0.0010\n",
      "Epoch 26/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 834us/step - accuracy: 0.5790 - loss: 1.5760 - val_accuracy: 0.6113 - val_loss: 1.4381 - learning_rate: 0.0010\n",
      "Epoch 27/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 818us/step - accuracy: 0.5705 - loss: 1.5874 - val_accuracy: 0.6540 - val_loss: 1.4243 - learning_rate: 0.0010\n",
      "Epoch 28/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.5767 - loss: 1.5708 - val_accuracy: 0.6433 - val_loss: 1.4312 - learning_rate: 0.0010\n",
      "Epoch 29/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.5769 - loss: 1.5714 - val_accuracy: 0.6280 - val_loss: 1.4310 - learning_rate: 0.0010\n",
      "Epoch 30/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 812us/step - accuracy: 0.5772 - loss: 1.5786 - val_accuracy: 0.6447 - val_loss: 1.4090 - learning_rate: 0.0010\n",
      "Epoch 31/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 844us/step - accuracy: 0.5818 - loss: 1.5500 - val_accuracy: 0.6493 - val_loss: 1.4095 - learning_rate: 0.0010\n",
      "Epoch 32/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 873us/step - accuracy: 0.5772 - loss: 1.5786 - val_accuracy: 0.6507 - val_loss: 1.4171 - learning_rate: 0.0010\n",
      "Epoch 33/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.5874 - loss: 1.5486 - val_accuracy: 0.6467 - val_loss: 1.3986 - learning_rate: 0.0010\n",
      "Epoch 34/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.5959 - loss: 1.5258 - val_accuracy: 0.6447 - val_loss: 1.4025 - learning_rate: 0.0010\n",
      "Epoch 35/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 904us/step - accuracy: 0.5997 - loss: 1.5264 - val_accuracy: 0.6533 - val_loss: 1.3884 - learning_rate: 0.0010\n",
      "Epoch 36/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.5876 - loss: 1.5354 - val_accuracy: 0.6547 - val_loss: 1.3819 - learning_rate: 0.0010\n",
      "Epoch 37/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 830us/step - accuracy: 0.5788 - loss: 1.5538 - val_accuracy: 0.6527 - val_loss: 1.3746 - learning_rate: 0.0010\n",
      "Epoch 38/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 898us/step - accuracy: 0.5870 - loss: 1.5354 - val_accuracy: 0.6493 - val_loss: 1.3845 - learning_rate: 0.0010\n",
      "Epoch 39/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.5834 - loss: 1.5285 - val_accuracy: 0.6507 - val_loss: 1.3702 - learning_rate: 0.0010\n",
      "Epoch 40/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.5869 - loss: 1.5292 - val_accuracy: 0.6513 - val_loss: 1.3641 - learning_rate: 0.0010\n",
      "Epoch 41/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 884us/step - accuracy: 0.5834 - loss: 1.5509 - val_accuracy: 0.6447 - val_loss: 1.3725 - learning_rate: 0.0010\n",
      "Epoch 42/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 809us/step - accuracy: 0.5784 - loss: 1.5456 - val_accuracy: 0.6513 - val_loss: 1.3596 - learning_rate: 0.0010\n",
      "Epoch 43/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 907us/step - accuracy: 0.5979 - loss: 1.5275 - val_accuracy: 0.6607 - val_loss: 1.3571 - learning_rate: 0.0010\n",
      "Epoch 44/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 843us/step - accuracy: 0.6057 - loss: 1.4808 - val_accuracy: 0.6580 - val_loss: 1.3796 - learning_rate: 0.0010\n",
      "Epoch 45/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6010 - loss: 1.5095 - val_accuracy: 0.6453 - val_loss: 1.3630 - learning_rate: 0.0010\n",
      "Epoch 46/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.5966 - loss: 1.5081 - val_accuracy: 0.6493 - val_loss: 1.3487 - learning_rate: 0.0010\n",
      "Epoch 47/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.5997 - loss: 1.4925 - val_accuracy: 0.6473 - val_loss: 1.3516 - learning_rate: 0.0010\n",
      "Epoch 48/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6029 - loss: 1.4768 - val_accuracy: 0.6600 - val_loss: 1.3521 - learning_rate: 0.0010\n",
      "Epoch 49/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 839us/step - accuracy: 0.6006 - loss: 1.4917 - val_accuracy: 0.6607 - val_loss: 1.3485 - learning_rate: 0.0010\n",
      "Epoch 50/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.6030 - loss: 1.5025 - val_accuracy: 0.6500 - val_loss: 1.3362 - learning_rate: 0.0010\n",
      "Epoch 51/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 833us/step - accuracy: 0.6099 - loss: 1.4638 - val_accuracy: 0.6607 - val_loss: 1.3426 - learning_rate: 0.0010\n",
      "Epoch 52/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.5994 - loss: 1.4864 - val_accuracy: 0.6607 - val_loss: 1.3359 - learning_rate: 0.0010\n",
      "Epoch 53/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.5990 - loss: 1.4790 - val_accuracy: 0.6600 - val_loss: 1.3432 - learning_rate: 0.0010\n",
      "Epoch 54/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.6040 - loss: 1.4871 - val_accuracy: 0.6747 - val_loss: 1.3297 - learning_rate: 0.0010\n",
      "Epoch 55/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.6054 - loss: 1.4732 - val_accuracy: 0.6580 - val_loss: 1.3389 - learning_rate: 0.0010\n",
      "Epoch 56/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 886us/step - accuracy: 0.6029 - loss: 1.4904 - val_accuracy: 0.6513 - val_loss: 1.3269 - learning_rate: 0.0010\n",
      "Epoch 57/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 837us/step - accuracy: 0.5965 - loss: 1.4662 - val_accuracy: 0.6580 - val_loss: 1.3248 - learning_rate: 0.0010\n",
      "Epoch 58/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6019 - loss: 1.4862 - val_accuracy: 0.6733 - val_loss: 1.3401 - learning_rate: 0.0010\n",
      "Epoch 59/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 864us/step - accuracy: 0.5964 - loss: 1.4764 - val_accuracy: 0.6480 - val_loss: 1.3314 - learning_rate: 0.0010\n",
      "Epoch 60/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6135 - loss: 1.4595 - val_accuracy: 0.6753 - val_loss: 1.3431 - learning_rate: 0.0010\n",
      "Epoch 61/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 836us/step - accuracy: 0.5992 - loss: 1.4873 - val_accuracy: 0.6747 - val_loss: 1.3202 - learning_rate: 0.0010\n",
      "Epoch 62/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 867us/step - accuracy: 0.6092 - loss: 1.4644 - val_accuracy: 0.6613 - val_loss: 1.3154 - learning_rate: 0.0010\n",
      "Epoch 63/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 827us/step - accuracy: 0.5956 - loss: 1.4855 - val_accuracy: 0.6633 - val_loss: 1.3264 - learning_rate: 0.0010\n",
      "Epoch 64/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.6079 - loss: 1.4527 - val_accuracy: 0.6787 - val_loss: 1.3132 - learning_rate: 0.0010\n",
      "Epoch 65/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.6152 - loss: 1.4313 - val_accuracy: 0.6753 - val_loss: 1.3132 - learning_rate: 0.0010\n",
      "Epoch 66/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.6149 - loss: 1.4539 - val_accuracy: 0.6753 - val_loss: 1.3134 - learning_rate: 0.0010\n",
      "Epoch 67/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6068 - loss: 1.4487 - val_accuracy: 0.6733 - val_loss: 1.3065 - learning_rate: 0.0010\n",
      "Epoch 68/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.6029 - loss: 1.4805 - val_accuracy: 0.6613 - val_loss: 1.3085 - learning_rate: 0.0010\n",
      "Epoch 69/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 999us/step - accuracy: 0.6009 - loss: 1.4647 - val_accuracy: 0.6680 - val_loss: 1.3335 - learning_rate: 0.0010\n",
      "Epoch 70/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6105 - loss: 1.4437 - val_accuracy: 0.6593 - val_loss: 1.3207 - learning_rate: 0.0010\n",
      "Epoch 71/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6100 - loss: 1.4445 - val_accuracy: 0.6600 - val_loss: 1.3051 - learning_rate: 0.0010\n",
      "Epoch 72/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 845us/step - accuracy: 0.6018 - loss: 1.4667 - val_accuracy: 0.6827 - val_loss: 1.3147 - learning_rate: 0.0010\n",
      "Epoch 73/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 832us/step - accuracy: 0.6221 - loss: 1.4160 - val_accuracy: 0.6833 - val_loss: 1.3110 - learning_rate: 0.0010\n",
      "Epoch 74/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 946us/step - accuracy: 0.6077 - loss: 1.4463 - val_accuracy: 0.6780 - val_loss: 1.3022 - learning_rate: 0.0010\n",
      "Epoch 75/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 848us/step - accuracy: 0.5978 - loss: 1.4622 - val_accuracy: 0.6860 - val_loss: 1.2973 - learning_rate: 0.0010\n",
      "Epoch 76/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.6175 - loss: 1.4351 - val_accuracy: 0.6740 - val_loss: 1.3030 - learning_rate: 0.0010\n",
      "Epoch 77/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 846us/step - accuracy: 0.5958 - loss: 1.4545 - val_accuracy: 0.6760 - val_loss: 1.2931 - learning_rate: 0.0010\n",
      "Epoch 78/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 908us/step - accuracy: 0.6070 - loss: 1.4360 - val_accuracy: 0.6753 - val_loss: 1.2918 - learning_rate: 0.0010\n",
      "Epoch 79/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 829us/step - accuracy: 0.6095 - loss: 1.4208 - val_accuracy: 0.6687 - val_loss: 1.3008 - learning_rate: 0.0010\n",
      "Epoch 80/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 930us/step - accuracy: 0.6101 - loss: 1.4493 - val_accuracy: 0.6767 - val_loss: 1.2878 - learning_rate: 0.0010\n",
      "Epoch 81/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.6023 - loss: 1.4514 - val_accuracy: 0.6773 - val_loss: 1.2881 - learning_rate: 0.0010\n",
      "Epoch 82/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 911us/step - accuracy: 0.6051 - loss: 1.4573 - val_accuracy: 0.6587 - val_loss: 1.2956 - learning_rate: 0.0010\n",
      "Epoch 83/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 862us/step - accuracy: 0.6182 - loss: 1.4303 - val_accuracy: 0.6753 - val_loss: 1.2909 - learning_rate: 0.0010\n",
      "Epoch 84/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6262 - loss: 1.4079 - val_accuracy: 0.6747 - val_loss: 1.2855 - learning_rate: 0.0010\n",
      "Epoch 85/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 910us/step - accuracy: 0.6297 - loss: 1.3960 - val_accuracy: 0.6753 - val_loss: 1.2851 - learning_rate: 0.0010\n",
      "Epoch 86/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6124 - loss: 1.4295 - val_accuracy: 0.6773 - val_loss: 1.2858 - learning_rate: 0.0010\n",
      "Epoch 87/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 888us/step - accuracy: 0.6200 - loss: 1.4140 - val_accuracy: 0.6747 - val_loss: 1.3103 - learning_rate: 0.0010\n",
      "Epoch 88/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 968us/step - accuracy: 0.6220 - loss: 1.4199 - val_accuracy: 0.6767 - val_loss: 1.2792 - learning_rate: 0.0010\n",
      "Epoch 89/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6153 - loss: 1.4249 - val_accuracy: 0.6787 - val_loss: 1.2777 - learning_rate: 0.0010\n",
      "Epoch 90/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 941us/step - accuracy: 0.6131 - loss: 1.4226 - val_accuracy: 0.6887 - val_loss: 1.2846 - learning_rate: 0.0010\n",
      "Epoch 91/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 850us/step - accuracy: 0.6117 - loss: 1.4270 - val_accuracy: 0.6780 - val_loss: 1.2731 - learning_rate: 0.0010\n",
      "Epoch 92/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 977us/step - accuracy: 0.6229 - loss: 1.4086 - val_accuracy: 0.6907 - val_loss: 1.2827 - learning_rate: 0.0010\n",
      "Epoch 93/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6234 - loss: 1.4139 - val_accuracy: 0.6873 - val_loss: 1.2725 - learning_rate: 0.0010\n",
      "Epoch 94/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.6264 - loss: 1.3960 - val_accuracy: 0.6753 - val_loss: 1.2714 - learning_rate: 0.0010\n",
      "Epoch 95/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6177 - loss: 1.4191 - val_accuracy: 0.6780 - val_loss: 1.2739 - learning_rate: 0.0010\n",
      "Epoch 96/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 876us/step - accuracy: 0.6206 - loss: 1.4119 - val_accuracy: 0.6873 - val_loss: 1.2611 - learning_rate: 0.0010\n",
      "Epoch 97/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6266 - loss: 1.4052 - val_accuracy: 0.6740 - val_loss: 1.2760 - learning_rate: 0.0010\n",
      "Epoch 98/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - accuracy: 0.6331 - loss: 1.3978 - val_accuracy: 0.6867 - val_loss: 1.2658 - learning_rate: 0.0010\n",
      "Epoch 99/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.6237 - loss: 1.4117 - val_accuracy: 0.6880 - val_loss: 1.2584 - learning_rate: 0.0010\n",
      "Epoch 100/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 889us/step - accuracy: 0.6231 - loss: 1.3956 - val_accuracy: 0.6733 - val_loss: 1.2641 - learning_rate: 0.0010\n",
      "Epoch 101/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 943us/step - accuracy: 0.6238 - loss: 1.4270 - val_accuracy: 0.6780 - val_loss: 1.2657 - learning_rate: 0.0010\n",
      "Epoch 102/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.6327 - loss: 1.3821 - val_accuracy: 0.6793 - val_loss: 1.2673 - learning_rate: 0.0010\n",
      "Epoch 103/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 971us/step - accuracy: 0.6312 - loss: 1.3825 - val_accuracy: 0.6780 - val_loss: 1.2572 - learning_rate: 0.0010\n",
      "Epoch 104/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 894us/step - accuracy: 0.6320 - loss: 1.4121 - val_accuracy: 0.6787 - val_loss: 1.2547 - learning_rate: 0.0010\n",
      "Epoch 105/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 992us/step - accuracy: 0.6324 - loss: 1.3833 - val_accuracy: 0.6773 - val_loss: 1.2586 - learning_rate: 0.0010\n",
      "Epoch 106/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 854us/step - accuracy: 0.6236 - loss: 1.4051 - val_accuracy: 0.6793 - val_loss: 1.2570 - learning_rate: 0.0010\n",
      "Epoch 107/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6290 - loss: 1.4045 - val_accuracy: 0.6773 - val_loss: 1.2564 - learning_rate: 0.0010\n",
      "Epoch 108/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.6257 - loss: 1.3808 - val_accuracy: 0.6793 - val_loss: 1.2625 - learning_rate: 0.0010\n",
      "Epoch 109/200\n",
      "\u001b[1m 62/110\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 938us/step - accuracy: 0.6276 - loss: 1.4123\n",
      "Epoch 109: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6263 - loss: 1.4090 - val_accuracy: 0.6900 - val_loss: 1.2597 - learning_rate: 0.0010\n",
      "Epoch 110/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 899us/step - accuracy: 0.6233 - loss: 1.4102 - val_accuracy: 0.6787 - val_loss: 1.2536 - learning_rate: 5.0000e-04\n",
      "Epoch 111/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 951us/step - accuracy: 0.6272 - loss: 1.3894 - val_accuracy: 0.6907 - val_loss: 1.2517 - learning_rate: 5.0000e-04\n",
      "Epoch 112/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 872us/step - accuracy: 0.6337 - loss: 1.3943 - val_accuracy: 0.6787 - val_loss: 1.2440 - learning_rate: 5.0000e-04\n",
      "Epoch 113/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 895us/step - accuracy: 0.6346 - loss: 1.3601 - val_accuracy: 0.6887 - val_loss: 1.2478 - learning_rate: 5.0000e-04\n",
      "Epoch 114/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.6251 - loss: 1.3801 - val_accuracy: 0.6800 - val_loss: 1.2485 - learning_rate: 5.0000e-04\n",
      "Epoch 115/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6367 - loss: 1.3513 - val_accuracy: 0.6920 - val_loss: 1.2457 - learning_rate: 5.0000e-04\n",
      "Epoch 116/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 870us/step - accuracy: 0.6231 - loss: 1.3890 - val_accuracy: 0.6793 - val_loss: 1.2404 - learning_rate: 5.0000e-04\n",
      "Epoch 117/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 891us/step - accuracy: 0.6276 - loss: 1.4000 - val_accuracy: 0.6907 - val_loss: 1.2420 - learning_rate: 5.0000e-04\n",
      "Epoch 118/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.6289 - loss: 1.4074 - val_accuracy: 0.6920 - val_loss: 1.2409 - learning_rate: 5.0000e-04\n",
      "Epoch 119/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.6267 - loss: 1.3922 - val_accuracy: 0.6867 - val_loss: 1.2462 - learning_rate: 5.0000e-04\n",
      "Epoch 120/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 797us/step - accuracy: 0.6382 - loss: 1.3763 - val_accuracy: 0.6793 - val_loss: 1.2452 - learning_rate: 5.0000e-04\n",
      "Epoch 121/200\n",
      "\u001b[1m106/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6366 - loss: 1.3675  \n",
      "Epoch 121: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6363 - loss: 1.3679 - val_accuracy: 0.6900 - val_loss: 1.2460 - learning_rate: 5.0000e-04\n",
      "Epoch 122/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.6225 - loss: 1.3782 - val_accuracy: 0.6900 - val_loss: 1.2435 - learning_rate: 2.5000e-04\n",
      "Epoch 123/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 961us/step - accuracy: 0.6303 - loss: 1.3573 - val_accuracy: 0.6913 - val_loss: 1.2390 - learning_rate: 2.5000e-04\n",
      "Epoch 124/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 892us/step - accuracy: 0.6345 - loss: 1.3718 - val_accuracy: 0.6913 - val_loss: 1.2414 - learning_rate: 2.5000e-04\n",
      "Epoch 125/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 881us/step - accuracy: 0.6397 - loss: 1.3636 - val_accuracy: 0.6800 - val_loss: 1.2441 - learning_rate: 2.5000e-04\n",
      "Epoch 126/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 957us/step - accuracy: 0.6269 - loss: 1.3996 - val_accuracy: 0.6793 - val_loss: 1.2403 - learning_rate: 2.5000e-04\n",
      "Epoch 127/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 855us/step - accuracy: 0.6239 - loss: 1.3840 - val_accuracy: 0.6787 - val_loss: 1.2403 - learning_rate: 2.5000e-04\n",
      "Epoch 128/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 964us/step - accuracy: 0.6379 - loss: 1.3557 - val_accuracy: 0.6907 - val_loss: 1.2356 - learning_rate: 2.5000e-04\n",
      "Epoch 129/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 950us/step - accuracy: 0.6371 - loss: 1.3548 - val_accuracy: 0.6893 - val_loss: 1.2354 - learning_rate: 2.5000e-04\n",
      "Epoch 130/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6349 - loss: 1.3588 - val_accuracy: 0.6907 - val_loss: 1.2333 - learning_rate: 2.5000e-04\n",
      "Epoch 131/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 919us/step - accuracy: 0.6378 - loss: 1.3576 - val_accuracy: 0.6900 - val_loss: 1.2360 - learning_rate: 2.5000e-04\n",
      "Epoch 132/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 929us/step - accuracy: 0.6253 - loss: 1.3802 - val_accuracy: 0.6920 - val_loss: 1.2379 - learning_rate: 2.5000e-04\n",
      "Epoch 133/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 869us/step - accuracy: 0.6322 - loss: 1.3789 - val_accuracy: 0.6900 - val_loss: 1.2360 - learning_rate: 2.5000e-04\n",
      "Epoch 134/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6252 - loss: 1.3940 - val_accuracy: 0.6900 - val_loss: 1.2377 - learning_rate: 2.5000e-04\n",
      "Epoch 135/200\n",
      "\u001b[1m 79/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6332 - loss: 1.3676\n",
      "Epoch 135: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6328 - loss: 1.3692 - val_accuracy: 0.6933 - val_loss: 1.2381 - learning_rate: 2.5000e-04\n",
      "Epoch 136/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6324 - loss: 1.3776 - val_accuracy: 0.6793 - val_loss: 1.2395 - learning_rate: 1.2500e-04\n",
      "Epoch 137/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 901us/step - accuracy: 0.6242 - loss: 1.3996 - val_accuracy: 0.6900 - val_loss: 1.2332 - learning_rate: 1.2500e-04\n",
      "Epoch 138/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 989us/step - accuracy: 0.6201 - loss: 1.3897 - val_accuracy: 0.6913 - val_loss: 1.2343 - learning_rate: 1.2500e-04\n",
      "Epoch 139/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 920us/step - accuracy: 0.6178 - loss: 1.3891 - val_accuracy: 0.6907 - val_loss: 1.2348 - learning_rate: 1.2500e-04\n",
      "Epoch 140/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 984us/step - accuracy: 0.6356 - loss: 1.3759 - val_accuracy: 0.6933 - val_loss: 1.2356 - learning_rate: 1.2500e-04\n",
      "Epoch 141/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 926us/step - accuracy: 0.6236 - loss: 1.3922 - val_accuracy: 0.6900 - val_loss: 1.2328 - learning_rate: 1.2500e-04\n",
      "Epoch 142/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6253 - loss: 1.3883 - val_accuracy: 0.6927 - val_loss: 1.2337 - learning_rate: 1.2500e-04\n",
      "Epoch 143/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 874us/step - accuracy: 0.6336 - loss: 1.3571 - val_accuracy: 0.6927 - val_loss: 1.2342 - learning_rate: 1.2500e-04\n",
      "Epoch 144/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 903us/step - accuracy: 0.6325 - loss: 1.3629 - val_accuracy: 0.6913 - val_loss: 1.2338 - learning_rate: 1.2500e-04\n",
      "Epoch 145/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6364 - loss: 1.3618 - val_accuracy: 0.6907 - val_loss: 1.2319 - learning_rate: 1.2500e-04\n",
      "Epoch 146/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 890us/step - accuracy: 0.6410 - loss: 1.3392 - val_accuracy: 0.6927 - val_loss: 1.2314 - learning_rate: 1.2500e-04\n",
      "Epoch 147/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6279 - loss: 1.3767 - val_accuracy: 0.6927 - val_loss: 1.2325 - learning_rate: 1.2500e-04\n",
      "Epoch 148/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 835us/step - accuracy: 0.6304 - loss: 1.3766 - val_accuracy: 0.6920 - val_loss: 1.2318 - learning_rate: 1.2500e-04\n",
      "Epoch 149/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 981us/step - accuracy: 0.6307 - loss: 1.3845 - val_accuracy: 0.6913 - val_loss: 1.2337 - learning_rate: 1.2500e-04\n",
      "Epoch 150/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 882us/step - accuracy: 0.6335 - loss: 1.3728 - val_accuracy: 0.6900 - val_loss: 1.2350 - learning_rate: 1.2500e-04\n",
      "Epoch 151/200\n",
      "\u001b[1m 63/110\u001b[0m \u001b[32m━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 865us/step - accuracy: 0.6432 - loss: 1.3544\n",
      "Epoch 151: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6388 - loss: 1.3606 - val_accuracy: 0.6907 - val_loss: 1.2348 - learning_rate: 1.2500e-04\n",
      "Epoch 152/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 885us/step - accuracy: 0.6336 - loss: 1.3642 - val_accuracy: 0.6900 - val_loss: 1.2338 - learning_rate: 6.2500e-05\n",
      "Epoch 153/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 958us/step - accuracy: 0.6231 - loss: 1.3843 - val_accuracy: 0.6907 - val_loss: 1.2314 - learning_rate: 6.2500e-05\n",
      "Epoch 154/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.6372 - loss: 1.3394 - val_accuracy: 0.6927 - val_loss: 1.2328 - learning_rate: 6.2500e-05\n",
      "Epoch 155/200\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6410 - loss: 1.3383 - val_accuracy: 0.6900 - val_loss: 1.2325 - learning_rate: 6.2500e-05\n",
      "Epoch 156/200\n",
      "\u001b[1m 77/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 698us/step - accuracy: 0.6286 - loss: 1.3595\n",
      "Epoch 156: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m110/110\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 878us/step - accuracy: 0.6286 - loss: 1.3625 - val_accuracy: 0.6920 - val_loss: 1.2320 - learning_rate: 6.2500e-05\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 365us/step - accuracy: 0.6708 - loss: 1.2884\n",
      "Test Loss: 1.2552454471588135, Test Accuracy: 0.6800000071525574\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "# Build the ANN model for multi-class classification with additional layers and regularization\n",
    "model = Sequential()\n",
    "# Input layer and first hidden layer\n",
    "model.add(Dense(128, input_dim=X_train.shape[1], activation='relu', kernel_regularizer=l2(0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "# Additional hidden layers\n",
    "model.add(Dense(64, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(32, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "# model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(16, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "# Output layer\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Nadam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping and learning rate reduction to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5, min_lr=1e-6, verbose=1)\n",
    "\n",
    "# Train the model with the callbacks\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=64, callbacks=[early_stopping, reduce_lr])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/kiran/Library/Python/3.9/lib/python/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: '@rpath/libomp.dylib'\n  Referenced from: '/Users/kiran/Library/Python/3.9/lib/python/site-packages/lightgbm/lib/lib_lightgbm.dylib'\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[43], line 9\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# TO DO: \u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# - Implement CV later since it will probably add a lot to the already long runtime\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39m# Note:\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m# Care in running the grid search it will take a very long time\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39m# Current best params for sample: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 50}\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlightgbm\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mlgb\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split, GridSearchCV\n\u001b[1;32m     12\u001b[0m \u001b[39m# Dropped dataset, IoTIP_int, hostIP_int, year_month\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightgbm/__init__.py:9\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39m\"\"\"LightGBM, Light Gradient Boosting Machine.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[1;32m      4\u001b[0m \u001b[39mContributors: https://github.com/microsoft/LightGBM/graphs/contributors.\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpathlib\u001b[39;00m \u001b[39mimport\u001b[39;00m Path\n\u001b[0;32m----> 9\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbasic\u001b[39;00m \u001b[39mimport\u001b[39;00m Booster, Dataset, Sequence, register_logger\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcallback\u001b[39;00m \u001b[39mimport\u001b[39;00m EarlyStopException, early_stopping, log_evaluation, record_evaluation, reset_parameter\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mengine\u001b[39;00m \u001b[39mimport\u001b[39;00m CVBooster, cv, train\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightgbm/basic.py:281\u001b[0m\n\u001b[1;32m    279\u001b[0m     _LIB \u001b[39m=\u001b[39m Mock(ctypes\u001b[39m.\u001b[39mCDLL)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    280\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     _LIB \u001b[39m=\u001b[39m _load_lib()\n\u001b[1;32m    284\u001b[0m _NUMERIC_TYPES \u001b[39m=\u001b[39m (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m, \u001b[39mbool\u001b[39m)\n\u001b[1;32m    287\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_safe_call\u001b[39m(ret: \u001b[39mint\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/lightgbm/basic.py:265\u001b[0m, in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m    263\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Load LightGBM library.\"\"\"\u001b[39;00m\n\u001b[1;32m    264\u001b[0m lib_path \u001b[39m=\u001b[39m find_lib_path()\n\u001b[0;32m--> 265\u001b[0m lib \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39;49mcdll\u001b[39m.\u001b[39;49mLoadLibrary(lib_path[\u001b[39m0\u001b[39;49m])\n\u001b[1;32m    266\u001b[0m lib\u001b[39m.\u001b[39mLGBM_GetLastError\u001b[39m.\u001b[39mrestype \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mc_char_p\n\u001b[1;32m    267\u001b[0m callback \u001b[39m=\u001b[39m ctypes\u001b[39m.\u001b[39mCFUNCTYPE(\u001b[39mNone\u001b[39;00m, ctypes\u001b[39m.\u001b[39mc_char_p)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:444\u001b[0m, in \u001b[0;36mLibraryLoader.LoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mLoadLibrary\u001b[39m(\u001b[39mself\u001b[39m, name):\n\u001b[0;32m--> 444\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dlltype(name)\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/ctypes/__init__.py:366\u001b[0m, in \u001b[0;36mCDLL.__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error, winmode)\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_FuncPtr \u001b[39m=\u001b[39m _FuncPtr\n\u001b[1;32m    365\u001b[0m \u001b[39mif\u001b[39;00m handle \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 366\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m _dlopen(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_name, mode)\n\u001b[1;32m    367\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    368\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_handle \u001b[39m=\u001b[39m handle\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/kiran/Library/Python/3.9/lib/python/site-packages/lightgbm/lib/lib_lightgbm.dylib, 0x0006): Library not loaded: '@rpath/libomp.dylib'\n  Referenced from: '/Users/kiran/Library/Python/3.9/lib/python/site-packages/lightgbm/lib/lib_lightgbm.dylib'\n  Reason: tried: '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/opt/homebrew/opt/libomp/lib/libomp.dylib' (no such file), '/opt/local/lib/libomp/libomp.dylib' (no such file), '/usr/local/lib/libomp.dylib' (no such file), '/usr/lib/libomp.dylib' (no such file)"
     ]
    }
   ],
   "source": [
    "# TO DO: \n",
    "# - Implement CV later since it will probably add a lot to the already long runtime\n",
    "\n",
    "# Note:\n",
    "# Care in running the grid search it will take a very long time\n",
    "# Current best params for sample: {'learning_rate': 0.05, 'max_depth': 10, 'n_estimators': 100, 'num_leaves': 50}\n",
    "\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Dropped dataset, IoTIP_int, hostIP_int, year_month\n",
    "df = pd.read_csv('newSample.csv')\n",
    "\n",
    "# Drop original date and time columns\n",
    "df.drop(columns=['start_date', 'start_time'], inplace=True)\n",
    "\n",
    "# Defines categorical variables\n",
    "categories = ['IoTMac', 'hostMac', 'IoTIP', 'hostIP', 'ipProto', 'reverseFlowExists', 'remote', 'broadcast', 'HTTP', 'HTTPS', 'DNS', 'NTP', 'TCP_others', 'UDP_others']\n",
    "for var in categories:\n",
    "    df[var] = df[var].astype('category')\n",
    "\n",
    "X = df.drop(columns=['IoTMac'])\n",
    "y = df['IoTMac']\n",
    "\n",
    "XTrain, XTest, yTrain, yTest = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "parameters = param_grid = {\n",
    "    'num_leaves': [30, 50, 100],\n",
    "    'max_depth': [10, 20, -1], # -1 means unlimited\n",
    "    'learning_rate': [0.01, 0.05, 0.1],\n",
    "    'n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "grid = GridSearchCV(lgb.LGBMClassifier(random_state=42), param_grid, cv=3, scoring='neg_log_loss', n_jobs=-1)\n",
    "grid.fit(XTrain, yTrain)\n",
    "\n",
    "bestParamsModel = grid.best_estimator_\n",
    "\n",
    "bestParamsModel.fit(XTrain, yTrain)\n",
    "\n",
    "print(\"Best parameters found: \", grid.best_params_)\n",
    "print('Training accuracy {:.4f}'.format(bestParamsModel.score(XTrain, yTrain)))\n",
    "print('Testing accuracy {:.4f}'.format(bestParamsModel.score(XTest,yTest)))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'kerastuner'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkerastuner\u001b[39;00m \u001b[39mimport\u001b[39;00m RandomSearch\n\u001b[1;32m      2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m Dense\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptimizers\u001b[39;00m \u001b[39mimport\u001b[39;00m Adam\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'kerastuner'"
     ]
    }
   ],
   "source": [
    "from kerastuner import RandomSearch\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# Define the model builder function\n",
    "def build_model(hp):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hp.Int('units_1', min_value=32, max_value=128, step=32), activation='relu', input_dim=X_train.shape[1]))\n",
    "    model.add(Dense(hp.Int('units_2', min_value=32, max_value=128, step=32), activation='relu'))\n",
    "    model.add(Dense(len(encoder.classes_), activation='softmax'))\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=hp.Choice('learning_rate', [0.01, 0.001, 0.0001])),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    return model\n",
    "\n",
    "# Instantiate Keras Tuner\n",
    "tuner = RandomSearch(\n",
    "    build_model,\n",
    "    objective='val_accuracy',\n",
    "    max_trials=5,\n",
    "    executions_per_trial=3,\n",
    "    directory='tuner_dir',\n",
    "    project_name='multi_classification_tuning'\n",
    ")\n",
    "\n",
    "# Run the search\n",
    "tuner.search(X_train, y_train, epochs=50, validation_data=(X_val, y_val), callbacks=[early_stopping])\n",
    "\n",
    "# Get the best model and evaluate on the test set\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)\n",
    "print(f\"Optimized Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>start_time</th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>IoTMac</th>\n",
       "      <th>hostMac</th>\n",
       "      <th>IoTIP</th>\n",
       "      <th>hostIP</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>hostPort</th>\n",
       "      <th>PacketCount</th>\n",
       "      <th>BytesCount</th>\n",
       "      <th>reversePacketCount</th>\n",
       "      <th>reverseBytesCount</th>\n",
       "      <th>SmallPktCount</th>\n",
       "      <th>LargePktCount</th>\n",
       "      <th>NonEmptyPktCount</th>\n",
       "      <th>DataByteCount</th>\n",
       "      <th>AvgIAT</th>\n",
       "      <th>FirstNonEmptyPktSize</th>\n",
       "      <th>MaxPktSize</th>\n",
       "      <th>StdevPayloadSize</th>\n",
       "      <th>StdevIAT</th>\n",
       "      <th>AvgPacketSize</th>\n",
       "      <th>reverseSmallPktCount</th>\n",
       "      <th>reverseLargePktCount</th>\n",
       "      <th>reverseNonEmptyPktCount</th>\n",
       "      <th>reverseDataByteCount</th>\n",
       "      <th>reverseAvgIAT</th>\n",
       "      <th>reverseFirstNonEmptyPktSize</th>\n",
       "      <th>reverseMaxPktSize</th>\n",
       "      <th>reverseStdevPayloadSize</th>\n",
       "      <th>reverseStdevIAT</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-09-25</td>\n",
       "      <td>06:50:15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>33033</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-08-12</td>\n",
       "      <td>21:01:27</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>48:d6:d5:92:96:a2:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.184</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>17</td>\n",
       "      <td>33789</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-09-19</td>\n",
       "      <td>06:31:15</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>46713</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-08-16</td>\n",
       "      <td>02:58:57</td>\n",
       "      <td>0.434</td>\n",
       "      <td>0.012</td>\n",
       "      <td>04:5d:4b:a4:d0:2e:</td>\n",
       "      <td>38:d5:47:0c:25:d4:</td>\n",
       "      <td>192.168.1.124</td>\n",
       "      <td>74.125.102.41</td>\n",
       "      <td>6</td>\n",
       "      <td>53460</td>\n",
       "      <td>443</td>\n",
       "      <td>18</td>\n",
       "      <td>1986</td>\n",
       "      <td>18</td>\n",
       "      <td>18612</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1030</td>\n",
       "      <td>21</td>\n",
       "      <td>188</td>\n",
       "      <td>685</td>\n",
       "      <td>253</td>\n",
       "      <td>54</td>\n",
       "      <td>257</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "      <td>17668</td>\n",
       "      <td>24</td>\n",
       "      <td>1396</td>\n",
       "      <td>2792</td>\n",
       "      <td>803</td>\n",
       "      <td>55</td>\n",
       "      <td>1359</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-07-29</td>\n",
       "      <td>03:03:10</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>00:1b:c7:fa:c3:e6:</td>\n",
       "      <td>01:00:5e:7f:ff:fa:</td>\n",
       "      <td>192.168.1.236</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>17</td>\n",
       "      <td>48008</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date start_time  duration  reverseDelta              IoTMac  \\\n",
       "0  2019-09-25   06:50:15     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "1  2019-08-12   21:01:27     0.000         0.000  48:d6:d5:92:96:a2:   \n",
       "2  2019-09-19   06:31:15     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "3  2019-08-16   02:58:57     0.434         0.012  04:5d:4b:a4:d0:2e:   \n",
       "4  2019-07-29   03:03:10     0.000         0.000  00:1b:c7:fa:c3:e6:   \n",
       "\n",
       "              hostMac          IoTIP           hostIP  ipProto  IoTPort  \\\n",
       "0  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    33033   \n",
       "1  38:d5:47:0c:25:d4:  192.168.1.184      192.168.1.1       17    33789   \n",
       "2  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    46713   \n",
       "3  38:d5:47:0c:25:d4:  192.168.1.124    74.125.102.41        6    53460   \n",
       "4  01:00:5e:7f:ff:fa:  192.168.1.236  239.255.255.250       17    48008   \n",
       "\n",
       "   hostPort  PacketCount  BytesCount  reversePacketCount  reverseBytesCount  \\\n",
       "0      1900            1         294                   0                  0   \n",
       "1        53            1          75                   0                  0   \n",
       "2      1900            1         294                   0                  0   \n",
       "3       443           18        1986                  18              18612   \n",
       "4      1900            1         294                   0                  0   \n",
       "\n",
       "   SmallPktCount  LargePktCount  NonEmptyPktCount  DataByteCount  AvgIAT  \\\n",
       "0              0              1                 1            266       0   \n",
       "1              1              0                 1             47       0   \n",
       "2              0              1                 1            266       0   \n",
       "3              1              1                 4           1030      21   \n",
       "4              0              1                 1            266       0   \n",
       "\n",
       "   FirstNonEmptyPktSize  MaxPktSize  StdevPayloadSize  StdevIAT  \\\n",
       "0                   266         266                 0         0   \n",
       "1                    47          47                 0         0   \n",
       "2                   266         266                 0         0   \n",
       "3                   188         685               253        54   \n",
       "4                   266         266                 0         0   \n",
       "\n",
       "   AvgPacketSize  reverseSmallPktCount  reverseLargePktCount  \\\n",
       "0            266                     0                     0   \n",
       "1             47                     0                     0   \n",
       "2            266                     0                     0   \n",
       "3            257                     0                    13   \n",
       "4            266                     0                     0   \n",
       "\n",
       "   reverseNonEmptyPktCount  reverseDataByteCount  reverseAvgIAT  \\\n",
       "0                        0                     0              0   \n",
       "1                        0                     0              0   \n",
       "2                        0                     0              0   \n",
       "3                       13                 17668             24   \n",
       "4                        0                     0              0   \n",
       "\n",
       "   reverseFirstNonEmptyPktSize  reverseMaxPktSize  reverseStdevPayloadSize  \\\n",
       "0                            0                  0                        0   \n",
       "1                            0                  0                        0   \n",
       "2                            0                  0                        0   \n",
       "3                         1396               2792                      803   \n",
       "4                            0                  0                        0   \n",
       "\n",
       "   reverseStdevIAT  reverseAvgPacketSize  reverseFlowExists  remote  \\\n",
       "0                0                     0                  0       1   \n",
       "1                0                     0                  0       0   \n",
       "2                0                     0                  0       1   \n",
       "3               55                  1359                  1       1   \n",
       "4                0                     0                  0       1   \n",
       "\n",
       "   broadcast  HTTP  HTTPS  DNS  NTP  TCP_others  UDP_others  \n",
       "0          0     0      0    0    0           0           1  \n",
       "1          0     0      0    1    0           0           0  \n",
       "2          0     0      0    0    0           0           1  \n",
       "3          0     0      1    0    0           1           0  \n",
       "4          0     0      0    0    0           0           1  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"newSample.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  reverseDelta  ipProto  IoTPort  hostPort  PacketCount  \\\n",
      "0     0.000         0.000       17    33033      1900            1   \n",
      "1     0.000         0.000       17    33789        53            1   \n",
      "2     0.000         0.000       17    46713      1900            1   \n",
      "3     0.434         0.012        6    53460       443           18   \n",
      "4     0.000         0.000       17    48008      1900            1   \n",
      "\n",
      "   BytesCount  reversePacketCount  reverseBytesCount  SmallPktCount  ...  \\\n",
      "0         294                   0                  0              0  ...   \n",
      "1          75                   0                  0              1  ...   \n",
      "2         294                   0                  0              0  ...   \n",
      "3        1986                  18              18612              1  ...   \n",
      "4         294                   0                  0              0  ...   \n",
      "\n",
      "   hostIP_74.125.204.188  hostIP_74.125.23.102  hostIP_74.125.23.188  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_8.8.4.4  hostIP_8.8.8.8  hostIP_99.84.138.143  hostIP_99.84.138.70  \\\n",
      "0           False           False                 False                False   \n",
      "1           False           False                 False                False   \n",
      "2           False           False                 False                False   \n",
      "3           False           False                 False                False   \n",
      "4           False           False                 False                False   \n",
      "\n",
      "   hostIP_99.84.143.77  hostIP_99.84.54.35  hostIP_99.84.59.93  \n",
      "0                False               False               False  \n",
      "1                False               False               False  \n",
      "2                False               False               False  \n",
      "3                False               False               False  \n",
      "4                False               False               False  \n",
      "\n",
      "[5 rows x 259 columns]\n",
      "               IoTMac\n",
      "0  00:1b:c7:fa:c3:e6:\n",
      "1  48:d6:d5:92:96:a2:\n",
      "2  00:1b:c7:fa:c3:e6:\n",
      "3  04:5d:4b:a4:d0:2e:\n",
      "4  00:1b:c7:fa:c3:e6:\n",
      "Accuracy: 0.85900\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Oct 29 12:48:35 2024\n",
    "\n",
    "@author: camer\n",
    "\"\"\"\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "column_names = [\n",
    "    \"name\", \"start_date\", \"start_time\", \"duration\", \"reverseDelta\", \"IoTMac\", \"hostMac\", \n",
    "    \"IoTIP\", \"IoTIP_int\", \"hostIP\", \"hostIP_int\", \"ipProto\", \"IoTPort\", \"hostPort\", \n",
    "    \"PacketCount\", \"BytesCount\", \"reversePacketCount\", \"reverseBytesCount\", \"SmallPktCount\", \n",
    "    \"LargePktCount\", \"NonEmptyPktCount\", \"DataByteCount\", \"AvgIAT\", \"FirstNonEmptyPktSize\", \n",
    "    \"MaxPktSize\", \"StdevPayloadSize\", \"StdevIAT\", \"AvgPacketSize\", \"reverseSmallPktCount\", \n",
    "    \"reverseLargePktCount\", \"reverseNonEmptyPktCount\", \"reverseDataByteCount\", \"reverseAvgIAT\", \n",
    "    \"reverseFirstNonEmptyPktSize\", \"reverseMaxPktSize\", \"reverseStdevPayloadSize\", \"reverseStdevIAT\", \n",
    "    \"reverseAvgPacketSize\", \"reverseFlowExists\", \"remote\", \"broadcast\", \"HTTP\", \"HTTPS\", \"DNS\", \n",
    "    \"NTP\", \"TCP_others\", \"UDP_others\", \"year_month\"\n",
    "]\n",
    "\n",
    "# Load data and clean 'name' column\n",
    "# df = pd.read_csv('sample2.csv', names=column_names)\n",
    "# df['name'] = df['name'].str.replace(r'_\\d{4}_\\d{2}\\.csv$', '', regex=True)\n",
    "df = pd.read_csv(\"newSample.csv\")\n",
    "\n",
    "# Step 3: Encode 'name' as dummy variables\n",
    "target_columns = ['IoTMac']\n",
    "y = df.filter(items = target_columns)\n",
    "df = df.drop(['start_date', 'start_time','IoTIP', 'IoTMac', 'hostMac'], axis=1)\n",
    "df2 = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "\n",
    "X = df2\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "# Split the dataset into training and test sets 20-80\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y.values.ravel(), test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "# Initialize and train the Random Forest classifier\n",
    "\n",
    "model = MLPClassifier(alpha = 0.01,learning_rate_init=0.01,learning_rate='constant',early_stopping=True,max_iter=100,random_state=42, hidden_layer_sizes=(100,50,20))\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>reverseDelta</th>\n",
       "      <th>hostIP</th>\n",
       "      <th>hostIP_int</th>\n",
       "      <th>ipProto</th>\n",
       "      <th>IoTPort</th>\n",
       "      <th>hostPort</th>\n",
       "      <th>PacketCount</th>\n",
       "      <th>BytesCount</th>\n",
       "      <th>reversePacketCount</th>\n",
       "      <th>reverseBytesCount</th>\n",
       "      <th>SmallPktCount</th>\n",
       "      <th>LargePktCount</th>\n",
       "      <th>NonEmptyPktCount</th>\n",
       "      <th>DataByteCount</th>\n",
       "      <th>AvgIAT</th>\n",
       "      <th>FirstNonEmptyPktSize</th>\n",
       "      <th>MaxPktSize</th>\n",
       "      <th>StdevPayloadSize</th>\n",
       "      <th>StdevIAT</th>\n",
       "      <th>AvgPacketSize</th>\n",
       "      <th>reverseSmallPktCount</th>\n",
       "      <th>reverseLargePktCount</th>\n",
       "      <th>reverseNonEmptyPktCount</th>\n",
       "      <th>reverseDataByteCount</th>\n",
       "      <th>reverseAvgIAT</th>\n",
       "      <th>reverseFirstNonEmptyPktSize</th>\n",
       "      <th>reverseMaxPktSize</th>\n",
       "      <th>reverseStdevPayloadSize</th>\n",
       "      <th>reverseStdevIAT</th>\n",
       "      <th>reverseAvgPacketSize</th>\n",
       "      <th>reverseFlowExists</th>\n",
       "      <th>remote</th>\n",
       "      <th>broadcast</th>\n",
       "      <th>HTTP</th>\n",
       "      <th>HTTPS</th>\n",
       "      <th>DNS</th>\n",
       "      <th>NTP</th>\n",
       "      <th>TCP_others</th>\n",
       "      <th>UDP_others</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>239.255.255.250</td>\n",
       "      <td>4026531834</td>\n",
       "      <td>17</td>\n",
       "      <td>47087</td>\n",
       "      <td>1900</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>266</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>26321</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.001</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>6</td>\n",
       "      <td>41178</td>\n",
       "      <td>40480</td>\n",
       "      <td>7</td>\n",
       "      <td>452</td>\n",
       "      <td>6</td>\n",
       "      <td>3238</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2918</td>\n",
       "      <td>1</td>\n",
       "      <td>1448</td>\n",
       "      <td>1470</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1459</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>240.117</td>\n",
       "      <td>0.007</td>\n",
       "      <td>172.217.26.46</td>\n",
       "      <td>2899909166</td>\n",
       "      <td>6</td>\n",
       "      <td>60388</td>\n",
       "      <td>443</td>\n",
       "      <td>19</td>\n",
       "      <td>5053</td>\n",
       "      <td>21</td>\n",
       "      <td>2021</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>4057</td>\n",
       "      <td>13339</td>\n",
       "      <td>517</td>\n",
       "      <td>1486</td>\n",
       "      <td>560</td>\n",
       "      <td>13328</td>\n",
       "      <td>507</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>921</td>\n",
       "      <td>12005</td>\n",
       "      <td>156</td>\n",
       "      <td>280</td>\n",
       "      <td>78</td>\n",
       "      <td>11995</td>\n",
       "      <td>115</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.001</td>\n",
       "      <td>0.000</td>\n",
       "      <td>192.168.1.1</td>\n",
       "      <td>3232235777</td>\n",
       "      <td>17</td>\n",
       "      <td>38645</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>128</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>5001</td>\n",
       "      <td>36</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  reverseDelta           hostIP  hostIP_int  ipProto  IoTPort  \\\n",
       "0     0.000         0.000  239.255.255.250  4026531834       17    47087   \n",
       "1     0.000         0.000      192.168.1.1  3232235777       17    26321   \n",
       "2     0.006         0.001      192.168.1.1  3232235777        6    41178   \n",
       "3   240.117         0.007    172.217.26.46  2899909166        6    60388   \n",
       "4     5.001         0.000      192.168.1.1  3232235777       17    38645   \n",
       "\n",
       "   hostPort  PacketCount  BytesCount  reversePacketCount  reverseBytesCount  \\\n",
       "0      1900            1         294                   0                  0   \n",
       "1        53            1          75                   0                  0   \n",
       "2     40480            7         452                   6               3238   \n",
       "3       443           19        5053                  21               2021   \n",
       "4        53            2         128                   0                  0   \n",
       "\n",
       "   SmallPktCount  LargePktCount  NonEmptyPktCount  DataByteCount  AvgIAT  \\\n",
       "0              0              1                 1            266       0   \n",
       "1              1              0                 1             47       0   \n",
       "2              0              0                 1             80       0   \n",
       "3              3              4                 8           4057   13339   \n",
       "4              2              0                 2             72    5001   \n",
       "\n",
       "   FirstNonEmptyPktSize  MaxPktSize  StdevPayloadSize  StdevIAT  \\\n",
       "0                   266         266                 0         0   \n",
       "1                    47          47                 0         0   \n",
       "2                    80          80                 0         1   \n",
       "3                   517        1486               560     13328   \n",
       "4                    36          36                 0         0   \n",
       "\n",
       "   AvgPacketSize  reverseSmallPktCount  reverseLargePktCount  \\\n",
       "0            266                     0                     0   \n",
       "1             47                     0                     0   \n",
       "2             80                     0                     2   \n",
       "3            507                     2                     1   \n",
       "4             36                     0                     0   \n",
       "\n",
       "   reverseNonEmptyPktCount  reverseDataByteCount  reverseAvgIAT  \\\n",
       "0                        0                     0              0   \n",
       "1                        0                     0              0   \n",
       "2                        2                  2918              1   \n",
       "3                        8                   921          12005   \n",
       "4                        0                     0              0   \n",
       "\n",
       "   reverseFirstNonEmptyPktSize  reverseMaxPktSize  reverseStdevPayloadSize  \\\n",
       "0                            0                  0                        0   \n",
       "1                            0                  0                        0   \n",
       "2                         1448               1470                       11   \n",
       "3                          156                280                       78   \n",
       "4                            0                  0                        0   \n",
       "\n",
       "   reverseStdevIAT  reverseAvgPacketSize  reverseFlowExists  remote  \\\n",
       "0                0                     0                  0       1   \n",
       "1                0                     0                  0       0   \n",
       "2                0                  1459                  1       0   \n",
       "3            11995                   115                  1       1   \n",
       "4                0                     0                  0       0   \n",
       "\n",
       "   broadcast  HTTP  HTTPS  DNS  NTP  TCP_others  UDP_others  \n",
       "0          0     0      0    0    0           0           1  \n",
       "1          0     0      0    1    0           0           0  \n",
       "2          0     0      0    0    0           1           0  \n",
       "3          0     0      1    0    0           1           0  \n",
       "4          0     0      0    1    0           0           0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = pd.read_csv(\"data/sample2.csv\")\n",
    "column_names = [\n",
    "    \"dataset\", \"start_date\", \"start_time\", \"duration\", \"reverseDelta\", \"IoTMac\", \"hostMac\", \"IoTIP\", \"IoTIP_int\",\n",
    "    \"hostIP\", \"hostIP_int\", \"ipProto\", \"IoTPort\", \"hostPort\", \"PacketCount\", \"BytesCount\", \"reversePacketCount\",\n",
    "    \"reverseBytesCount\", \"SmallPktCount\", \"LargePktCount\", \"NonEmptyPktCount\", \"DataByteCount\", \"AvgIAT\",\n",
    "    \"FirstNonEmptyPktSize\", \"MaxPktSize\", \"StdevPayloadSize\", \"StdevIAT\", \"AvgPacketSize\", \"reverseSmallPktCount\",\n",
    "    \"reverseLargePktCount\", \"reverseNonEmptyPktCount\", \"reverseDataByteCount\", \"reverseAvgIAT\",\n",
    "    \"reverseFirstNonEmptyPktSize\", \"reverseMaxPktSize\", \"reverseStdevPayloadSize\", \"reverseStdevIAT\",\n",
    "    \"reverseAvgPacketSize\", \"reverseFlowExists\", \"remote\", \"broadcast\", \"HTTP\", \"HTTPS\", \"DNS\", \"NTP\", \"TCP_others\",\n",
    "    \"UDP_others\", \"year_month\"\n",
    "]\n",
    "sample.columns = column_names\n",
    "heads = sample.drop(columns = ['dataset', 'start_date', 'start_time', 'IoTMac', 'IoTIP', 'IoTIP_int', 'year_month','hostMac'])\n",
    "heads.head()\n",
    "# sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of correctly classified elements: 18167\n",
      "correct divide all: 0.9083590835908357\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Thu Oct 24 10:50:30 2024\n",
    "\n",
    "@author: camer\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "\n",
    "sample = pd.read_csv(\"data/sample2.csv\")\n",
    "test_size = 0.2\n",
    "column_names = [\n",
    "    \"dataset\", \"start_date\", \"start_time\", \"duration\", \"reverseDelta\", \"IoTMac\", \"hostMac\", \"IoTIP\", \"IoTIP_int\",\n",
    "    \"hostIP\", \"hostIP_int\", \"ipProto\", \"IoTPort\", \"hostPort\", \"PacketCount\", \"BytesCount\", \"reversePacketCount\",\n",
    "    \"reverseBytesCount\", \"SmallPktCount\", \"LargePktCount\", \"NonEmptyPktCount\", \"DataByteCount\", \"AvgIAT\",\n",
    "    \"FirstNonEmptyPktSize\", \"MaxPktSize\", \"StdevPayloadSize\", \"StdevIAT\", \"AvgPacketSize\", \"reverseSmallPktCount\",\n",
    "    \"reverseLargePktCount\", \"reverseNonEmptyPktCount\", \"reverseDataByteCount\", \"reverseAvgIAT\",\n",
    "    \"reverseFirstNonEmptyPktSize\", \"reverseMaxPktSize\", \"reverseStdevPayloadSize\", \"reverseStdevIAT\",\n",
    "    \"reverseAvgPacketSize\", \"reverseFlowExists\", \"remote\", \"broadcast\", \"HTTP\", \"HTTPS\", \"DNS\", \"NTP\", \"TCP_others\",\n",
    "    \"UDP_others\", \"year_month\"\n",
    "]\n",
    "sample.columns = column_names\n",
    "sample.head()\n",
    "sample_size = len(sample[\"dataset\"])\n",
    " \n",
    "heads = sample.drop(columns = ['dataset', 'start_date', 'start_time', 'IoTMac', 'IoTIP', 'IoTIP_int', 'year_month','hostMac'])\n",
    "data = pd.get_dummies(heads)\n",
    "classes = sample['IoTMac']\n",
    " \n",
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=test_size, random_state=42)\n",
    "del data\n",
    "import gc\n",
    "gc.collect()\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "X_train_weighted = X_train_scaled * feature_importances\n",
    "X_test_weighted = X_test_scaled * feature_importances\n",
    "# knn_regressor = KNeighborsRegressor(n_neighbors=5)\n",
    "# knn_regressor.fit(X_train, y_train)\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_classifier.fit(X_train_weighted, y_train)\n",
    "# y_pred = knn_regressor.predict(X_test)\n",
    "y_pred = knn_classifier.predict(X_test_weighted)\n",
    " \n",
    "labels = sorted(set(y_train) | set(y_test))\n",
    " \n",
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    " \n",
    " \n",
    "correct_classifications = cm.diagonal().sum()\n",
    "print(\"Number of correctly classified elements:\", correct_classifications)\n",
    "print(\"correct divide all:\", correct_classifications/(sample_size * test_size))\n",
    " \n",
    " \n",
    " \n",
    "# Display the confusion matrix\n",
    "# disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=knn_classifier.classes_)\n",
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "for f in cmatrix:\n",
    "    f += 1\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "sns.heatmap(cmatrix, annot=False, cmap='coolwarm', norm=LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   duration  reverseDelta  hostIP_int  ipProto  IoTPort  hostPort  \\\n",
      "0     0.000         0.000  4026531834       17    47087      1900   \n",
      "1     0.000         0.000  3232235777       17    26321        53   \n",
      "2     0.006         0.001  3232235777        6    41178     40480   \n",
      "3   240.117         0.007  2899909166        6    60388       443   \n",
      "4     5.001         0.000  3232235777       17    38645        53   \n",
      "\n",
      "   PacketCount  BytesCount  reversePacketCount  reverseBytesCount  \\\n",
      "0            1         294                   0                  0   \n",
      "1            1          75                   0                  0   \n",
      "2            7         452                   6               3238   \n",
      "3           19        5053                  21               2021   \n",
      "4            2         128                   0                  0   \n",
      "\n",
      "   SmallPktCount  LargePktCount  NonEmptyPktCount  DataByteCount  AvgIAT  \\\n",
      "0              0              1                 1            266       0   \n",
      "1              1              0                 1             47       0   \n",
      "2              0              0                 1             80       0   \n",
      "3              3              4                 8           4057   13339   \n",
      "4              2              0                 2             72    5001   \n",
      "\n",
      "   FirstNonEmptyPktSize  MaxPktSize  StdevPayloadSize  StdevIAT  \\\n",
      "0                   266         266                 0         0   \n",
      "1                    47          47                 0         0   \n",
      "2                    80          80                 0         1   \n",
      "3                   517        1486               560     13328   \n",
      "4                    36          36                 0         0   \n",
      "\n",
      "   AvgPacketSize  reverseSmallPktCount  reverseLargePktCount  \\\n",
      "0            266                     0                     0   \n",
      "1             47                     0                     0   \n",
      "2             80                     0                     2   \n",
      "3            507                     2                     1   \n",
      "4             36                     0                     0   \n",
      "\n",
      "   reverseNonEmptyPktCount  reverseDataByteCount  reverseAvgIAT  \\\n",
      "0                        0                     0              0   \n",
      "1                        0                     0              0   \n",
      "2                        2                  2918              1   \n",
      "3                        8                   921          12005   \n",
      "4                        0                     0              0   \n",
      "\n",
      "   reverseFirstNonEmptyPktSize  reverseMaxPktSize  reverseStdevPayloadSize  \\\n",
      "0                            0                  0                        0   \n",
      "1                            0                  0                        0   \n",
      "2                         1448               1470                       11   \n",
      "3                          156                280                       78   \n",
      "4                            0                  0                        0   \n",
      "\n",
      "   reverseStdevIAT  reverseAvgPacketSize  reverseFlowExists  remote  \\\n",
      "0                0                     0                  0       1   \n",
      "1                0                     0                  0       0   \n",
      "2                0                  1459                  1       0   \n",
      "3            11995                   115                  1       1   \n",
      "4                0                     0                  0       0   \n",
      "\n",
      "   broadcast  HTTP  HTTPS  DNS  NTP  TCP_others  UDP_others  hostIP_0.4.1.32  \\\n",
      "0          0     0      0    0    0           0           1            False   \n",
      "1          0     0      0    1    0           0           0            False   \n",
      "2          0     0      0    0    0           1           0            False   \n",
      "3          0     0      1    0    0           1           0            False   \n",
      "4          0     0      0    1    0           0           0            False   \n",
      "\n",
      "   hostIP_100.26.141.166  hostIP_104.71.156.206  hostIP_104.71.163.162  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_104.71.173.249  hostIP_104.78.1.12  hostIP_104.78.183.123  \\\n",
      "0                  False               False                  False   \n",
      "1                  False               False                  False   \n",
      "2                  False               False                  False   \n",
      "3                  False               False                  False   \n",
      "4                  False               False                  False   \n",
      "\n",
      "   hostIP_104.78.28.62  hostIP_104.78.29.66  hostIP_104.78.87.88  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_104.92.147.252  hostIP_107.22.211.223  hostIP_108.177.125.188  \\\n",
      "0                  False                  False                   False   \n",
      "1                  False                  False                   False   \n",
      "2                  False                  False                   False   \n",
      "3                  False                  False                   False   \n",
      "4                  False                  False                   False   \n",
      "\n",
      "   hostIP_108.177.97.188  hostIP_118.215.184.205  hostIP_125.209.222.142  \\\n",
      "0                  False                   False                   False   \n",
      "1                  False                   False                   False   \n",
      "2                  False                   False                   False   \n",
      "3                  False                   False                   False   \n",
      "4                  False                   False                   False   \n",
      "\n",
      "   hostIP_128.138.140.44  hostIP_129.6.15.27  hostIP_129.6.15.29  \\\n",
      "0                  False               False               False   \n",
      "1                  False               False               False   \n",
      "2                  False               False               False   \n",
      "3                  False               False               False   \n",
      "4                  False               False               False   \n",
      "\n",
      "   hostIP_13.112.7.137  hostIP_13.114.247.56  hostIP_13.224.151.104  \\\n",
      "0                False                 False                  False   \n",
      "1                False                 False                  False   \n",
      "2                False                 False                  False   \n",
      "3                False                 False                  False   \n",
      "4                False                 False                  False   \n",
      "\n",
      "   hostIP_13.225.103.124  hostIP_13.225.105.18  hostIP_13.225.122.166  \\\n",
      "0                  False                 False                  False   \n",
      "1                  False                 False                  False   \n",
      "2                  False                 False                  False   \n",
      "3                  False                 False                  False   \n",
      "4                  False                 False                  False   \n",
      "\n",
      "   hostIP_13.225.153.180  hostIP_13.225.157.143  hostIP_13.225.157.146  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_13.225.157.176  hostIP_13.225.157.49  hostIP_13.225.165.99  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_13.225.166.45  hostIP_13.225.166.61  hostIP_13.225.166.92  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_13.225.173.99  hostIP_13.225.176.180  hostIP_13.225.176.31  \\\n",
      "0                 False                  False                 False   \n",
      "1                 False                  False                 False   \n",
      "2                 False                  False                 False   \n",
      "3                 False                  False                 False   \n",
      "4                 False                  False                 False   \n",
      "\n",
      "   hostIP_13.225.176.54  hostIP_13.225.176.80  hostIP_13.225.178.200  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_13.225.178.27  hostIP_13.226.77.60  hostIP_13.227.49.170  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_13.227.49.48  hostIP_13.230.154.154  hostIP_13.231.11.213  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_13.249.153.22  hostIP_13.249.153.66  hostIP_13.249.166.139  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_13.249.166.40  hostIP_13.249.171.235  hostIP_13.32.52.100  \\\n",
      "0                 False                  False                False   \n",
      "1                 False                  False                False   \n",
      "2                 False                  False                False   \n",
      "3                 False                  False                False   \n",
      "4                 False                  False                False   \n",
      "\n",
      "   hostIP_13.32.54.12  hostIP_13.32.54.17  hostIP_13.32.54.88  \\\n",
      "0               False               False               False   \n",
      "1               False               False               False   \n",
      "2               False               False               False   \n",
      "3               False               False               False   \n",
      "4               False               False               False   \n",
      "\n",
      "   hostIP_13.33.14.135  hostIP_13.33.174.102  hostIP_13.33.174.181  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_13.33.174.219  hostIP_13.33.174.25  hostIP_13.33.215.117  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_13.33.4.37  hostIP_13.33.9.114  hostIP_13.33.9.142  \\\n",
      "0              False               False               False   \n",
      "1              False               False               False   \n",
      "2              False               False               False   \n",
      "3              False               False               False   \n",
      "4              False               False               False   \n",
      "\n",
      "   hostIP_13.33.9.220  hostIP_13.33.9.221  hostIP_13.35.27.191  \\\n",
      "0               False               False                False   \n",
      "1               False               False                False   \n",
      "2               False               False                False   \n",
      "3               False               False                False   \n",
      "4               False               False                False   \n",
      "\n",
      "   hostIP_13.35.50.52  hostIP_13.35.55.117  hostIP_13.35.55.12  \\\n",
      "0               False                False               False   \n",
      "1               False                False               False   \n",
      "2               False                False               False   \n",
      "3               False                False               False   \n",
      "4               False                False               False   \n",
      "\n",
      "   hostIP_13.35.55.17  hostIP_13.35.55.80  hostIP_13.35.65.227  \\\n",
      "0               False               False                False   \n",
      "1               False               False                False   \n",
      "2               False               False                False   \n",
      "3               False               False                False   \n",
      "4               False               False                False   \n",
      "\n",
      "   hostIP_132.163.96.2  hostIP_132.163.96.3  hostIP_133.243.238.163  \\\n",
      "0                False                False                   False   \n",
      "1                False                False                   False   \n",
      "2                False                False                   False   \n",
      "3                False                False                   False   \n",
      "4                False                False                   False   \n",
      "\n",
      "   hostIP_133.243.238.164  hostIP_133.243.238.243  hostIP_133.243.238.244  \\\n",
      "0                   False                   False                   False   \n",
      "1                   False                   False                   False   \n",
      "2                   False                   False                   False   \n",
      "3                   False                   False                   False   \n",
      "4                   False                   False                   False   \n",
      "\n",
      "   hostIP_133.243.239.101  hostIP_133.243.3.15  hostIP_139.162.61.175  \\\n",
      "0                   False                False                  False   \n",
      "1                   False                False                  False   \n",
      "2                   False                False                  False   \n",
      "3                   False                False                  False   \n",
      "4                   False                False                  False   \n",
      "\n",
      "   hostIP_141.223.182.106  hostIP_143.204.125.61  hostIP_143.204.126.161  \\\n",
      "0                   False                  False                   False   \n",
      "1                   False                  False                   False   \n",
      "2                   False                  False                   False   \n",
      "3                   False                  False                   False   \n",
      "4                   False                  False                   False   \n",
      "\n",
      "   hostIP_143.204.126.166  hostIP_143.204.126.209  hostIP_143.204.77.12  \\\n",
      "0                   False                   False                 False   \n",
      "1                   False                   False                 False   \n",
      "2                   False                   False                 False   \n",
      "3                   False                   False                 False   \n",
      "4                   False                   False                 False   \n",
      "\n",
      "   hostIP_143.204.77.187  hostIP_143.204.83.13  hostIP_150.31.180.114  \\\n",
      "0                  False                 False                  False   \n",
      "1                  False                 False                  False   \n",
      "2                  False                 False                  False   \n",
      "3                  False                 False                  False   \n",
      "4                  False                 False                  False   \n",
      "\n",
      "   hostIP_150.31.181.170  hostIP_153.120.166.67  hostIP_161.117.94.163  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_163.43.28.246  hostIP_169.254.37.92  hostIP_169.254.60.246  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_172.105.236.23  hostIP_172.217.161.35  hostIP_172.217.161.36  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.161.42  hostIP_172.217.161.46  hostIP_172.217.161.52  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.161.67  hostIP_172.217.161.68  hostIP_172.217.161.74  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.161.78  hostIP_172.217.161.86  hostIP_172.217.24.131  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.24.132  hostIP_172.217.24.134  hostIP_172.217.24.138  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.24.142  hostIP_172.217.24.148  hostIP_172.217.24.150  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.25.100  hostIP_172.217.25.106  hostIP_172.217.25.110  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.25.116  hostIP_172.217.25.118  hostIP_172.217.25.195  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.25.196  hostIP_172.217.25.202  hostIP_172.217.25.206  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.25.227  hostIP_172.217.25.228  hostIP_172.217.25.234  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.25.238  hostIP_172.217.25.67  hostIP_172.217.25.68  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_172.217.25.74  hostIP_172.217.25.78  hostIP_172.217.25.84  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_172.217.25.99  hostIP_172.217.26.10  hostIP_172.217.26.14  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_172.217.26.20  hostIP_172.217.26.3  hostIP_172.217.26.35  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_172.217.26.36  hostIP_172.217.26.4  hostIP_172.217.26.42  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_172.217.26.46  hostIP_172.217.27.67  hostIP_172.217.27.68  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                  True                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_172.217.27.74  hostIP_172.217.27.78  hostIP_172.217.27.86  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_172.217.31.131  hostIP_172.217.31.132  hostIP_172.217.31.138  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.31.142  hostIP_172.217.31.150  hostIP_172.217.31.163  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.31.164  hostIP_172.217.31.170  hostIP_172.217.31.174  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_172.217.31.180  hostIP_172.217.31.182  hostIP_176.32.101.52  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_176.32.98.203  hostIP_176.32.99.148  hostIP_18.179.227.169  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_18.215.97.182  hostIP_184.27.18.81  hostIP_184.31.36.62  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_184.73.147.99  hostIP_185.53.178.8  hostIP_192.168.1.1  \\\n",
      "0                 False                False               False   \n",
      "1                 False                False                True   \n",
      "2                 False                False                True   \n",
      "3                 False                False               False   \n",
      "4                 False                False                True   \n",
      "\n",
      "   hostIP_192.168.1.115  hostIP_192.168.1.202  hostIP_192.168.1.236  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_192.168.1.253  hostIP_192.168.1.255  hostIP_192.168.1.26  \\\n",
      "0                 False                 False                False   \n",
      "1                 False                 False                False   \n",
      "2                 False                 False                False   \n",
      "3                 False                 False                False   \n",
      "4                 False                 False                False   \n",
      "\n",
      "   hostIP_192.168.1.78  hostIP_192.168.1.79  hostIP_192.168.1.92  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_192.168.1.93  hostIP_202.213.124.129  hostIP_202.213.124.133  \\\n",
      "0                False                   False                   False   \n",
      "1                False                   False                   False   \n",
      "2                False                   False                   False   \n",
      "3                False                   False                   False   \n",
      "4                False                   False                   False   \n",
      "\n",
      "   hostIP_202.213.125.83  hostIP_202.213.127.17  hostIP_202.213.127.18  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_203.104.150.58  hostIP_203.104.150.60  hostIP_203.104.150.61  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_203.248.240.140  hostIP_210.140.77.191  hostIP_210.162.18.34  \\\n",
      "0                   False                  False                 False   \n",
      "1                   False                  False                 False   \n",
      "2                   False                  False                 False   \n",
      "3                   False                  False                 False   \n",
      "4                   False                  False                 False   \n",
      "\n",
      "   hostIP_210.196.129.139  hostIP_210.196.129.140  hostIP_210.196.79.193  \\\n",
      "0                   False                   False                  False   \n",
      "1                   False                   False                  False   \n",
      "2                   False                   False                  False   \n",
      "3                   False                   False                  False   \n",
      "4                   False                   False                  False   \n",
      "\n",
      "   hostIP_210.89.160.88  hostIP_211.19.59.28  hostIP_211.233.84.186  \\\n",
      "0                 False                False                  False   \n",
      "1                 False                False                  False   \n",
      "2                 False                False                  False   \n",
      "3                 False                False                  False   \n",
      "4                 False                False                  False   \n",
      "\n",
      "   hostIP_216.239.35.0  hostIP_216.239.35.12  hostIP_216.239.35.4  \\\n",
      "0                False                 False                False   \n",
      "1                False                 False                False   \n",
      "2                False                 False                False   \n",
      "3                False                 False                False   \n",
      "4                False                 False                False   \n",
      "\n",
      "   hostIP_216.239.35.8  hostIP_216.58.197.131  hostIP_216.58.197.132  \\\n",
      "0                False                  False                  False   \n",
      "1                False                  False                  False   \n",
      "2                False                  False                  False   \n",
      "3                False                  False                  False   \n",
      "4                False                  False                  False   \n",
      "\n",
      "   hostIP_216.58.197.138  hostIP_216.58.197.14  hostIP_216.58.197.142  \\\n",
      "0                  False                 False                  False   \n",
      "1                  False                 False                  False   \n",
      "2                  False                 False                  False   \n",
      "3                  False                 False                  False   \n",
      "4                  False                 False                  False   \n",
      "\n",
      "   hostIP_216.58.197.163  hostIP_216.58.197.164  hostIP_216.58.197.170  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_216.58.197.174  hostIP_216.58.197.180  hostIP_216.58.197.195  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_216.58.197.196  hostIP_216.58.197.202  hostIP_216.58.197.206  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_216.58.197.212  hostIP_216.58.197.227  hostIP_216.58.197.228  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_216.58.197.234  hostIP_216.58.197.238  hostIP_216.58.197.244  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_216.58.197.4  hostIP_220.159.23.75  hostIP_222.158.245.162  \\\n",
      "0                False                 False                   False   \n",
      "1                False                 False                   False   \n",
      "2                False                 False                   False   \n",
      "3                False                 False                   False   \n",
      "4                False                 False                   False   \n",
      "\n",
      "   hostIP_224.0.0.113  hostIP_224.0.0.251  hostIP_23.10.3.178  \\\n",
      "0               False               False               False   \n",
      "1               False               False               False   \n",
      "2               False               False               False   \n",
      "3               False               False               False   \n",
      "4               False               False               False   \n",
      "\n",
      "   hostIP_23.2.130.146  hostIP_23.2.132.69  hostIP_23.2.142.23  \\\n",
      "0                False               False               False   \n",
      "1                False               False               False   \n",
      "2                False               False               False   \n",
      "3                False               False               False   \n",
      "4                False               False               False   \n",
      "\n",
      "   hostIP_23.2.2.154  hostIP_23.2.37.91  hostIP_23.206.254.139  \\\n",
      "0              False              False                  False   \n",
      "1              False              False                  False   \n",
      "2              False              False                  False   \n",
      "3              False              False                  False   \n",
      "4              False              False                  False   \n",
      "\n",
      "   hostIP_23.207.104.173  hostIP_23.207.96.50  hostIP_23.209.32.89  \\\n",
      "0                  False                False                False   \n",
      "1                  False                False                False   \n",
      "2                  False                False                False   \n",
      "3                  False                False                False   \n",
      "4                  False                False                False   \n",
      "\n",
      "   hostIP_23.211.99.223  hostIP_23.218.44.30  hostIP_23.246.47.152  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_23.34.104.163  hostIP_23.34.105.44  hostIP_23.35.176.22  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_23.35.192.103  hostIP_23.35.196.14  hostIP_23.37.146.24  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_23.37.157.177  hostIP_23.41.21.131  hostIP_23.42.104.156  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_23.46.220.29  hostIP_23.50.236.34  hostIP_23.51.208.16  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_23.9.172.29  hostIP_239.255.255.250  hostIP_3.112.164.182  \\\n",
      "0               False                    True                 False   \n",
      "1               False                   False                 False   \n",
      "2               False                   False                 False   \n",
      "3               False                   False                 False   \n",
      "4               False                   False                 False   \n",
      "\n",
      "   hostIP_3.213.177.166  hostIP_3.216.156.180  hostIP_3.223.26.89  \\\n",
      "0                 False                 False               False   \n",
      "1                 False                 False               False   \n",
      "2                 False                 False               False   \n",
      "3                 False                 False               False   \n",
      "4                 False                 False               False   \n",
      "\n",
      "   hostIP_3.226.17.54  hostIP_3.227.37.12  hostIP_3.81.202.210  \\\n",
      "0               False               False                False   \n",
      "1               False               False                False   \n",
      "2               False               False                False   \n",
      "3               False               False                False   \n",
      "4               False               False                False   \n",
      "\n",
      "   hostIP_3.84.119.101  hostIP_3.86.45.125  hostIP_3.87.76.4  \\\n",
      "0                False               False             False   \n",
      "1                False               False             False   \n",
      "2                False               False             False   \n",
      "3                False               False             False   \n",
      "4                False               False             False   \n",
      "\n",
      "   hostIP_3.88.203.170  hostIP_34.192.162.158  hostIP_34.193.124.179  \\\n",
      "0                False                  False                  False   \n",
      "1                False                  False                  False   \n",
      "2                False                  False                  False   \n",
      "3                False                  False                  False   \n",
      "4                False                  False                  False   \n",
      "\n",
      "   hostIP_34.193.167.69  hostIP_34.194.219.224  hostIP_34.196.74.50  \\\n",
      "0                 False                  False                False   \n",
      "1                 False                  False                False   \n",
      "2                 False                  False                False   \n",
      "3                 False                  False                False   \n",
      "4                 False                  False                False   \n",
      "\n",
      "   hostIP_34.198.70.51  hostIP_34.200.37.26  hostIP_34.201.126.158  \\\n",
      "0                False                False                  False   \n",
      "1                False                False                  False   \n",
      "2                False                False                  False   \n",
      "3                False                False                  False   \n",
      "4                False                False                  False   \n",
      "\n",
      "   hostIP_34.202.204.73  hostIP_34.202.250.167  hostIP_34.203.47.230  \\\n",
      "0                 False                  False                 False   \n",
      "1                 False                  False                 False   \n",
      "2                 False                  False                 False   \n",
      "3                 False                  False                 False   \n",
      "4                 False                  False                 False   \n",
      "\n",
      "   hostIP_34.204.208.130  hostIP_34.204.22.118  hostIP_34.204.238.125  \\\n",
      "0                  False                 False                  False   \n",
      "1                  False                 False                  False   \n",
      "2                  False                 False                  False   \n",
      "3                  False                 False                  False   \n",
      "4                  False                 False                  False   \n",
      "\n",
      "   hostIP_34.205.61.194  hostIP_34.206.137.106  hostIP_34.206.209.190  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_34.206.236.142  hostIP_34.206.247.101  hostIP_34.206.91.215  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_34.208.11.132  hostIP_34.208.118.225  hostIP_34.208.135.230  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_34.208.146.1  hostIP_34.208.227.237  hostIP_34.208.28.151  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_34.209.120.117  hostIP_34.209.42.8  hostIP_34.209.70.105  \\\n",
      "0                  False               False                 False   \n",
      "1                  False               False                 False   \n",
      "2                  False               False                 False   \n",
      "3                  False               False                 False   \n",
      "4                  False               False                 False   \n",
      "\n",
      "   hostIP_34.210.171.188  hostIP_34.211.182.151  hostIP_34.211.212.7  \\\n",
      "0                  False                  False                False   \n",
      "1                  False                  False                False   \n",
      "2                  False                  False                False   \n",
      "3                  False                  False                False   \n",
      "4                  False                  False                False   \n",
      "\n",
      "   hostIP_34.211.85.239  hostIP_34.212.241.208  hostIP_34.213.36.29  \\\n",
      "0                 False                  False                False   \n",
      "1                 False                  False                False   \n",
      "2                 False                  False                False   \n",
      "3                 False                  False                False   \n",
      "4                 False                  False                False   \n",
      "\n",
      "   hostIP_34.213.4.245  hostIP_34.213.8.73  hostIP_34.213.87.172  \\\n",
      "0                False               False                 False   \n",
      "1                False               False                 False   \n",
      "2                False               False                 False   \n",
      "3                False               False                 False   \n",
      "4                False               False                 False   \n",
      "\n",
      "   hostIP_34.214.146.70  hostIP_34.214.82.50  hostIP_34.215.25.28  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_34.215.75.178  hostIP_34.216.95.171  hostIP_34.218.65.98  \\\n",
      "0                 False                 False                False   \n",
      "1                 False                 False                False   \n",
      "2                 False                 False                False   \n",
      "3                 False                 False                False   \n",
      "4                 False                 False                False   \n",
      "\n",
      "   hostIP_34.224.153.218  hostIP_34.224.211.133  hostIP_34.226.180.126  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_34.227.1.63  hostIP_34.227.230.104  hostIP_34.229.28.235  \\\n",
      "0               False                  False                 False   \n",
      "1               False                  False                 False   \n",
      "2               False                  False                 False   \n",
      "3               False                  False                 False   \n",
      "4               False                  False                 False   \n",
      "\n",
      "   hostIP_34.230.207.5  hostIP_34.230.237.199  hostIP_34.230.98.108  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_34.231.232.204  hostIP_34.232.226.142  hostIP_34.232.33.212  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_34.232.88.134  hostIP_34.233.181.224  hostIP_34.234.109.38  \\\n",
      "0                 False                  False                 False   \n",
      "1                 False                  False                 False   \n",
      "2                 False                  False                 False   \n",
      "3                 False                  False                 False   \n",
      "4                 False                  False                 False   \n",
      "\n",
      "   hostIP_34.234.42.132  hostIP_34.235.104.92  hostIP_34.235.108.111  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_34.235.98.12  hostIP_34.236.102.213  hostIP_34.236.107.1  \\\n",
      "0                False                  False                False   \n",
      "1                False                  False                False   \n",
      "2                False                  False                False   \n",
      "3                False                  False                False   \n",
      "4                False                  False                False   \n",
      "\n",
      "   hostIP_34.236.202.175  hostIP_34.237.207.243  hostIP_34.85.47.16  \\\n",
      "0                  False                  False               False   \n",
      "1                  False                  False               False   \n",
      "2                  False                  False               False   \n",
      "3                  False                  False               False   \n",
      "4                  False                  False               False   \n",
      "\n",
      "   hostIP_34.90.171.169  hostIP_34.90.173.53  hostIP_35.160.25.5  \\\n",
      "0                 False                False               False   \n",
      "1                 False                False               False   \n",
      "2                 False                False               False   \n",
      "3                 False                False               False   \n",
      "4                 False                False               False   \n",
      "\n",
      "   hostIP_35.160.27.49  hostIP_35.160.74.29  hostIP_35.161.122.185  \\\n",
      "0                False                False                  False   \n",
      "1                False                False                  False   \n",
      "2                False                False                  False   \n",
      "3                False                False                  False   \n",
      "4                False                False                  False   \n",
      "\n",
      "   hostIP_35.161.33.231  hostIP_35.161.34.12  hostIP_35.162.98.170  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_35.163.13.81  hostIP_35.163.241.134  hostIP_35.163.71.114  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_35.163.8.35  hostIP_35.164.103.50  hostIP_35.164.106.194  \\\n",
      "0               False                 False                  False   \n",
      "1               False                 False                  False   \n",
      "2               False                 False                  False   \n",
      "3               False                 False                  False   \n",
      "4               False                 False                  False   \n",
      "\n",
      "   hostIP_35.164.244.233  hostIP_35.165.141.208  hostIP_35.165.97.83  \\\n",
      "0                  False                  False                False   \n",
      "1                  False                  False                False   \n",
      "2                  False                  False                False   \n",
      "3                  False                  False                False   \n",
      "4                  False                  False                False   \n",
      "\n",
      "   hostIP_35.166.107.234  hostIP_35.167.144.130  hostIP_35.167.157.99  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_35.167.237.37  hostIP_35.169.33.119  hostIP_35.173.240.57  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_35.189.142.105  hostIP_35.197.82.39  hostIP_35.203.134.251  \\\n",
      "0                  False                False                  False   \n",
      "1                  False                False                  False   \n",
      "2                  False                False                  False   \n",
      "3                  False                False                  False   \n",
      "4                  False                False                  False   \n",
      "\n",
      "   hostIP_47.74.133.42  hostIP_47.74.144.176  hostIP_47.88.174.248  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_47.88.175.190  hostIP_47.88.221.18  hostIP_47.88.222.245  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_50.17.213.27  hostIP_50.19.205.119  hostIP_50.19.254.134  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_52.0.140.227  hostIP_52.0.143.13  hostIP_52.0.146.122  \\\n",
      "0                False               False                False   \n",
      "1                False               False                False   \n",
      "2                False               False                False   \n",
      "3                False               False                False   \n",
      "4                False               False                False   \n",
      "\n",
      "   hostIP_52.0.38.79  hostIP_52.1.167.97  hostIP_52.1.196.224  \\\n",
      "0              False               False                False   \n",
      "1              False               False                False   \n",
      "2              False               False                False   \n",
      "3              False               False                False   \n",
      "4              False               False                False   \n",
      "\n",
      "   hostIP_52.10.131.142  hostIP_52.10.162.81  hostIP_52.10.170.249  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_52.10.173.232  hostIP_52.10.246.46  hostIP_52.10.251.82  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_52.11.139.105  hostIP_52.11.9.91  hostIP_52.119.161.177  \\\n",
      "0                 False              False                  False   \n",
      "1                 False              False                  False   \n",
      "2                 False              False                  False   \n",
      "3                 False              False                  False   \n",
      "4                 False              False                  False   \n",
      "\n",
      "   hostIP_52.119.162.179  hostIP_52.119.164.210  hostIP_52.119.168.147  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.119.168.148  hostIP_52.119.196.25  hostIP_52.119.196.66  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_52.119.196.87  hostIP_52.193.210.16  hostIP_52.197.1.111  \\\n",
      "0                 False                 False                False   \n",
      "1                 False                 False                False   \n",
      "2                 False                 False                False   \n",
      "3                 False                 False                False   \n",
      "4                 False                 False                False   \n",
      "\n",
      "   hostIP_52.197.92.45  hostIP_52.198.235.92  hostIP_52.199.146.90  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_52.199.156.28  hostIP_52.2.18.6  hostIP_52.2.204.77  \\\n",
      "0                 False             False               False   \n",
      "1                 False             False               False   \n",
      "2                 False             False               False   \n",
      "3                 False             False               False   \n",
      "4                 False             False               False   \n",
      "\n",
      "   hostIP_52.2.249.117  hostIP_52.2.73.101  hostIP_52.20.132.200  \\\n",
      "0                False               False                 False   \n",
      "1                False               False                 False   \n",
      "2                False               False                 False   \n",
      "3                False               False                 False   \n",
      "4                False               False                 False   \n",
      "\n",
      "   hostIP_52.20.175.169  hostIP_52.20.246.12  hostIP_52.200.140.10  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_52.201.117.39  hostIP_52.201.227.246  hostIP_52.202.182.249  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_52.202.25.104  hostIP_52.202.69.222  hostIP_52.204.213.123  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_52.205.128.212  hostIP_52.205.198.186  hostIP_52.206.55.236  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_52.207.126.43  hostIP_52.207.177.211  hostIP_52.207.201.93  \\\n",
      "0                 False                  False                 False   \n",
      "1                 False                  False                 False   \n",
      "2                 False                  False                 False   \n",
      "3                 False                  False                 False   \n",
      "4                 False                  False                 False   \n",
      "\n",
      "   hostIP_52.207.205.49  hostIP_52.207.91.135  hostIP_52.208.124.161  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_52.209.221.129  hostIP_52.21.155.181  hostIP_52.21.158.86  \\\n",
      "0                  False                 False                False   \n",
      "1                  False                 False                False   \n",
      "2                  False                 False                False   \n",
      "3                  False                 False                False   \n",
      "4                  False                 False                False   \n",
      "\n",
      "   hostIP_52.21.54.132  hostIP_52.213.192.178  hostIP_52.216.10.131  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_52.216.10.139  hostIP_52.216.10.27  hostIP_52.216.100.211  \\\n",
      "0                 False                False                  False   \n",
      "1                 False                False                  False   \n",
      "2                 False                False                  False   \n",
      "3                 False                False                  False   \n",
      "4                 False                False                  False   \n",
      "\n",
      "   hostIP_52.216.101.227  hostIP_52.216.104.139  hostIP_52.216.104.187  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.105.155  hostIP_52.216.105.219  hostIP_52.216.106.107  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.106.51  hostIP_52.216.107.148  hostIP_52.216.107.4  \\\n",
      "0                 False                  False                False   \n",
      "1                 False                  False                False   \n",
      "2                 False                  False                False   \n",
      "3                 False                  False                False   \n",
      "4                 False                  False                False   \n",
      "\n",
      "   hostIP_52.216.107.60  hostIP_52.216.108.163  hostIP_52.216.108.251  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.109.115  hostIP_52.216.109.139  hostIP_52.216.109.203  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.109.251  hostIP_52.216.110.131  hostIP_52.216.110.51  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_52.216.110.67  hostIP_52.216.111.83  hostIP_52.216.112.251  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_52.216.113.211  hostIP_52.216.113.27  hostIP_52.216.113.35  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.114.171  hostIP_52.216.114.27  hostIP_52.216.128.211  \\\n",
      "0                  False                 False                  False   \n",
      "1                  False                 False                  False   \n",
      "2                  False                 False                  False   \n",
      "3                  False                 False                  False   \n",
      "4                  False                 False                  False   \n",
      "\n",
      "   hostIP_52.216.128.83  hostIP_52.216.128.91  hostIP_52.216.129.19  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.131.171  hostIP_52.216.133.27  hostIP_52.216.134.19  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.134.3  hostIP_52.216.134.67  hostIP_52.216.138.131  \\\n",
      "0                False                 False                  False   \n",
      "1                False                 False                  False   \n",
      "2                False                 False                  False   \n",
      "3                False                 False                  False   \n",
      "4                False                 False                  False   \n",
      "\n",
      "   hostIP_52.216.144.11  hostIP_52.216.144.27  hostIP_52.216.145.19  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.145.219  hostIP_52.216.145.3  hostIP_52.216.146.203  \\\n",
      "0                  False                False                  False   \n",
      "1                  False                False                  False   \n",
      "2                  False                False                  False   \n",
      "3                  False                False                  False   \n",
      "4                  False                False                  False   \n",
      "\n",
      "   hostIP_52.216.146.211  hostIP_52.216.146.243  hostIP_52.216.146.67  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_52.216.147.27  hostIP_52.216.147.51  hostIP_52.216.147.75  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.161.227  hostIP_52.216.161.235  hostIP_52.216.162.131  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.162.155  hostIP_52.216.162.19  hostIP_52.216.163.139  \\\n",
      "0                  False                 False                  False   \n",
      "1                  False                 False                  False   \n",
      "2                  False                 False                  False   \n",
      "3                  False                 False                  False   \n",
      "4                  False                 False                  False   \n",
      "\n",
      "   hostIP_52.216.164.19  hostIP_52.216.164.235  hostIP_52.216.164.3  \\\n",
      "0                 False                  False                False   \n",
      "1                 False                  False                False   \n",
      "2                 False                  False                False   \n",
      "3                 False                  False                False   \n",
      "4                 False                  False                False   \n",
      "\n",
      "   hostIP_52.216.165.123  hostIP_52.216.169.139  hostIP_52.216.170.115  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.170.203  hostIP_52.216.170.211  hostIP_52.216.171.123  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.177.11  hostIP_52.216.177.147  hostIP_52.216.177.203  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.178.115  hostIP_52.216.178.83  hostIP_52.216.179.43  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.179.75  hostIP_52.216.18.40  hostIP_52.216.184.219  \\\n",
      "0                 False                False                  False   \n",
      "1                 False                False                  False   \n",
      "2                 False                False                  False   \n",
      "3                 False                False                  False   \n",
      "4                 False                False                  False   \n",
      "\n",
      "   hostIP_52.216.185.171  hostIP_52.216.186.139  hostIP_52.216.19.56  \\\n",
      "0                  False                  False                False   \n",
      "1                  False                  False                False   \n",
      "2                  False                  False                False   \n",
      "3                  False                  False                False   \n",
      "4                  False                  False                False   \n",
      "\n",
      "   hostIP_52.216.19.88  hostIP_52.216.200.147  hostIP_52.216.204.147  \\\n",
      "0                False                  False                  False   \n",
      "1                False                  False                  False   \n",
      "2                False                  False                  False   \n",
      "3                False                  False                  False   \n",
      "4                False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.205.139  hostIP_52.216.205.67  hostIP_52.216.205.83  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.21.67  hostIP_52.216.228.176  hostIP_52.216.228.208  \\\n",
      "0                False                  False                  False   \n",
      "1                False                  False                  False   \n",
      "2                False                  False                  False   \n",
      "3                False                  False                  False   \n",
      "4                False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.229.219  hostIP_52.216.230.155  hostIP_52.216.230.235  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.232.163  hostIP_52.216.232.19  hostIP_52.216.233.147  \\\n",
      "0                  False                 False                  False   \n",
      "1                  False                 False                  False   \n",
      "2                  False                 False                  False   \n",
      "3                  False                 False                  False   \n",
      "4                  False                 False                  False   \n",
      "\n",
      "   hostIP_52.216.233.3  hostIP_52.216.233.67  hostIP_52.216.233.83  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_52.216.236.163  hostIP_52.216.236.179  hostIP_52.216.237.243  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.238.163  hostIP_52.216.238.251  hostIP_52.216.239.179  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.216.241.124  hostIP_52.216.8.251  hostIP_52.216.84.115  \\\n",
      "0                  False                False                 False   \n",
      "1                  False                False                 False   \n",
      "2                  False                False                 False   \n",
      "3                  False                False                 False   \n",
      "4                  False                False                 False   \n",
      "\n",
      "   hostIP_52.216.84.195  hostIP_52.216.84.80  hostIP_52.216.85.139  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_52.216.9.115  hostIP_52.216.92.3  hostIP_52.216.93.115  \\\n",
      "0                False               False                 False   \n",
      "1                False               False                 False   \n",
      "2                False               False                 False   \n",
      "3                False               False                 False   \n",
      "4                False               False                 False   \n",
      "\n",
      "   hostIP_52.216.94.75  hostIP_52.216.95.171  hostIP_52.216.96.3  \\\n",
      "0                False                 False               False   \n",
      "1                False                 False               False   \n",
      "2                False                 False               False   \n",
      "3                False                 False               False   \n",
      "4                False                 False               False   \n",
      "\n",
      "   hostIP_52.216.97.227  hostIP_52.216.97.43  hostIP_52.216.98.251  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_52.216.98.51  hostIP_52.216.99.147  hostIP_52.217.0.27  \\\n",
      "0                False                 False               False   \n",
      "1                False                 False               False   \n",
      "2                False                 False               False   \n",
      "3                False                 False               False   \n",
      "4                False                 False               False   \n",
      "\n",
      "   hostIP_52.217.0.83  hostIP_52.217.1.252  hostIP_52.217.1.44  \\\n",
      "0               False                False               False   \n",
      "1               False                False               False   \n",
      "2               False                False               False   \n",
      "3               False                False               False   \n",
      "4               False                False               False   \n",
      "\n",
      "   hostIP_52.217.32.116  hostIP_52.217.32.20  hostIP_52.217.36.228  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_52.217.36.44  hostIP_52.217.38.116  hostIP_52.217.38.212  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_52.217.38.28  hostIP_52.217.8.212  hostIP_52.219.68.38  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_52.222.201.159  hostIP_52.222.201.216  hostIP_52.222.205.152  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_52.222.205.153  hostIP_52.24.135.130  hostIP_52.25.135.146  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_52.25.91.36  hostIP_52.25.99.95  hostIP_52.26.10.162  \\\n",
      "0               False               False                False   \n",
      "1               False               False                False   \n",
      "2               False               False                False   \n",
      "3               False               False                False   \n",
      "4               False               False                False   \n",
      "\n",
      "   hostIP_52.26.166.3  hostIP_52.26.173.21  hostIP_52.26.193.129  \\\n",
      "0               False                False                 False   \n",
      "1               False                False                 False   \n",
      "2               False                False                 False   \n",
      "3               False                False                 False   \n",
      "4               False                False                 False   \n",
      "\n",
      "   hostIP_52.26.198.20  hostIP_52.27.139.245  hostIP_52.27.165.87  \\\n",
      "0                False                 False                False   \n",
      "1                False                 False                False   \n",
      "2                False                 False                False   \n",
      "3                False                 False                False   \n",
      "4                False                 False                False   \n",
      "\n",
      "   hostIP_52.27.44.151  hostIP_52.27.48.202  hostIP_52.3.123.204  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_52.3.175.140  hostIP_52.31.143.145  hostIP_52.32.106.245  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_52.32.116.201  hostIP_52.32.157.2  hostIP_52.32.205.4  \\\n",
      "0                 False               False               False   \n",
      "1                 False               False               False   \n",
      "2                 False               False               False   \n",
      "3                 False               False               False   \n",
      "4                 False               False               False   \n",
      "\n",
      "   hostIP_52.32.214.121  hostIP_52.32.44.85  hostIP_52.32.62.213  \\\n",
      "0                 False               False                False   \n",
      "1                 False               False                False   \n",
      "2                 False               False                False   \n",
      "3                 False               False                False   \n",
      "4                 False               False                False   \n",
      "\n",
      "   hostIP_52.33.233.73  hostIP_52.33.234.5  hostIP_52.33.66.52  \\\n",
      "0                False               False               False   \n",
      "1                False               False               False   \n",
      "2                False               False               False   \n",
      "3                False               False               False   \n",
      "4                False               False               False   \n",
      "\n",
      "   hostIP_52.34.110.118  hostIP_52.35.167.163  hostIP_52.36.157.158  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_52.36.229.246  hostIP_52.37.59.250  hostIP_52.37.88.51  \\\n",
      "0                 False                False               False   \n",
      "1                 False                False               False   \n",
      "2                 False                False               False   \n",
      "3                 False                False               False   \n",
      "4                 False                False               False   \n",
      "\n",
      "   hostIP_52.38.158.154  hostIP_52.39.200.39  hostIP_52.39.232.255  \\\n",
      "0                 False                False                 False   \n",
      "1                 False                False                 False   \n",
      "2                 False                False                 False   \n",
      "3                 False                False                 False   \n",
      "4                 False                False                 False   \n",
      "\n",
      "   hostIP_52.4.45.89  hostIP_52.40.123.84  hostIP_52.40.145.183  \\\n",
      "0              False                False                 False   \n",
      "1              False                False                 False   \n",
      "2              False                False                 False   \n",
      "3              False                False                 False   \n",
      "4              False                False                 False   \n",
      "\n",
      "   hostIP_52.40.15.135  hostIP_52.40.58.4  hostIP_52.41.165.115  \\\n",
      "0                False              False                 False   \n",
      "1                False              False                 False   \n",
      "2                False              False                 False   \n",
      "3                False              False                 False   \n",
      "4                False              False                 False   \n",
      "\n",
      "   hostIP_52.41.209.251  hostIP_52.41.217.163  hostIP_52.42.132.253  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_52.42.158.252  hostIP_52.42.228.219  hostIP_52.42.42.133  \\\n",
      "0                 False                 False                False   \n",
      "1                 False                 False                False   \n",
      "2                 False                 False                False   \n",
      "3                 False                 False                False   \n",
      "4                 False                 False                False   \n",
      "\n",
      "   hostIP_52.42.49.230  hostIP_52.42.98.162  hostIP_52.43.114.131  \\\n",
      "0                False                False                 False   \n",
      "1                False                False                 False   \n",
      "2                False                False                 False   \n",
      "3                False                False                 False   \n",
      "4                False                False                 False   \n",
      "\n",
      "   hostIP_52.43.138.106  hostIP_52.43.160.52  hostIP_52.43.20.12  \\\n",
      "0                 False                False               False   \n",
      "1                 False                False               False   \n",
      "2                 False                False               False   \n",
      "3                 False                False               False   \n",
      "4                 False                False               False   \n",
      "\n",
      "   hostIP_52.43.211.159  hostIP_52.43.242.246  hostIP_52.43.80.65  \\\n",
      "0                 False                 False               False   \n",
      "1                 False                 False               False   \n",
      "2                 False                 False               False   \n",
      "3                 False                 False               False   \n",
      "4                 False                 False               False   \n",
      "\n",
      "   hostIP_52.44.137.93  hostIP_52.44.143.101  hostIP_52.45.169.168  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_52.46.128.105  hostIP_52.46.129.109  hostIP_52.46.129.41  \\\n",
      "0                 False                 False                False   \n",
      "1                 False                 False                False   \n",
      "2                 False                 False                False   \n",
      "3                 False                 False                False   \n",
      "4                 False                 False                False   \n",
      "\n",
      "   hostIP_52.46.132.96  hostIP_52.46.133.39  hostIP_52.46.141.48  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_52.46.145.58  hostIP_52.46.158.193  hostIP_52.46.159.66  \\\n",
      "0                False                 False                False   \n",
      "1                False                 False                False   \n",
      "2                False                 False                False   \n",
      "3                False                 False                False   \n",
      "4                False                 False                False   \n",
      "\n",
      "   hostIP_52.5.171.20  hostIP_52.5.249.234  hostIP_52.52.134.18  \\\n",
      "0               False                False                False   \n",
      "1               False                False                False   \n",
      "2               False                False                False   \n",
      "3               False                False                False   \n",
      "4               False                False                False   \n",
      "\n",
      "   hostIP_52.54.10.4  hostIP_52.6.173.73  hostIP_52.6.75.180  \\\n",
      "0              False               False               False   \n",
      "1              False               False               False   \n",
      "2              False               False               False   \n",
      "3              False               False               False   \n",
      "4              False               False               False   \n",
      "\n",
      "   hostIP_52.68.228.91  hostIP_52.68.55.167  hostIP_52.7.141.127  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_52.7.169.168  hostIP_52.7.184.66  hostIP_52.7.20.178  \\\n",
      "0                False               False               False   \n",
      "1                False               False               False   \n",
      "2                False               False               False   \n",
      "3                False               False               False   \n",
      "4                False               False               False   \n",
      "\n",
      "   hostIP_52.7.75.32  hostIP_52.71.43.251  hostIP_52.72.166.101  \\\n",
      "0              False                False                 False   \n",
      "1              False                False                 False   \n",
      "2              False                False                 False   \n",
      "3              False                False                 False   \n",
      "4              False                False                 False   \n",
      "\n",
      "   hostIP_52.73.138.113  hostIP_52.73.224.7  hostIP_52.73.251.28  \\\n",
      "0                 False               False                False   \n",
      "1                 False               False                False   \n",
      "2                 False               False                False   \n",
      "3                 False               False                False   \n",
      "4                 False               False                False   \n",
      "\n",
      "   hostIP_52.73.53.78  hostIP_52.84.254.66  hostIP_52.88.19.36  \\\n",
      "0               False                False               False   \n",
      "1               False                False               False   \n",
      "2               False                False               False   \n",
      "3               False                False               False   \n",
      "4               False                False               False   \n",
      "\n",
      "   hostIP_52.89.125.155  hostIP_52.89.48.213  hostIP_52.9.115.122  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_52.9.214.97  hostIP_52.9.51.216  hostIP_52.9.64.62  \\\n",
      "0               False               False              False   \n",
      "1               False               False              False   \n",
      "2               False               False              False   \n",
      "3               False               False              False   \n",
      "4               False               False              False   \n",
      "\n",
      "   hostIP_52.94.228.52  hostIP_52.94.228.85  hostIP_52.94.229.76  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_52.94.232.195  hostIP_52.94.232.206  hostIP_52.94.232.230  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_52.94.240.157  hostIP_52.94.241.86  hostIP_54.148.10.42  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_54.148.156.148  hostIP_54.148.229.18  hostIP_54.148.81.9  \\\n",
      "0                  False                 False               False   \n",
      "1                  False                 False               False   \n",
      "2                  False                 False               False   \n",
      "3                  False                 False               False   \n",
      "4                  False                 False               False   \n",
      "\n",
      "   hostIP_54.149.179.70  hostIP_54.149.232.167  hostIP_54.162.224.174  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_54.164.173.30  hostIP_54.164.18.206  hostIP_54.164.181.42  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.164.205.93  hostIP_54.164.207.213  hostIP_54.164.216.123  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_54.165.213.66  hostIP_54.165.252.77  hostIP_54.173.178.127  \\\n",
      "0                 False                 False                  False   \n",
      "1                 False                 False                  False   \n",
      "2                 False                 False                  False   \n",
      "3                 False                 False                  False   \n",
      "4                 False                 False                  False   \n",
      "\n",
      "   hostIP_54.175.177.212  hostIP_54.175.238.199  hostIP_54.183.20.68  \\\n",
      "0                  False                  False                False   \n",
      "1                  False                  False                False   \n",
      "2                  False                  False                False   \n",
      "3                  False                  False                False   \n",
      "4                  False                  False                False   \n",
      "\n",
      "   hostIP_54.186.120.37  hostIP_54.186.194.37  hostIP_54.186.195.66  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.186.244.101  hostIP_54.187.197.125  hostIP_54.191.1.237  \\\n",
      "0                  False                  False                False   \n",
      "1                  False                  False                False   \n",
      "2                  False                  False                False   \n",
      "3                  False                  False                False   \n",
      "4                  False                  False                False   \n",
      "\n",
      "   hostIP_54.191.101.74  hostIP_54.191.14.224  hostIP_54.191.204.31  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.191.88.96  hostIP_54.192.111.172  hostIP_54.199.132.50  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_54.199.57.189  hostIP_54.205.129.27  hostIP_54.208.154.79  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.208.206.93  hostIP_54.208.30.245  hostIP_54.213.83.135  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.221.169.1  hostIP_54.224.29.73  hostIP_54.226.36.106  \\\n",
      "0                False                False                 False   \n",
      "1                False                False                 False   \n",
      "2                False                False                 False   \n",
      "3                False                False                 False   \n",
      "4                False                False                 False   \n",
      "\n",
      "   hostIP_54.227.93.14  hostIP_54.230.109.129  hostIP_54.230.109.13  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_54.230.109.138  hostIP_54.230.109.232  hostIP_54.230.109.88  \\\n",
      "0                  False                  False                 False   \n",
      "1                  False                  False                 False   \n",
      "2                  False                  False                 False   \n",
      "3                  False                  False                 False   \n",
      "4                  False                  False                 False   \n",
      "\n",
      "   hostIP_54.230.175.252  hostIP_54.231.11.152  hostIP_54.231.115.19  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_54.231.120.19  hostIP_54.231.40.203  hostIP_54.231.72.235  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.231.72.43  hostIP_54.238.198.224  hostIP_54.239.18.122  \\\n",
      "0                False                  False                 False   \n",
      "1                False                  False                 False   \n",
      "2                False                  False                 False   \n",
      "3                False                  False                 False   \n",
      "4                False                  False                 False   \n",
      "\n",
      "   hostIP_54.239.19.125  hostIP_54.239.25.214  hostIP_54.239.26.244  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.239.26.255  hostIP_54.239.27.11  hostIP_54.239.29.0  \\\n",
      "0                 False                False               False   \n",
      "1                 False                False               False   \n",
      "2                 False                False               False   \n",
      "3                 False                False               False   \n",
      "4                 False                False               False   \n",
      "\n",
      "   hostIP_54.239.29.142  hostIP_54.239.31.37  hostIP_54.240.188.172  \\\n",
      "0                 False                False                  False   \n",
      "1                 False                False                  False   \n",
      "2                 False                False                  False   \n",
      "3                 False                False                  False   \n",
      "4                 False                False                  False   \n",
      "\n",
      "   hostIP_54.240.188.229  hostIP_54.240.188.23  hostIP_54.240.188.4  \\\n",
      "0                  False                 False                False   \n",
      "1                  False                 False                False   \n",
      "2                  False                 False                False   \n",
      "3                  False                 False                False   \n",
      "4                  False                 False                False   \n",
      "\n",
      "   hostIP_54.240.188.87  hostIP_54.244.25.229  hostIP_54.249.82.168  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_54.249.82.169  hostIP_54.250.163.99  hostIP_54.250.82.24  \\\n",
      "0                 False                 False                False   \n",
      "1                 False                 False                False   \n",
      "2                 False                 False                False   \n",
      "3                 False                 False                False   \n",
      "4                 False                 False                False   \n",
      "\n",
      "   hostIP_54.64.148.31  hostIP_54.68.104.85  hostIP_54.68.113.102  \\\n",
      "0                False                False                 False   \n",
      "1                False                False                 False   \n",
      "2                False                False                 False   \n",
      "3                False                False                 False   \n",
      "4                False                False                 False   \n",
      "\n",
      "   hostIP_54.69.146.98  hostIP_54.69.176.92  hostIP_54.69.97.230  \\\n",
      "0                False                False                False   \n",
      "1                False                False                False   \n",
      "2                False                False                False   \n",
      "3                False                False                False   \n",
      "4                False                False                False   \n",
      "\n",
      "   hostIP_54.70.102.225  hostIP_54.70.111.46  hostIP_54.76.81.242  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_54.81.133.206  hostIP_54.84.202.69  hostIP_54.85.66.204  \\\n",
      "0                 False                False                False   \n",
      "1                 False                False                False   \n",
      "2                 False                False                False   \n",
      "3                 False                False                False   \n",
      "4                 False                False                False   \n",
      "\n",
      "   hostIP_54.86.21.222  hostIP_54.86.245.141  hostIP_54.88.253.197  \\\n",
      "0                False                 False                 False   \n",
      "1                False                 False                 False   \n",
      "2                False                 False                 False   \n",
      "3                False                 False                 False   \n",
      "4                False                 False                 False   \n",
      "\n",
      "   hostIP_60.248.237.221  hostIP_60.254.132.131  hostIP_60.254.134.108  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_61.188.37.216  hostIP_64.233.187.188  hostIP_64.233.188.188  \\\n",
      "0                 False                  False                  False   \n",
      "1                 False                  False                  False   \n",
      "2                 False                  False                  False   \n",
      "3                 False                  False                  False   \n",
      "4                 False                  False                  False   \n",
      "\n",
      "   hostIP_64.233.189.188  hostIP_72.21.207.142  hostIP_72.21.207.143  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "2                  False                 False                 False   \n",
      "3                  False                 False                 False   \n",
      "4                  False                 False                 False   \n",
      "\n",
      "   hostIP_72.21.207.87  hostIP_72.21.214.79  hostIP_72.247.136.15  \\\n",
      "0                False                False                 False   \n",
      "1                False                False                 False   \n",
      "2                False                False                 False   \n",
      "3                False                False                 False   \n",
      "4                False                False                 False   \n",
      "\n",
      "   hostIP_74.125.106.202  hostIP_74.125.203.188  hostIP_74.125.204.188  \\\n",
      "0                  False                  False                  False   \n",
      "1                  False                  False                  False   \n",
      "2                  False                  False                  False   \n",
      "3                  False                  False                  False   \n",
      "4                  False                  False                  False   \n",
      "\n",
      "   hostIP_74.125.23.188  hostIP_8.8.4.4  hostIP_8.8.8.8  hostIP_96.16.104.16  \\\n",
      "0                 False           False           False                False   \n",
      "1                 False           False           False                False   \n",
      "2                 False           False           False                False   \n",
      "3                 False           False           False                False   \n",
      "4                 False           False           False                False   \n",
      "\n",
      "   hostIP_99.84.133.139  hostIP_99.84.138.118  hostIP_99.84.138.143  \\\n",
      "0                 False                 False                 False   \n",
      "1                 False                 False                 False   \n",
      "2                 False                 False                 False   \n",
      "3                 False                 False                 False   \n",
      "4                 False                 False                 False   \n",
      "\n",
      "   hostIP_99.84.138.57  hostIP_99.84.138.70  hostIP_99.84.139.128  \\\n",
      "0                False                False                 False   \n",
      "1                False                False                 False   \n",
      "2                False                False                 False   \n",
      "3                False                False                 False   \n",
      "4                False                False                 False   \n",
      "\n",
      "   hostIP_99.84.143.104  hostIP_99.84.143.17  hostIP_99.84.143.3  \\\n",
      "0                 False                False               False   \n",
      "1                 False                False               False   \n",
      "2                 False                False               False   \n",
      "3                 False                False               False   \n",
      "4                 False                False               False   \n",
      "\n",
      "   hostIP_99.84.143.4  hostIP_99.84.143.5  hostIP_99.84.54.212  \\\n",
      "0               False               False                False   \n",
      "1               False               False                False   \n",
      "2               False               False                False   \n",
      "3               False               False                False   \n",
      "4               False               False                False   \n",
      "\n",
      "   hostIP_99.84.54.35  hostIP_99.84.54.42  hostIP_99.84.54.89  \\\n",
      "0               False               False               False   \n",
      "1               False               False               False   \n",
      "2               False               False               False   \n",
      "3               False               False               False   \n",
      "4               False               False               False   \n",
      "\n",
      "   hostIP_99.84.58.99  hostIP_99.84.59.126  hostIP_99.84.59.18  \\\n",
      "0               False                False               False   \n",
      "1               False                False               False   \n",
      "2               False                False               False   \n",
      "3               False                False               False   \n",
      "4               False                False               False   \n",
      "\n",
      "   hostIP_99.84.59.35  hostIP_99.84.59.67  hostIP_99.84.62.160  \\\n",
      "0               False               False                False   \n",
      "1               False               False                False   \n",
      "2               False               False                False   \n",
      "3               False               False                False   \n",
      "4               False               False                False   \n",
      "\n",
      "   hostIP_99.84.63.15  hostIP_99.84.63.39  hostIP_99.84.63.7  \\\n",
      "0               False               False              False   \n",
      "1               False               False              False   \n",
      "2               False               False              False   \n",
      "3               False               False              False   \n",
      "4               False               False              False   \n",
      "\n",
      "   hostIP_99.86.193.123  hostIP_99.86.193.37  hostIP_99.86.193.97  \n",
      "0                 False                False                False  \n",
      "1                 False                False                False  \n",
      "2                 False                False                False  \n",
      "3                 False                False                False  \n",
      "4                 False                False                False  \n",
      "0    00:1b:c7:fa:c3:e6:\n",
      "1    04:5d:4b:a4:d0:2e:\n",
      "2    04:5d:4b:a4:d0:2e:\n",
      "3    6c:5a:b5:56:39:3e:\n",
      "4    bc:c3:42:dc:24:78:\n",
      "Name: IoTMac, dtype: object\n",
      "Accuracy: 0.94935\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Oct 29 11:59:39 2024\n",
    "\n",
    "@author: camer\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SequentialFeatureSelector as sfs\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "seed = 42\n",
    "sample = pd.read_csv(\"data/sample2.csv\")\n",
    "column_names = [\n",
    "    \"dataset\", \"start_date\", \"start_time\", \"duration\", \"reverseDelta\", \"IoTMac\", \"hostMac\", \"IoTIP\", \"IoTIP_int\",\n",
    "    \"hostIP\", \"hostIP_int\", \"ipProto\", \"IoTPort\", \"hostPort\", \"PacketCount\", \"BytesCount\", \"reversePacketCount\",\n",
    "    \"reverseBytesCount\", \"SmallPktCount\", \"LargePktCount\", \"NonEmptyPktCount\", \"DataByteCount\", \"AvgIAT\",\n",
    "    \"FirstNonEmptyPktSize\", \"MaxPktSize\", \"StdevPayloadSize\", \"StdevIAT\", \"AvgPacketSize\", \"reverseSmallPktCount\",\n",
    "    \"reverseLargePktCount\", \"reverseNonEmptyPktCount\", \"reverseDataByteCount\", \"reverseAvgIAT\",\n",
    "    \"reverseFirstNonEmptyPktSize\", \"reverseMaxPktSize\", \"reverseStdevPayloadSize\", \"reverseStdevIAT\",\n",
    "    \"reverseAvgPacketSize\", \"reverseFlowExists\", \"remote\", \"broadcast\", \"HTTP\", \"HTTPS\", \"DNS\", \"NTP\", \"TCP_others\",\n",
    "    \"UDP_others\", \"year_month\"\n",
    "]\n",
    "sample.columns = column_names\n",
    "heads = sample.drop(columns = ['dataset', 'start_date', 'start_time', 'IoTMac', 'IoTIP', 'IoTIP_int', 'year_month','hostMac'])\n",
    "heads.head()\n",
    "data = pd.get_dummies(heads)\n",
    "classes = sample['IoTMac']\n",
    "y = classes\n",
    "X = data\n",
    "print(X.head())\n",
    "print(y.head())\n",
    "# Split the dataset into training and test sets 20-80\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, classes, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the Random Forest classifier\n",
    "model = RandomForestClassifier(n_estimators=25, random_state=seed)\n",
    "'''\n",
    "selector = sfs(model, direction='forward', cv=2)\n",
    "selector.fit(X_train,y_train)\n",
    "features = selector.get_feature_names_out(list(X))\n",
    "'''\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions and evaluate the model\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "for f in cmatrix:\n",
    "    f += 1\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "sns.heatmap(cmatrix, annot=False, cmap='coolwarm', norm=LogNorm())\n",
    "feature_importances = model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiran/Library/Python/3.9/lib/python/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.4496 - loss: 2.1774 - val_accuracy: 0.5920 - val_loss: 1.2749 - learning_rate: 0.0100\n",
      "Epoch 2/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.5930 - loss: 1.2818 - val_accuracy: 0.6207 - val_loss: 1.1869 - learning_rate: 0.0100\n",
      "Epoch 3/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6138 - loss: 1.1794 - val_accuracy: 0.6373 - val_loss: 1.1451 - learning_rate: 0.0100\n",
      "Epoch 4/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6280 - loss: 1.0983 - val_accuracy: 0.6440 - val_loss: 1.1059 - learning_rate: 0.0100\n",
      "Epoch 5/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6348 - loss: 1.0823 - val_accuracy: 0.6673 - val_loss: 1.0796 - learning_rate: 0.0100\n",
      "Epoch 6/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6568 - loss: 1.0184 - val_accuracy: 0.6880 - val_loss: 1.0260 - learning_rate: 0.0100\n",
      "Epoch 7/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6613 - loss: 0.9868 - val_accuracy: 0.7053 - val_loss: 0.9778 - learning_rate: 0.0100\n",
      "Epoch 8/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.6854 - loss: 0.9234 - val_accuracy: 0.7580 - val_loss: 0.9584 - learning_rate: 0.0100\n",
      "Epoch 9/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7298 - loss: 0.8746 - val_accuracy: 0.7480 - val_loss: 0.9053 - learning_rate: 0.0100\n",
      "Epoch 10/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7425 - loss: 0.8374 - val_accuracy: 0.7533 - val_loss: 0.8681 - learning_rate: 0.0100\n",
      "Epoch 11/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7689 - loss: 0.7813 - val_accuracy: 0.7733 - val_loss: 0.8537 - learning_rate: 0.0100\n",
      "Epoch 12/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7888 - loss: 0.7421 - val_accuracy: 0.7693 - val_loss: 0.8462 - learning_rate: 0.0100\n",
      "Epoch 13/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7869 - loss: 0.7260 - val_accuracy: 0.8033 - val_loss: 0.8234 - learning_rate: 0.0100\n",
      "Epoch 14/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.7971 - loss: 0.7142 - val_accuracy: 0.8093 - val_loss: 0.8401 - learning_rate: 0.0100\n",
      "Epoch 15/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8031 - loss: 0.6839 - val_accuracy: 0.7840 - val_loss: 0.8358 - learning_rate: 0.0100\n",
      "Epoch 16/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8033 - loss: 0.6552 - val_accuracy: 0.8047 - val_loss: 0.8191 - learning_rate: 0.0100\n",
      "Epoch 17/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8051 - loss: 0.6592 - val_accuracy: 0.8120 - val_loss: 0.8473 - learning_rate: 0.0100\n",
      "Epoch 18/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8004 - loss: 0.6616 - val_accuracy: 0.8093 - val_loss: 0.8693 - learning_rate: 0.0100\n",
      "Epoch 19/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8188 - loss: 0.6236 - val_accuracy: 0.8113 - val_loss: 0.8598 - learning_rate: 0.0100\n",
      "Epoch 20/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8075 - loss: 0.6475 - val_accuracy: 0.8060 - val_loss: 0.8649 - learning_rate: 0.0100\n",
      "Epoch 21/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8037 - loss: 0.6148 - val_accuracy: 0.8007 - val_loss: 0.8710 - learning_rate: 0.0100\n",
      "Epoch 22/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8081 - loss: 0.6225 - val_accuracy: 0.8047 - val_loss: 0.8866 - learning_rate: 0.0100\n",
      "Epoch 23/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8154 - loss: 0.5916 - val_accuracy: 0.8200 - val_loss: 0.8926 - learning_rate: 0.0100\n",
      "Epoch 24/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8149 - loss: 0.5959 - val_accuracy: 0.8040 - val_loss: 0.8930 - learning_rate: 0.0100\n",
      "Epoch 25/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8185 - loss: 0.5875 - val_accuracy: 0.8087 - val_loss: 0.9083 - learning_rate: 0.0100\n",
      "Epoch 26/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8226 - loss: 0.5706 - val_accuracy: 0.8173 - val_loss: 0.9464 - learning_rate: 0.0100\n",
      "Epoch 27/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8168 - loss: 0.5896 - val_accuracy: 0.8253 - val_loss: 0.9389 - learning_rate: 0.0100\n",
      "Epoch 28/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.5792 - val_accuracy: 0.8120 - val_loss: 0.9246 - learning_rate: 0.0100\n",
      "Epoch 29/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8192 - loss: 0.5790 - val_accuracy: 0.8240 - val_loss: 0.9098 - learning_rate: 0.0100\n",
      "Epoch 30/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8161 - loss: 0.5866 - val_accuracy: 0.8133 - val_loss: 0.9083 - learning_rate: 0.0100\n",
      "Epoch 31/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8232 - loss: 0.5618 - val_accuracy: 0.8073 - val_loss: 0.9408 - learning_rate: 0.0100\n",
      "Epoch 32/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8296 - loss: 0.5430 - val_accuracy: 0.8180 - val_loss: 0.9272 - learning_rate: 0.0100\n",
      "Epoch 33/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8216 - loss: 0.5631 - val_accuracy: 0.8213 - val_loss: 0.9471 - learning_rate: 0.0100\n",
      "Epoch 34/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8315 - loss: 0.5496 - val_accuracy: 0.8260 - val_loss: 0.9747 - learning_rate: 0.0100\n",
      "Epoch 35/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8110 - loss: 0.5751 - val_accuracy: 0.8107 - val_loss: 0.9566 - learning_rate: 0.0100\n",
      "Epoch 36/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8291 - loss: 0.5664 - val_accuracy: 0.8093 - val_loss: 0.9666 - learning_rate: 0.0100\n",
      "Epoch 37/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8173 - loss: 0.5628 - val_accuracy: 0.8220 - val_loss: 0.9552 - learning_rate: 0.0100\n",
      "Epoch 38/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8209 - loss: 0.5611 - val_accuracy: 0.8160 - val_loss: 0.9786 - learning_rate: 0.0100\n",
      "Epoch 39/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8271 - loss: 0.5522 - val_accuracy: 0.8300 - val_loss: 0.9387 - learning_rate: 0.0100\n",
      "Epoch 40/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8243 - loss: 0.5432 - val_accuracy: 0.8187 - val_loss: 0.9536 - learning_rate: 0.0100\n",
      "Epoch 41/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8240 - loss: 0.5519 - val_accuracy: 0.7967 - val_loss: 0.9898 - learning_rate: 0.0100\n",
      "Epoch 42/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8198 - loss: 0.5453 - val_accuracy: 0.8193 - val_loss: 0.9474 - learning_rate: 0.0100\n",
      "Epoch 43/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8309 - loss: 0.5355 - val_accuracy: 0.8320 - val_loss: 0.9596 - learning_rate: 0.0100\n",
      "Epoch 44/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8305 - loss: 0.5275 - val_accuracy: 0.8240 - val_loss: 0.9533 - learning_rate: 0.0100\n",
      "Epoch 45/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8261 - loss: 0.5364 - val_accuracy: 0.8233 - val_loss: 0.9542 - learning_rate: 0.0100\n",
      "Epoch 46/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8221 - loss: 0.5262 - val_accuracy: 0.8267 - val_loss: 0.9572 - learning_rate: 0.0100\n",
      "Epoch 47/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8268 - loss: 0.5194 - val_accuracy: 0.8267 - val_loss: 0.9632 - learning_rate: 0.0100\n",
      "Epoch 48/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 0.5154 - val_accuracy: 0.8160 - val_loss: 0.9688 - learning_rate: 0.0100\n",
      "Epoch 49/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8242 - loss: 0.5287 - val_accuracy: 0.8240 - val_loss: 0.9754 - learning_rate: 0.0100\n",
      "Epoch 50/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8307 - loss: 0.5240 - val_accuracy: 0.8193 - val_loss: 0.9853 - learning_rate: 0.0100\n",
      "Epoch 51/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 0.5133 - val_accuracy: 0.8200 - val_loss: 0.9784 - learning_rate: 0.0100\n",
      "Epoch 52/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8299 - loss: 0.5193 - val_accuracy: 0.8333 - val_loss: 0.9731 - learning_rate: 0.0100\n",
      "Epoch 53/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8400 - loss: 0.5141 - val_accuracy: 0.8227 - val_loss: 0.9629 - learning_rate: 0.0100\n",
      "Epoch 54/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8291 - loss: 0.5169 - val_accuracy: 0.8373 - val_loss: 0.9612 - learning_rate: 0.0100\n",
      "Epoch 55/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8392 - loss: 0.5011 - val_accuracy: 0.8173 - val_loss: 0.9859 - learning_rate: 0.0100\n",
      "Epoch 56/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.4709\n",
      "Epoch 56: ReduceLROnPlateau reducing learning rate to 0.008999999798834325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 0.5063 - val_accuracy: 0.8333 - val_loss: 0.9994 - learning_rate: 0.0100\n",
      "Epoch 57/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.5148 - val_accuracy: 0.7933 - val_loss: 0.9736 - learning_rate: 0.0090\n",
      "Epoch 58/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8297 - loss: 0.5080 - val_accuracy: 0.8333 - val_loss: 0.9519 - learning_rate: 0.0090\n",
      "Epoch 59/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8354 - loss: 0.5082 - val_accuracy: 0.8353 - val_loss: 0.9762 - learning_rate: 0.0090\n",
      "Epoch 60/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8321 - loss: 0.5011 - val_accuracy: 0.8287 - val_loss: 0.9622 - learning_rate: 0.0090\n",
      "Epoch 61/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8489 - loss: 0.4883 - val_accuracy: 0.8300 - val_loss: 0.9564 - learning_rate: 0.0090\n",
      "Epoch 62/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8362 - loss: 0.5025 - val_accuracy: 0.8293 - val_loss: 0.9727 - learning_rate: 0.0090\n",
      "Epoch 63/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 0.5038 - val_accuracy: 0.8353 - val_loss: 0.9765 - learning_rate: 0.0090\n",
      "Epoch 64/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8378 - loss: 0.4938 - val_accuracy: 0.8260 - val_loss: 1.0004 - learning_rate: 0.0090\n",
      "Epoch 65/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8478 - loss: 0.5122 - val_accuracy: 0.8467 - val_loss: 0.9673 - learning_rate: 0.0090\n",
      "Epoch 66/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8431 - loss: 0.4952 - val_accuracy: 0.8440 - val_loss: 0.9718 - learning_rate: 0.0090\n",
      "Epoch 67/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8394 - loss: 0.5023 - val_accuracy: 0.8420 - val_loss: 0.9636 - learning_rate: 0.0090\n",
      "Epoch 68/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 0.4821 - val_accuracy: 0.8267 - val_loss: 0.9576 - learning_rate: 0.0090\n",
      "Epoch 69/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8382 - loss: 0.4863 - val_accuracy: 0.8487 - val_loss: 0.9535 - learning_rate: 0.0090\n",
      "Epoch 70/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8488 - loss: 0.4834 - val_accuracy: 0.8247 - val_loss: 0.9663 - learning_rate: 0.0090\n",
      "Epoch 71/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8436 - loss: 0.4807 - val_accuracy: 0.8320 - val_loss: 0.9648 - learning_rate: 0.0090\n",
      "Epoch 72/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8506 - loss: 0.4681 - val_accuracy: 0.8367 - val_loss: 0.9701 - learning_rate: 0.0090\n",
      "Epoch 73/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8476 - loss: 0.4881 - val_accuracy: 0.8287 - val_loss: 0.9806 - learning_rate: 0.0090\n",
      "Epoch 74/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8449 - loss: 0.4823 - val_accuracy: 0.8333 - val_loss: 0.9910 - learning_rate: 0.0090\n",
      "Epoch 75/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.5057 - val_accuracy: 0.8120 - val_loss: 0.9995 - learning_rate: 0.0090\n",
      "Epoch 76/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8404 - loss: 0.4883 - val_accuracy: 0.8533 - val_loss: 0.9817 - learning_rate: 0.0090\n",
      "Epoch 77/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8530 - loss: 0.4956 - val_accuracy: 0.7960 - val_loss: 1.0221 - learning_rate: 0.0090\n",
      "Epoch 78/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8227 - loss: 0.5189 - val_accuracy: 0.8500 - val_loss: 0.9656 - learning_rate: 0.0090\n",
      "Epoch 79/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 0.4803 - val_accuracy: 0.8593 - val_loss: 0.9491 - learning_rate: 0.0090\n",
      "Epoch 80/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8523 - loss: 0.5078 - val_accuracy: 0.8173 - val_loss: 0.9644 - learning_rate: 0.0090\n",
      "Epoch 81/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8437 - loss: 0.5001 - val_accuracy: 0.8380 - val_loss: 0.9990 - learning_rate: 0.0090\n",
      "Epoch 82/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8471 - loss: 0.4994 - val_accuracy: 0.8313 - val_loss: 0.9655 - learning_rate: 0.0090\n",
      "Epoch 83/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8494 - loss: 0.5001 - val_accuracy: 0.8367 - val_loss: 0.9962 - learning_rate: 0.0090\n",
      "Epoch 84/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8515 - loss: 0.4806 - val_accuracy: 0.8253 - val_loss: 0.7155 - learning_rate: 0.0090\n",
      "Epoch 85/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.4800 - val_accuracy: 0.8280 - val_loss: 0.7330 - learning_rate: 0.0090\n",
      "Epoch 86/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8460 - loss: 0.4902 - val_accuracy: 0.8333 - val_loss: 0.7218 - learning_rate: 0.0090\n",
      "Epoch 87/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8499 - loss: 0.4762 - val_accuracy: 0.8207 - val_loss: 0.7171 - learning_rate: 0.0090\n",
      "Epoch 88/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 0.4477 - val_accuracy: 0.8433 - val_loss: 0.7181 - learning_rate: 0.0090\n",
      "Epoch 89/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8498 - loss: 0.4721 - val_accuracy: 0.8600 - val_loss: 0.7059 - learning_rate: 0.0090\n",
      "Epoch 90/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8550 - loss: 0.4701 - val_accuracy: 0.8460 - val_loss: 0.7246 - learning_rate: 0.0090\n",
      "Epoch 91/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 0.4726 - val_accuracy: 0.8440 - val_loss: 0.7028 - learning_rate: 0.0090\n",
      "Epoch 92/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8384 - loss: 0.4928 - val_accuracy: 0.8387 - val_loss: 0.7300 - learning_rate: 0.0090\n",
      "Epoch 93/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8422 - loss: 0.4927 - val_accuracy: 0.8320 - val_loss: 0.7120 - learning_rate: 0.0090\n",
      "Epoch 94/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8489 - loss: 0.4754 - val_accuracy: 0.8333 - val_loss: 0.7032 - learning_rate: 0.0090\n",
      "Epoch 95/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8419 - loss: 0.4934 - val_accuracy: 0.8440 - val_loss: 0.7313 - learning_rate: 0.0090\n",
      "Epoch 96/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8550 - loss: 0.4731 - val_accuracy: 0.8327 - val_loss: 0.7059 - learning_rate: 0.0090\n",
      "Epoch 97/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8458 - loss: 0.4691 - val_accuracy: 0.8613 - val_loss: 0.7120 - learning_rate: 0.0090\n",
      "Epoch 98/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.4706 - val_accuracy: 0.8567 - val_loss: 0.6960 - learning_rate: 0.0090\n",
      "Epoch 99/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8539 - loss: 0.4696 - val_accuracy: 0.8133 - val_loss: 0.7255 - learning_rate: 0.0090\n",
      "Epoch 100/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8520 - loss: 0.4744 - val_accuracy: 0.8287 - val_loss: 0.7138 - learning_rate: 0.0090\n",
      "Epoch 101/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.4775 - val_accuracy: 0.8633 - val_loss: 0.7200 - learning_rate: 0.0090\n",
      "Epoch 102/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8590 - loss: 0.4559 - val_accuracy: 0.8220 - val_loss: 0.7272 - learning_rate: 0.0090\n",
      "Epoch 103/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8543 - loss: 0.4601 - val_accuracy: 0.8533 - val_loss: 0.7316 - learning_rate: 0.0090\n",
      "Epoch 104/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8533 - loss: 0.4653 - val_accuracy: 0.8073 - val_loss: 0.7427 - learning_rate: 0.0090\n",
      "Epoch 105/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 0.4577 - val_accuracy: 0.8547 - val_loss: 0.6992 - learning_rate: 0.0090\n",
      "Epoch 106/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8487 - loss: 0.4736 - val_accuracy: 0.8447 - val_loss: 0.7132 - learning_rate: 0.0090\n",
      "Epoch 107/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8504 - loss: 0.4672 - val_accuracy: 0.8387 - val_loss: 0.6959 - learning_rate: 0.0090\n",
      "Epoch 108/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8475 - loss: 0.4557 - val_accuracy: 0.8320 - val_loss: 0.7236 - learning_rate: 0.0090\n",
      "Epoch 109/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8571 - loss: 0.4548 - val_accuracy: 0.8180 - val_loss: 0.7536 - learning_rate: 0.0090\n",
      "Epoch 110/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8409 - loss: 0.4916 - val_accuracy: 0.8293 - val_loss: 0.7640 - learning_rate: 0.0090\n",
      "Epoch 111/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8424 - loss: 0.4720 - val_accuracy: 0.8467 - val_loss: 0.7328 - learning_rate: 0.0090\n",
      "Epoch 112/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8550 - loss: 0.4602 - val_accuracy: 0.8587 - val_loss: 0.7200 - learning_rate: 0.0090\n",
      "Epoch 113/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8581 - loss: 0.4498 - val_accuracy: 0.8527 - val_loss: 0.7413 - learning_rate: 0.0090\n",
      "Epoch 114/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8559 - loss: 0.4577 - val_accuracy: 0.8553 - val_loss: 0.7360 - learning_rate: 0.0090\n",
      "Epoch 115/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8652 - loss: 0.4629 - val_accuracy: 0.8500 - val_loss: 0.7439 - learning_rate: 0.0090\n",
      "Epoch 116/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8488 - loss: 0.4802 - val_accuracy: 0.8447 - val_loss: 0.7224 - learning_rate: 0.0090\n",
      "Epoch 117/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8461 - loss: 0.4820 - val_accuracy: 0.8447 - val_loss: 0.7370 - learning_rate: 0.0090\n",
      "Epoch 118/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8552 - loss: 0.4567 - val_accuracy: 0.8313 - val_loss: 0.7400 - learning_rate: 0.0090\n",
      "Epoch 119/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8517 - loss: 0.4582 - val_accuracy: 0.8473 - val_loss: 0.7311 - learning_rate: 0.0090\n",
      "Epoch 120/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8603 - loss: 0.4461 - val_accuracy: 0.8427 - val_loss: 0.7311 - learning_rate: 0.0090\n",
      "Epoch 121/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8531 - loss: 0.4586 - val_accuracy: 0.8553 - val_loss: 0.7304 - learning_rate: 0.0090\n",
      "Epoch 122/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8643 - loss: 0.4647 - val_accuracy: 0.8380 - val_loss: 0.7292 - learning_rate: 0.0090\n",
      "Epoch 123/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8592 - loss: 0.4447 - val_accuracy: 0.8693 - val_loss: 0.7381 - learning_rate: 0.0090\n",
      "Epoch 124/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8621 - loss: 0.4531 - val_accuracy: 0.8600 - val_loss: 0.7349 - learning_rate: 0.0090\n",
      "Epoch 125/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8617 - loss: 0.4446 - val_accuracy: 0.8493 - val_loss: 0.7267 - learning_rate: 0.0090\n",
      "Epoch 126/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8683 - loss: 0.4403 - val_accuracy: 0.8420 - val_loss: 0.7190 - learning_rate: 0.0090\n",
      "Epoch 127/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8521 - loss: 0.4494 - val_accuracy: 0.8420 - val_loss: 0.7312 - learning_rate: 0.0090\n",
      "Epoch 128/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8526 - loss: 0.4659 - val_accuracy: 0.8227 - val_loss: 0.7520 - learning_rate: 0.0090\n",
      "Epoch 129/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8414 - loss: 0.4707 - val_accuracy: 0.8393 - val_loss: 0.7375 - learning_rate: 0.0090\n",
      "Epoch 130/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8580 - loss: 0.4586 - val_accuracy: 0.8047 - val_loss: 0.7611 - learning_rate: 0.0090\n",
      "Epoch 131/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8503 - loss: 0.4595 - val_accuracy: 0.8580 - val_loss: 0.7193 - learning_rate: 0.0090\n",
      "Epoch 132/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8613 - loss: 0.4474 - val_accuracy: 0.8440 - val_loss: 0.7158 - learning_rate: 0.0090\n",
      "Epoch 133/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8522 - loss: 0.4576 - val_accuracy: 0.8560 - val_loss: 0.7119 - learning_rate: 0.0090\n",
      "Epoch 134/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8690 - loss: 0.4513 - val_accuracy: 0.8427 - val_loss: 0.7208 - learning_rate: 0.0090\n",
      "Epoch 135/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8646 - loss: 0.4321 - val_accuracy: 0.8387 - val_loss: 0.7291 - learning_rate: 0.0090\n",
      "Epoch 136/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8714 - loss: 0.4311 - val_accuracy: 0.8447 - val_loss: 0.7237 - learning_rate: 0.0090\n",
      "Epoch 137/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8682 - loss: 0.4391 - val_accuracy: 0.8213 - val_loss: 0.7229 - learning_rate: 0.0090\n",
      "Epoch 138/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8566 - loss: 0.4533 - val_accuracy: 0.8320 - val_loss: 0.7416 - learning_rate: 0.0090\n",
      "Epoch 139/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8669 - loss: 0.4460 - val_accuracy: 0.8580 - val_loss: 0.7184 - learning_rate: 0.0090\n",
      "Epoch 140/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8689 - loss: 0.4278 - val_accuracy: 0.8467 - val_loss: 0.7265 - learning_rate: 0.0090\n",
      "Epoch 141/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8525 - loss: 0.4747 - val_accuracy: 0.8580 - val_loss: 0.7252 - learning_rate: 0.0090\n",
      "Epoch 142/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8628 - loss: 0.4626 - val_accuracy: 0.8560 - val_loss: 0.7190 - learning_rate: 0.0090\n",
      "Epoch 143/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8549 - loss: 0.4625 - val_accuracy: 0.8393 - val_loss: 0.7300 - learning_rate: 0.0090\n",
      "Epoch 144/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8603 - loss: 0.4630 - val_accuracy: 0.8707 - val_loss: 0.7114 - learning_rate: 0.0090\n",
      "Epoch 145/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8716 - loss: 0.4463 - val_accuracy: 0.8620 - val_loss: 0.7115 - learning_rate: 0.0090\n",
      "Epoch 146/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8697 - loss: 0.4503 - val_accuracy: 0.8680 - val_loss: 0.7120 - learning_rate: 0.0090\n",
      "Epoch 147/5000\n",
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8722 - loss: 0.4351 \n",
      "Epoch 147: ReduceLROnPlateau reducing learning rate to 0.008099999651312828.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8662 - loss: 0.4437 - val_accuracy: 0.8473 - val_loss: 0.7079 - learning_rate: 0.0090\n",
      "Epoch 148/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8722 - loss: 0.4339 - val_accuracy: 0.8653 - val_loss: 0.7071 - learning_rate: 0.0081\n",
      "Epoch 149/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8694 - loss: 0.4389 - val_accuracy: 0.8580 - val_loss: 0.7117 - learning_rate: 0.0081\n",
      "Epoch 150/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8774 - loss: 0.4267 - val_accuracy: 0.8607 - val_loss: 0.7061 - learning_rate: 0.0081\n",
      "Epoch 151/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8695 - loss: 0.4544 - val_accuracy: 0.8407 - val_loss: 0.7120 - learning_rate: 0.0081\n",
      "Epoch 152/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8719 - loss: 0.4409 - val_accuracy: 0.8527 - val_loss: 0.7082 - learning_rate: 0.0081\n",
      "Epoch 153/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.4309 - val_accuracy: 0.8600 - val_loss: 0.7107 - learning_rate: 0.0081\n",
      "Epoch 154/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8665 - loss: 0.4407 - val_accuracy: 0.8467 - val_loss: 0.7105 - learning_rate: 0.0081\n",
      "Epoch 155/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8682 - loss: 0.4166 - val_accuracy: 0.8380 - val_loss: 0.7200 - learning_rate: 0.0081\n",
      "Epoch 156/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 0.4424 - val_accuracy: 0.8387 - val_loss: 0.7274 - learning_rate: 0.0081\n",
      "Epoch 157/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8655 - loss: 0.4328 - val_accuracy: 0.8667 - val_loss: 0.6982 - learning_rate: 0.0081\n",
      "Epoch 158/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8753 - loss: 0.4330 - val_accuracy: 0.8540 - val_loss: 0.7051 - learning_rate: 0.0081\n",
      "Epoch 159/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8687 - loss: 0.4393 - val_accuracy: 0.8553 - val_loss: 0.7177 - learning_rate: 0.0081\n",
      "Epoch 160/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.4516 - val_accuracy: 0.8667 - val_loss: 0.7040 - learning_rate: 0.0081\n",
      "Epoch 161/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8624 - loss: 0.4385 - val_accuracy: 0.8727 - val_loss: 0.7012 - learning_rate: 0.0081\n",
      "Epoch 162/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8690 - loss: 0.4368 - val_accuracy: 0.8633 - val_loss: 0.7011 - learning_rate: 0.0081\n",
      "Epoch 163/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8659 - loss: 0.4304 - val_accuracy: 0.8540 - val_loss: 0.7062 - learning_rate: 0.0081\n",
      "Epoch 164/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8642 - loss: 0.4312 - val_accuracy: 0.8653 - val_loss: 0.6998 - learning_rate: 0.0081\n",
      "Epoch 165/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8706 - loss: 0.4322 - val_accuracy: 0.8573 - val_loss: 0.6999 - learning_rate: 0.0081\n",
      "Epoch 166/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8718 - loss: 0.4286 - val_accuracy: 0.8413 - val_loss: 0.6997 - learning_rate: 0.0081\n",
      "Epoch 167/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8625 - loss: 0.4326 - val_accuracy: 0.8540 - val_loss: 0.7081 - learning_rate: 0.0081\n",
      "Epoch 168/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8700 - loss: 0.4321 - val_accuracy: 0.8507 - val_loss: 0.7228 - learning_rate: 0.0081\n",
      "Epoch 169/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8743 - loss: 0.4221 - val_accuracy: 0.8520 - val_loss: 0.7015 - learning_rate: 0.0081\n",
      "Epoch 170/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8696 - loss: 0.4387 - val_accuracy: 0.8520 - val_loss: 0.7137 - learning_rate: 0.0081\n",
      "Epoch 171/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8610 - loss: 0.4481 - val_accuracy: 0.8427 - val_loss: 0.7130 - learning_rate: 0.0081\n",
      "Epoch 172/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8582 - loss: 0.4397 - val_accuracy: 0.8647 - val_loss: 0.7067 - learning_rate: 0.0081\n",
      "Epoch 173/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8692 - loss: 0.4383 - val_accuracy: 0.8633 - val_loss: 0.7248 - learning_rate: 0.0081\n",
      "Epoch 174/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8698 - loss: 0.4423 - val_accuracy: 0.8693 - val_loss: 0.7147 - learning_rate: 0.0081\n",
      "Epoch 175/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8627 - loss: 0.4418 - val_accuracy: 0.8393 - val_loss: 0.7178 - learning_rate: 0.0081\n",
      "Epoch 176/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8710 - loss: 0.4246 - val_accuracy: 0.8493 - val_loss: 0.7285 - learning_rate: 0.0081\n",
      "Epoch 177/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8801 - loss: 0.4244 - val_accuracy: 0.8420 - val_loss: 0.7210 - learning_rate: 0.0081\n",
      "Epoch 178/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8705 - loss: 0.4386 - val_accuracy: 0.8500 - val_loss: 0.7168 - learning_rate: 0.0081\n",
      "Epoch 179/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8692 - loss: 0.4502 - val_accuracy: 0.8533 - val_loss: 0.7202 - learning_rate: 0.0081\n",
      "Epoch 180/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.4445 - val_accuracy: 0.8600 - val_loss: 0.6946 - learning_rate: 0.0081\n",
      "Epoch 181/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8680 - loss: 0.4430 - val_accuracy: 0.8620 - val_loss: 0.7334 - learning_rate: 0.0081\n",
      "Epoch 182/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8732 - loss: 0.4486 - val_accuracy: 0.8580 - val_loss: 0.7043 - learning_rate: 0.0081\n",
      "Epoch 183/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8705 - loss: 0.4351 - val_accuracy: 0.8607 - val_loss: 0.7205 - learning_rate: 0.0081\n",
      "Epoch 184/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8713 - loss: 0.4436 - val_accuracy: 0.8600 - val_loss: 0.7169 - learning_rate: 0.0081\n",
      "Epoch 185/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.4464 - val_accuracy: 0.8400 - val_loss: 0.7229 - learning_rate: 0.0081\n",
      "Epoch 186/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 0.4542 - val_accuracy: 0.8547 - val_loss: 0.7031 - learning_rate: 0.0081\n",
      "Epoch 187/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8745 - loss: 0.4181 - val_accuracy: 0.8567 - val_loss: 0.7079 - learning_rate: 0.0081\n",
      "Epoch 188/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8671 - loss: 0.4372 - val_accuracy: 0.8653 - val_loss: 0.6945 - learning_rate: 0.0081\n",
      "Epoch 189/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8730 - loss: 0.4311 - val_accuracy: 0.8640 - val_loss: 0.7095 - learning_rate: 0.0081\n",
      "Epoch 190/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8688 - loss: 0.4271 - val_accuracy: 0.8633 - val_loss: 0.7040 - learning_rate: 0.0081\n",
      "Epoch 191/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8718 - loss: 0.4242 - val_accuracy: 0.8633 - val_loss: 0.7170 - learning_rate: 0.0081\n",
      "Epoch 192/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.4122 - val_accuracy: 0.8627 - val_loss: 0.7015 - learning_rate: 0.0081\n",
      "Epoch 193/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8821 - loss: 0.3992 - val_accuracy: 0.8480 - val_loss: 0.7165 - learning_rate: 0.0081\n",
      "Epoch 194/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8680 - loss: 0.4346 - val_accuracy: 0.8520 - val_loss: 0.7103 - learning_rate: 0.0081\n",
      "Epoch 195/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8719 - loss: 0.4230 - val_accuracy: 0.8533 - val_loss: 0.7132 - learning_rate: 0.0081\n",
      "Epoch 196/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.4119 - val_accuracy: 0.8520 - val_loss: 0.7208 - learning_rate: 0.0081\n",
      "Epoch 197/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8801 - loss: 0.4024 - val_accuracy: 0.8433 - val_loss: 0.7395 - learning_rate: 0.0081\n",
      "Epoch 198/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8784 - loss: 0.4140 - val_accuracy: 0.8653 - val_loss: 0.7327 - learning_rate: 0.0081\n",
      "Epoch 199/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8754 - loss: 0.4195 - val_accuracy: 0.8607 - val_loss: 0.7223 - learning_rate: 0.0081\n",
      "Epoch 200/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8758 - loss: 0.4156 - val_accuracy: 0.8367 - val_loss: 0.7454 - learning_rate: 0.0081\n",
      "Epoch 201/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8699 - loss: 0.4091 - val_accuracy: 0.8580 - val_loss: 0.7392 - learning_rate: 0.0081\n",
      "Epoch 202/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8712 - loss: 0.4153 - val_accuracy: 0.8613 - val_loss: 0.7301 - learning_rate: 0.0081\n",
      "Epoch 203/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8744 - loss: 0.4156 - val_accuracy: 0.8620 - val_loss: 0.7371 - learning_rate: 0.0081\n",
      "Epoch 204/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8779 - loss: 0.4034 - val_accuracy: 0.8520 - val_loss: 0.7672 - learning_rate: 0.0081\n",
      "Epoch 205/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8684 - loss: 0.4231 - val_accuracy: 0.8627 - val_loss: 0.7619 - learning_rate: 0.0081\n",
      "Epoch 206/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8715 - loss: 0.4241 - val_accuracy: 0.8507 - val_loss: 0.7646 - learning_rate: 0.0081\n",
      "Epoch 207/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8753 - loss: 0.4139 - val_accuracy: 0.8560 - val_loss: 0.7887 - learning_rate: 0.0081\n",
      "Epoch 208/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8726 - loss: 0.4166 - val_accuracy: 0.8553 - val_loss: 0.8042 - learning_rate: 0.0081\n",
      "Epoch 209/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8793 - loss: 0.4158 - val_accuracy: 0.8653 - val_loss: 0.8237 - learning_rate: 0.0081\n",
      "Epoch 210/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.3958 - val_accuracy: 0.8693 - val_loss: 0.7980 - learning_rate: 0.0081\n",
      "Epoch 211/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8778 - loss: 0.4053 - val_accuracy: 0.8607 - val_loss: 0.8269 - learning_rate: 0.0081\n",
      "Epoch 212/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8836 - loss: 0.3933 - val_accuracy: 0.8613 - val_loss: 0.8606 - learning_rate: 0.0081\n",
      "Epoch 213/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8782 - loss: 0.4107 - val_accuracy: 0.8640 - val_loss: 0.8738 - learning_rate: 0.0081\n",
      "Epoch 214/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8721 - loss: 0.4092 - val_accuracy: 0.8600 - val_loss: 0.8853 - learning_rate: 0.0081\n",
      "Epoch 215/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8769 - loss: 0.4148 - val_accuracy: 0.8653 - val_loss: 0.8800 - learning_rate: 0.0081\n",
      "Epoch 216/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8681 - loss: 0.4260 - val_accuracy: 0.8573 - val_loss: 0.8673 - learning_rate: 0.0081\n",
      "Epoch 217/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8684 - loss: 0.4291 - val_accuracy: 0.8587 - val_loss: 0.9107 - learning_rate: 0.0081\n",
      "Epoch 218/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8776 - loss: 0.4126 - val_accuracy: 0.8580 - val_loss: 0.9127 - learning_rate: 0.0081\n",
      "Epoch 219/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8763 - loss: 0.4006 - val_accuracy: 0.8707 - val_loss: 0.8731 - learning_rate: 0.0081\n",
      "Epoch 220/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 838us/step - accuracy: 0.8967 - loss: 0.3438\n",
      "Epoch 220: ReduceLROnPlateau reducing learning rate to 0.007289999350905419.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8774 - loss: 0.3927 - val_accuracy: 0.8640 - val_loss: 0.8727 - learning_rate: 0.0081\n",
      "Epoch 221/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8759 - loss: 0.4029 - val_accuracy: 0.8613 - val_loss: 0.8710 - learning_rate: 0.0073\n",
      "Epoch 222/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.3908 - val_accuracy: 0.8640 - val_loss: 0.9019 - learning_rate: 0.0073\n",
      "Epoch 223/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.3988 - val_accuracy: 0.8527 - val_loss: 0.8792 - learning_rate: 0.0073\n",
      "Epoch 224/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8728 - loss: 0.4179 - val_accuracy: 0.8633 - val_loss: 0.8919 - learning_rate: 0.0073\n",
      "Epoch 225/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8718 - loss: 0.4135 - val_accuracy: 0.8613 - val_loss: 0.9028 - learning_rate: 0.0073\n",
      "Epoch 226/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3941 - val_accuracy: 0.8580 - val_loss: 0.9375 - learning_rate: 0.0073\n",
      "Epoch 227/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8782 - loss: 0.3990 - val_accuracy: 0.8640 - val_loss: 0.9088 - learning_rate: 0.0073\n",
      "Epoch 228/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8731 - loss: 0.4154 - val_accuracy: 0.8633 - val_loss: 0.9516 - learning_rate: 0.0073\n",
      "Epoch 229/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8771 - loss: 0.3993 - val_accuracy: 0.8640 - val_loss: 0.9134 - learning_rate: 0.0073\n",
      "Epoch 230/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.3965 - val_accuracy: 0.8633 - val_loss: 0.9240 - learning_rate: 0.0073\n",
      "Epoch 231/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8826 - loss: 0.3854 - val_accuracy: 0.8647 - val_loss: 0.9448 - learning_rate: 0.0073\n",
      "Epoch 232/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8825 - loss: 0.3773 - val_accuracy: 0.8640 - val_loss: 0.9365 - learning_rate: 0.0073\n",
      "Epoch 233/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8791 - loss: 0.3929 - val_accuracy: 0.8660 - val_loss: 0.9409 - learning_rate: 0.0073\n",
      "Epoch 234/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8807 - loss: 0.3994 - val_accuracy: 0.8680 - val_loss: 0.9127 - learning_rate: 0.0073\n",
      "Epoch 235/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8846 - loss: 0.3960 - val_accuracy: 0.8580 - val_loss: 0.9144 - learning_rate: 0.0073\n",
      "Epoch 236/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8753 - loss: 0.4069 - val_accuracy: 0.8520 - val_loss: 0.9394 - learning_rate: 0.0073\n",
      "Epoch 237/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8708 - loss: 0.4096 - val_accuracy: 0.8627 - val_loss: 0.9285 - learning_rate: 0.0073\n",
      "Epoch 238/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8841 - loss: 0.3858 - val_accuracy: 0.8640 - val_loss: 0.9671 - learning_rate: 0.0073\n",
      "Epoch 239/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8806 - loss: 0.3959 - val_accuracy: 0.8673 - val_loss: 0.9485 - learning_rate: 0.0073\n",
      "Epoch 240/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8881 - loss: 0.3743 - val_accuracy: 0.8627 - val_loss: 0.9635 - learning_rate: 0.0073\n",
      "Epoch 241/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.3911 - val_accuracy: 0.8660 - val_loss: 0.9457 - learning_rate: 0.0073\n",
      "Epoch 242/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8822 - loss: 0.3885 - val_accuracy: 0.8660 - val_loss: 0.9620 - learning_rate: 0.0073\n",
      "Epoch 243/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8883 - loss: 0.3775 - val_accuracy: 0.8573 - val_loss: 1.0111 - learning_rate: 0.0073\n",
      "Epoch 244/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8790 - loss: 0.3828 - val_accuracy: 0.8633 - val_loss: 1.0004 - learning_rate: 0.0073\n",
      "Epoch 245/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8725 - loss: 0.4107 - val_accuracy: 0.8653 - val_loss: 1.0192 - learning_rate: 0.0073\n",
      "Epoch 246/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8770 - loss: 0.4046 - val_accuracy: 0.8613 - val_loss: 1.0332 - learning_rate: 0.0073\n",
      "Epoch 247/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8696 - loss: 0.3996 - val_accuracy: 0.8560 - val_loss: 0.9991 - learning_rate: 0.0073\n",
      "Epoch 248/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8803 - loss: 0.3939 - val_accuracy: 0.8647 - val_loss: 0.9696 - learning_rate: 0.0073\n",
      "Epoch 249/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8795 - loss: 0.3865 - val_accuracy: 0.8653 - val_loss: 1.0111 - learning_rate: 0.0073\n",
      "Epoch 250/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8794 - loss: 0.3789 - val_accuracy: 0.8580 - val_loss: 1.0010 - learning_rate: 0.0073\n",
      "Epoch 251/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8741 - loss: 0.3994 - val_accuracy: 0.8680 - val_loss: 0.9638 - learning_rate: 0.0073\n",
      "Epoch 252/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8792 - loss: 0.3918 - val_accuracy: 0.8607 - val_loss: 1.0213 - learning_rate: 0.0073\n",
      "Epoch 253/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8704 - loss: 0.4212 - val_accuracy: 0.8653 - val_loss: 0.9866 - learning_rate: 0.0073\n",
      "Epoch 254/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8735 - loss: 0.4068 - val_accuracy: 0.8633 - val_loss: 0.9066 - learning_rate: 0.0073\n",
      "Epoch 255/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8756 - loss: 0.3963 - val_accuracy: 0.8580 - val_loss: 0.8901 - learning_rate: 0.0073\n",
      "Epoch 256/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.3953 - val_accuracy: 0.8667 - val_loss: 0.9269 - learning_rate: 0.0073\n",
      "Epoch 257/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.4085 - val_accuracy: 0.8687 - val_loss: 0.8860 - learning_rate: 0.0073\n",
      "Epoch 258/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8774 - loss: 0.4021 - val_accuracy: 0.8660 - val_loss: 0.9568 - learning_rate: 0.0073\n",
      "Epoch 259/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8738 - loss: 0.4389 - val_accuracy: 0.8647 - val_loss: 0.9823 - learning_rate: 0.0073\n",
      "Epoch 260/5000\n",
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 696us/step - accuracy: 0.8735 - loss: 0.4435\n",
      "Epoch 260: ReduceLROnPlateau reducing learning rate to 0.006560999248176813.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8786 - loss: 0.4154 - val_accuracy: 0.8527 - val_loss: 0.9509 - learning_rate: 0.0073\n",
      "Epoch 261/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8774 - loss: 0.3868 - val_accuracy: 0.8713 - val_loss: 0.8814 - learning_rate: 0.0066\n",
      "Epoch 262/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3813 - val_accuracy: 0.8680 - val_loss: 0.8869 - learning_rate: 0.0066\n",
      "Epoch 263/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8854 - loss: 0.3665 - val_accuracy: 0.8633 - val_loss: 0.9053 - learning_rate: 0.0066\n",
      "Epoch 264/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8818 - loss: 0.3831 - val_accuracy: 0.8667 - val_loss: 0.8857 - learning_rate: 0.0066\n",
      "Epoch 265/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3851 - val_accuracy: 0.8667 - val_loss: 0.9062 - learning_rate: 0.0066\n",
      "Epoch 266/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8805 - loss: 0.3822 - val_accuracy: 0.8627 - val_loss: 0.9180 - learning_rate: 0.0066\n",
      "Epoch 267/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8798 - loss: 0.3894 - val_accuracy: 0.8547 - val_loss: 0.9208 - learning_rate: 0.0066\n",
      "Epoch 268/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8791 - loss: 0.3818 - val_accuracy: 0.8613 - val_loss: 0.9486 - learning_rate: 0.0066\n",
      "Epoch 269/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8780 - loss: 0.3804 - val_accuracy: 0.8693 - val_loss: 0.9610 - learning_rate: 0.0066\n",
      "Epoch 270/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8798 - loss: 0.3794 - val_accuracy: 0.8693 - val_loss: 0.9670 - learning_rate: 0.0066\n",
      "Epoch 271/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8762 - loss: 0.3907 - val_accuracy: 0.8713 - val_loss: 0.9497 - learning_rate: 0.0066\n",
      "Epoch 272/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8753 - loss: 0.3893 - val_accuracy: 0.8653 - val_loss: 0.9513 - learning_rate: 0.0066\n",
      "Epoch 273/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8811 - loss: 0.3836 - val_accuracy: 0.8627 - val_loss: 0.9310 - learning_rate: 0.0066\n",
      "Epoch 274/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.3846 - val_accuracy: 0.8627 - val_loss: 0.9400 - learning_rate: 0.0066\n",
      "Epoch 275/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8748 - loss: 0.4018 - val_accuracy: 0.8640 - val_loss: 0.9573 - learning_rate: 0.0066\n",
      "Epoch 276/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8797 - loss: 0.3803 - val_accuracy: 0.8707 - val_loss: 0.9553 - learning_rate: 0.0066\n",
      "Epoch 277/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8790 - loss: 0.3890 - val_accuracy: 0.8687 - val_loss: 0.9593 - learning_rate: 0.0066\n",
      "Epoch 278/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8789 - loss: 0.3839 - val_accuracy: 0.8647 - val_loss: 0.9804 - learning_rate: 0.0066\n",
      "Epoch 279/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8749 - loss: 0.3958 - val_accuracy: 0.8613 - val_loss: 0.9976 - learning_rate: 0.0066\n",
      "Epoch 280/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8783 - loss: 0.3840 - val_accuracy: 0.8613 - val_loss: 1.0056 - learning_rate: 0.0066\n",
      "Epoch 281/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3882 - val_accuracy: 0.8633 - val_loss: 0.9818 - learning_rate: 0.0066\n",
      "Epoch 282/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8802 - loss: 0.3843 - val_accuracy: 0.8667 - val_loss: 0.9759 - learning_rate: 0.0066\n",
      "Epoch 283/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8812 - loss: 0.3826 - val_accuracy: 0.8673 - val_loss: 0.9922 - learning_rate: 0.0066\n",
      "Epoch 284/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8754 - loss: 0.3902 - val_accuracy: 0.8653 - val_loss: 1.0009 - learning_rate: 0.0066\n",
      "Epoch 285/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8812 - loss: 0.3764 - val_accuracy: 0.8667 - val_loss: 1.0034 - learning_rate: 0.0066\n",
      "Epoch 286/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3662 - val_accuracy: 0.8667 - val_loss: 0.9966 - learning_rate: 0.0066\n",
      "Epoch 287/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8752 - loss: 0.3835 - val_accuracy: 0.8673 - val_loss: 1.0019 - learning_rate: 0.0066\n",
      "Epoch 288/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8826 - loss: 0.3785 - val_accuracy: 0.8640 - val_loss: 1.0088 - learning_rate: 0.0066\n",
      "Epoch 289/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8777 - loss: 0.3900 - val_accuracy: 0.8640 - val_loss: 1.0321 - learning_rate: 0.0066\n",
      "Epoch 290/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8819 - loss: 0.3813 - val_accuracy: 0.8620 - val_loss: 1.0291 - learning_rate: 0.0066\n",
      "Epoch 291/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8840 - loss: 0.3781 - val_accuracy: 0.8660 - val_loss: 1.0202 - learning_rate: 0.0066\n",
      "Epoch 292/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8783 - loss: 0.3847 - val_accuracy: 0.8700 - val_loss: 1.0075 - learning_rate: 0.0066\n",
      "Epoch 293/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8817 - loss: 0.3700 - val_accuracy: 0.8720 - val_loss: 1.0261 - learning_rate: 0.0066\n",
      "Epoch 294/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8783 - loss: 0.3866 - val_accuracy: 0.8613 - val_loss: 1.0544 - learning_rate: 0.0066\n",
      "Epoch 295/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8808 - loss: 0.3925 - val_accuracy: 0.8633 - val_loss: 1.0562 - learning_rate: 0.0066\n",
      "Epoch 296/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8756 - loss: 0.3879 - val_accuracy: 0.8633 - val_loss: 1.0377 - learning_rate: 0.0066\n",
      "Epoch 297/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8786 - loss: 0.3730 - val_accuracy: 0.8700 - val_loss: 1.0491 - learning_rate: 0.0066\n",
      "Epoch 298/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8870 - loss: 0.3569 - val_accuracy: 0.8620 - val_loss: 1.0426 - learning_rate: 0.0066\n",
      "Epoch 299/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8851 - loss: 0.3620 - val_accuracy: 0.8627 - val_loss: 1.0414 - learning_rate: 0.0066\n",
      "Epoch 300/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.8842 - loss: 0.3938\n",
      "Epoch 300: ReduceLROnPlateau reducing learning rate to 0.005904899490997195.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8819 - loss: 0.3791 - val_accuracy: 0.8607 - val_loss: 1.0368 - learning_rate: 0.0066\n",
      "Epoch 301/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8841 - loss: 0.3720 - val_accuracy: 0.8607 - val_loss: 1.0575 - learning_rate: 0.0059\n",
      "Epoch 302/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8793 - loss: 0.3675 - val_accuracy: 0.8620 - val_loss: 1.0753 - learning_rate: 0.0059\n",
      "Epoch 303/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8887 - loss: 0.3788 - val_accuracy: 0.8640 - val_loss: 1.0613 - learning_rate: 0.0059\n",
      "Epoch 304/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8759 - loss: 0.3821 - val_accuracy: 0.8747 - val_loss: 1.0516 - learning_rate: 0.0059\n",
      "Epoch 305/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8867 - loss: 0.3759 - val_accuracy: 0.8580 - val_loss: 1.0807 - learning_rate: 0.0059\n",
      "Epoch 306/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8785 - loss: 0.3851 - val_accuracy: 0.8620 - val_loss: 1.0557 - learning_rate: 0.0059\n",
      "Epoch 307/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8778 - loss: 0.3715 - val_accuracy: 0.8680 - val_loss: 1.0905 - learning_rate: 0.0059\n",
      "Epoch 308/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8781 - loss: 0.3799 - val_accuracy: 0.8553 - val_loss: 1.0644 - learning_rate: 0.0059\n",
      "Epoch 309/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8768 - loss: 0.3761 - val_accuracy: 0.8647 - val_loss: 1.0546 - learning_rate: 0.0059\n",
      "Epoch 310/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8881 - loss: 0.3732 - val_accuracy: 0.8613 - val_loss: 1.1039 - learning_rate: 0.0059\n",
      "Epoch 311/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8763 - loss: 0.3862 - val_accuracy: 0.8660 - val_loss: 1.0961 - learning_rate: 0.0059\n",
      "Epoch 312/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8747 - loss: 0.3930 - val_accuracy: 0.8687 - val_loss: 1.1237 - learning_rate: 0.0059\n",
      "Epoch 313/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8794 - loss: 0.3815 - val_accuracy: 0.8713 - val_loss: 1.1500 - learning_rate: 0.0059\n",
      "Epoch 314/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8866 - loss: 0.3520 - val_accuracy: 0.8693 - val_loss: 1.1137 - learning_rate: 0.0059\n",
      "Epoch 315/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8795 - loss: 0.3779 - val_accuracy: 0.8707 - val_loss: 1.1120 - learning_rate: 0.0059\n",
      "Epoch 316/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8787 - loss: 0.3692 - val_accuracy: 0.8673 - val_loss: 1.1055 - learning_rate: 0.0059\n",
      "Epoch 317/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3639 - val_accuracy: 0.8700 - val_loss: 1.0883 - learning_rate: 0.0059\n",
      "Epoch 318/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8792 - loss: 0.3700 - val_accuracy: 0.8780 - val_loss: 1.0969 - learning_rate: 0.0059\n",
      "Epoch 319/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8857 - loss: 0.3667 - val_accuracy: 0.8647 - val_loss: 1.1072 - learning_rate: 0.0059\n",
      "Epoch 320/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8892 - loss: 0.3581 - val_accuracy: 0.8693 - val_loss: 1.1317 - learning_rate: 0.0059\n",
      "Epoch 321/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8848 - loss: 0.3724 - val_accuracy: 0.8673 - val_loss: 1.1089 - learning_rate: 0.0059\n",
      "Epoch 322/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8878 - loss: 0.3528 - val_accuracy: 0.8620 - val_loss: 1.1167 - learning_rate: 0.0059\n",
      "Epoch 323/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8840 - loss: 0.3588 - val_accuracy: 0.8640 - val_loss: 1.1113 - learning_rate: 0.0059\n",
      "Epoch 324/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8842 - loss: 0.3557 - val_accuracy: 0.8627 - val_loss: 1.1134 - learning_rate: 0.0059\n",
      "Epoch 325/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8859 - loss: 0.3562 - val_accuracy: 0.8647 - val_loss: 1.1188 - learning_rate: 0.0059\n",
      "Epoch 326/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8859 - loss: 0.3631 - val_accuracy: 0.8667 - val_loss: 1.1283 - learning_rate: 0.0059\n",
      "Epoch 327/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8700 - loss: 0.3986 - val_accuracy: 0.8653 - val_loss: 1.1331 - learning_rate: 0.0059\n",
      "Epoch 328/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8861 - loss: 0.3618 - val_accuracy: 0.8593 - val_loss: 1.1206 - learning_rate: 0.0059\n",
      "Epoch 329/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8881 - loss: 0.3564 - val_accuracy: 0.8707 - val_loss: 1.1212 - learning_rate: 0.0059\n",
      "Epoch 330/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8846 - loss: 0.3596 - val_accuracy: 0.8660 - val_loss: 1.1488 - learning_rate: 0.0059\n",
      "Epoch 331/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.3780 - val_accuracy: 0.8727 - val_loss: 1.1312 - learning_rate: 0.0059\n",
      "Epoch 332/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8823 - loss: 0.3564 - val_accuracy: 0.8673 - val_loss: 1.1545 - learning_rate: 0.0059\n",
      "Epoch 333/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8887 - loss: 0.3489 - val_accuracy: 0.8613 - val_loss: 1.1537 - learning_rate: 0.0059\n",
      "Epoch 334/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8802 - loss: 0.3752 - val_accuracy: 0.8600 - val_loss: 1.1702 - learning_rate: 0.0059\n",
      "Epoch 335/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8900 - loss: 0.3586 - val_accuracy: 0.8647 - val_loss: 1.1656 - learning_rate: 0.0059\n",
      "Epoch 336/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8809 - loss: 0.3615 - val_accuracy: 0.8720 - val_loss: 1.1524 - learning_rate: 0.0059\n",
      "Epoch 337/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8897 - loss: 0.3573 - val_accuracy: 0.8667 - val_loss: 1.1372 - learning_rate: 0.0059\n",
      "Epoch 338/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8866 - loss: 0.3712 - val_accuracy: 0.8687 - val_loss: 1.1441 - learning_rate: 0.0059\n",
      "Epoch 339/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8810 - loss: 0.3598 - val_accuracy: 0.8767 - val_loss: 1.1285 - learning_rate: 0.0059\n",
      "Epoch 340/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9042 - loss: 0.3120\n",
      "Epoch 340: ReduceLROnPlateau reducing learning rate to 0.00531440949998796.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8903 - loss: 0.3549 - val_accuracy: 0.8653 - val_loss: 1.1509 - learning_rate: 0.0059\n",
      "Epoch 341/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8798 - loss: 0.3607 - val_accuracy: 0.8720 - val_loss: 1.1573 - learning_rate: 0.0053\n",
      "Epoch 342/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8892 - loss: 0.3510 - val_accuracy: 0.8747 - val_loss: 1.1602 - learning_rate: 0.0053\n",
      "Epoch 343/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8861 - loss: 0.3568 - val_accuracy: 0.8707 - val_loss: 1.1597 - learning_rate: 0.0053\n",
      "Epoch 344/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8859 - loss: 0.3531 - val_accuracy: 0.8640 - val_loss: 1.1722 - learning_rate: 0.0053\n",
      "Epoch 345/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8801 - loss: 0.3684 - val_accuracy: 0.8760 - val_loss: 1.1611 - learning_rate: 0.0053\n",
      "Epoch 346/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.3618 - val_accuracy: 0.8647 - val_loss: 1.1636 - learning_rate: 0.0053\n",
      "Epoch 347/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8829 - loss: 0.3617 - val_accuracy: 0.8687 - val_loss: 1.1523 - learning_rate: 0.0053\n",
      "Epoch 348/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8866 - loss: 0.3697 - val_accuracy: 0.8693 - val_loss: 1.1930 - learning_rate: 0.0053\n",
      "Epoch 349/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8876 - loss: 0.3534 - val_accuracy: 0.8647 - val_loss: 1.1730 - learning_rate: 0.0053\n",
      "Epoch 350/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8907 - loss: 0.3510 - val_accuracy: 0.8647 - val_loss: 1.1621 - learning_rate: 0.0053\n",
      "Epoch 351/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8847 - loss: 0.3567 - val_accuracy: 0.8773 - val_loss: 1.1628 - learning_rate: 0.0053\n",
      "Epoch 352/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8838 - loss: 0.3587 - val_accuracy: 0.8687 - val_loss: 1.1732 - learning_rate: 0.0053\n",
      "Epoch 353/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8860 - loss: 0.3513 - val_accuracy: 0.8760 - val_loss: 1.1648 - learning_rate: 0.0053\n",
      "Epoch 354/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8888 - loss: 0.3443 - val_accuracy: 0.8600 - val_loss: 1.1618 - learning_rate: 0.0053\n",
      "Epoch 355/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8883 - loss: 0.3477 - val_accuracy: 0.8633 - val_loss: 1.1762 - learning_rate: 0.0053\n",
      "Epoch 356/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8842 - loss: 0.3500 - val_accuracy: 0.8747 - val_loss: 1.1745 - learning_rate: 0.0053\n",
      "Epoch 357/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.3496 - val_accuracy: 0.8820 - val_loss: 1.1741 - learning_rate: 0.0053\n",
      "Epoch 358/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.3456 - val_accuracy: 0.8587 - val_loss: 1.2011 - learning_rate: 0.0053\n",
      "Epoch 359/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8824 - loss: 0.3715 - val_accuracy: 0.8707 - val_loss: 1.1866 - learning_rate: 0.0053\n",
      "Epoch 360/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8820 - loss: 0.3555 - val_accuracy: 0.8747 - val_loss: 1.2066 - learning_rate: 0.0053\n",
      "Epoch 361/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8862 - loss: 0.3511 - val_accuracy: 0.8733 - val_loss: 1.2226 - learning_rate: 0.0053\n",
      "Epoch 362/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8858 - loss: 0.3468 - val_accuracy: 0.8807 - val_loss: 1.1816 - learning_rate: 0.0053\n",
      "Epoch 363/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8884 - loss: 0.3578 - val_accuracy: 0.8640 - val_loss: 1.2132 - learning_rate: 0.0053\n",
      "Epoch 364/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.3649 - val_accuracy: 0.8820 - val_loss: 1.2048 - learning_rate: 0.0053\n",
      "Epoch 365/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.3497 - val_accuracy: 0.8733 - val_loss: 1.2151 - learning_rate: 0.0053\n",
      "Epoch 366/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8954 - loss: 0.3423 - val_accuracy: 0.8713 - val_loss: 1.2357 - learning_rate: 0.0053\n",
      "Epoch 367/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8892 - loss: 0.3436 - val_accuracy: 0.8647 - val_loss: 1.2508 - learning_rate: 0.0053\n",
      "Epoch 368/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8823 - loss: 0.3574 - val_accuracy: 0.8727 - val_loss: 1.2245 - learning_rate: 0.0053\n",
      "Epoch 369/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3591 - val_accuracy: 0.8667 - val_loss: 1.2394 - learning_rate: 0.0053\n",
      "Epoch 370/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8892 - loss: 0.3506 - val_accuracy: 0.8680 - val_loss: 1.2290 - learning_rate: 0.0053\n",
      "Epoch 371/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8853 - loss: 0.3536 - val_accuracy: 0.8633 - val_loss: 1.2405 - learning_rate: 0.0053\n",
      "Epoch 372/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8827 - loss: 0.3708 - val_accuracy: 0.8673 - val_loss: 1.2194 - learning_rate: 0.0053\n",
      "Epoch 373/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8890 - loss: 0.3515 - val_accuracy: 0.8733 - val_loss: 1.1937 - learning_rate: 0.0053\n",
      "Epoch 374/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8844 - loss: 0.3614 - val_accuracy: 0.8680 - val_loss: 1.2027 - learning_rate: 0.0053\n",
      "Epoch 375/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8852 - loss: 0.3556 - val_accuracy: 0.8880 - val_loss: 1.1953 - learning_rate: 0.0053\n",
      "Epoch 376/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9007 - loss: 0.3300 - val_accuracy: 0.8847 - val_loss: 1.2097 - learning_rate: 0.0053\n",
      "Epoch 377/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8904 - loss: 0.3606 - val_accuracy: 0.8787 - val_loss: 1.2014 - learning_rate: 0.0053\n",
      "Epoch 378/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8822 - loss: 0.3728 - val_accuracy: 0.8793 - val_loss: 1.2179 - learning_rate: 0.0053\n",
      "Epoch 379/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3761 - val_accuracy: 0.8733 - val_loss: 1.2114 - learning_rate: 0.0053\n",
      "Epoch 380/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 722us/step - accuracy: 0.8967 - loss: 0.3623\n",
      "Epoch 380: ReduceLROnPlateau reducing learning rate to 0.004782968759536744.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8917 - loss: 0.3576 - val_accuracy: 0.8687 - val_loss: 1.2116 - learning_rate: 0.0053\n",
      "Epoch 381/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8879 - loss: 0.3535 - val_accuracy: 0.8680 - val_loss: 1.2005 - learning_rate: 0.0048\n",
      "Epoch 382/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8916 - loss: 0.3412 - val_accuracy: 0.8753 - val_loss: 1.2294 - learning_rate: 0.0048\n",
      "Epoch 383/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.3785 - val_accuracy: 0.8753 - val_loss: 1.2230 - learning_rate: 0.0048\n",
      "Epoch 384/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8843 - loss: 0.3548 - val_accuracy: 0.8727 - val_loss: 1.2122 - learning_rate: 0.0048\n",
      "Epoch 385/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8886 - loss: 0.3492 - val_accuracy: 0.8727 - val_loss: 1.2234 - learning_rate: 0.0048\n",
      "Epoch 386/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8864 - loss: 0.3531 - val_accuracy: 0.8860 - val_loss: 1.2192 - learning_rate: 0.0048\n",
      "Epoch 387/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8919 - loss: 0.3422 - val_accuracy: 0.8813 - val_loss: 1.2517 - learning_rate: 0.0048\n",
      "Epoch 388/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8995 - loss: 0.3403 - val_accuracy: 0.8800 - val_loss: 1.2456 - learning_rate: 0.0048\n",
      "Epoch 389/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8908 - loss: 0.3537 - val_accuracy: 0.8740 - val_loss: 1.2614 - learning_rate: 0.0048\n",
      "Epoch 390/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8905 - loss: 0.3432 - val_accuracy: 0.8780 - val_loss: 1.2522 - learning_rate: 0.0048\n",
      "Epoch 391/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8923 - loss: 0.3406 - val_accuracy: 0.8660 - val_loss: 1.2741 - learning_rate: 0.0048\n",
      "Epoch 392/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.3450 - val_accuracy: 0.8767 - val_loss: 1.2691 - learning_rate: 0.0048\n",
      "Epoch 393/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8916 - loss: 0.3379 - val_accuracy: 0.8680 - val_loss: 1.2763 - learning_rate: 0.0048\n",
      "Epoch 394/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8914 - loss: 0.3417 - val_accuracy: 0.8660 - val_loss: 1.2653 - learning_rate: 0.0048\n",
      "Epoch 395/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8915 - loss: 0.3537 - val_accuracy: 0.8773 - val_loss: 1.2792 - learning_rate: 0.0048\n",
      "Epoch 396/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8801 - loss: 0.3657 - val_accuracy: 0.8753 - val_loss: 1.2745 - learning_rate: 0.0048\n",
      "Epoch 397/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8916 - loss: 0.3473 - val_accuracy: 0.8607 - val_loss: 1.2785 - learning_rate: 0.0048\n",
      "Epoch 398/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8882 - loss: 0.3524 - val_accuracy: 0.8707 - val_loss: 1.2817 - learning_rate: 0.0048\n",
      "Epoch 399/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8925 - loss: 0.3445 - val_accuracy: 0.8793 - val_loss: 1.2625 - learning_rate: 0.0048\n",
      "Epoch 400/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8905 - loss: 0.3537 - val_accuracy: 0.8720 - val_loss: 1.2873 - learning_rate: 0.0048\n",
      "Epoch 401/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.3457 - val_accuracy: 0.8733 - val_loss: 1.3071 - learning_rate: 0.0048\n",
      "Epoch 402/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8927 - loss: 0.3398 - val_accuracy: 0.8740 - val_loss: 1.3097 - learning_rate: 0.0048\n",
      "Epoch 403/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8874 - loss: 0.3501 - val_accuracy: 0.8780 - val_loss: 1.3142 - learning_rate: 0.0048\n",
      "Epoch 404/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8963 - loss: 0.3366 - val_accuracy: 0.8727 - val_loss: 1.3098 - learning_rate: 0.0048\n",
      "Epoch 405/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8839 - loss: 0.3691 - val_accuracy: 0.8633 - val_loss: 1.3013 - learning_rate: 0.0048\n",
      "Epoch 406/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8830 - loss: 0.3659 - val_accuracy: 0.8693 - val_loss: 1.3149 - learning_rate: 0.0048\n",
      "Epoch 407/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8898 - loss: 0.3645 - val_accuracy: 0.8813 - val_loss: 1.3075 - learning_rate: 0.0048\n",
      "Epoch 408/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.3429 - val_accuracy: 0.8787 - val_loss: 1.2899 - learning_rate: 0.0048\n",
      "Epoch 409/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8942 - loss: 0.3702 - val_accuracy: 0.8687 - val_loss: 1.3072 - learning_rate: 0.0048\n",
      "Epoch 410/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8897 - loss: 0.3496 - val_accuracy: 0.8760 - val_loss: 1.3067 - learning_rate: 0.0048\n",
      "Epoch 411/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.3525 - val_accuracy: 0.8693 - val_loss: 1.2772 - learning_rate: 0.0048\n",
      "Epoch 412/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.3519 - val_accuracy: 0.8700 - val_loss: 1.2897 - learning_rate: 0.0048\n",
      "Epoch 413/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8887 - loss: 0.3557 - val_accuracy: 0.8793 - val_loss: 1.3035 - learning_rate: 0.0048\n",
      "Epoch 414/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.3460 - val_accuracy: 0.8747 - val_loss: 1.2595 - learning_rate: 0.0048\n",
      "Epoch 415/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8959 - loss: 0.3324 - val_accuracy: 0.8733 - val_loss: 1.2570 - learning_rate: 0.0048\n",
      "Epoch 416/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8948 - loss: 0.3281 - val_accuracy: 0.8700 - val_loss: 1.2564 - learning_rate: 0.0048\n",
      "Epoch 417/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8867 - loss: 0.3425 - val_accuracy: 0.8813 - val_loss: 1.2867 - learning_rate: 0.0048\n",
      "Epoch 418/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8938 - loss: 0.3441 - val_accuracy: 0.8747 - val_loss: 1.2811 - learning_rate: 0.0048\n",
      "Epoch 419/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8883 - loss: 0.3463 - val_accuracy: 0.8747 - val_loss: 1.2756 - learning_rate: 0.0048\n",
      "Epoch 420/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 925us/step - accuracy: 0.9042 - loss: 0.3287\n",
      "Epoch 420: ReduceLROnPlateau reducing learning rate to 0.0043046717997640375.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.3424 - val_accuracy: 0.8747 - val_loss: 1.2873 - learning_rate: 0.0048\n",
      "Epoch 421/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.3499 - val_accuracy: 0.8713 - val_loss: 1.2997 - learning_rate: 0.0043\n",
      "Epoch 422/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8950 - loss: 0.3385 - val_accuracy: 0.8867 - val_loss: 1.2758 - learning_rate: 0.0043\n",
      "Epoch 423/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.3278 - val_accuracy: 0.8807 - val_loss: 1.2816 - learning_rate: 0.0043\n",
      "Epoch 424/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9010 - loss: 0.3307 - val_accuracy: 0.8800 - val_loss: 1.3069 - learning_rate: 0.0043\n",
      "Epoch 425/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8935 - loss: 0.3527 - val_accuracy: 0.8767 - val_loss: 1.3140 - learning_rate: 0.0043\n",
      "Epoch 426/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8872 - loss: 0.3408 - val_accuracy: 0.8673 - val_loss: 1.2986 - learning_rate: 0.0043\n",
      "Epoch 427/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8926 - loss: 0.3236 - val_accuracy: 0.8747 - val_loss: 1.3035 - learning_rate: 0.0043\n",
      "Epoch 428/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.3353 - val_accuracy: 0.8793 - val_loss: 1.2963 - learning_rate: 0.0043\n",
      "Epoch 429/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8971 - loss: 0.3337 - val_accuracy: 0.8800 - val_loss: 1.3059 - learning_rate: 0.0043\n",
      "Epoch 430/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8884 - loss: 0.3334 - val_accuracy: 0.8880 - val_loss: 1.3092 - learning_rate: 0.0043\n",
      "Epoch 431/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.3501 - val_accuracy: 0.8740 - val_loss: 1.3056 - learning_rate: 0.0043\n",
      "Epoch 432/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8934 - loss: 0.3420 - val_accuracy: 0.8880 - val_loss: 1.2913 - learning_rate: 0.0043\n",
      "Epoch 433/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8977 - loss: 0.3413 - val_accuracy: 0.8793 - val_loss: 1.3068 - learning_rate: 0.0043\n",
      "Epoch 434/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8979 - loss: 0.3319 - val_accuracy: 0.8707 - val_loss: 1.3104 - learning_rate: 0.0043\n",
      "Epoch 435/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3558 - val_accuracy: 0.8740 - val_loss: 1.2991 - learning_rate: 0.0043\n",
      "Epoch 436/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8937 - loss: 0.3408 - val_accuracy: 0.8760 - val_loss: 1.3225 - learning_rate: 0.0043\n",
      "Epoch 437/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3514 - val_accuracy: 0.8753 - val_loss: 1.3314 - learning_rate: 0.0043\n",
      "Epoch 438/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8957 - loss: 0.3273 - val_accuracy: 0.8787 - val_loss: 1.3347 - learning_rate: 0.0043\n",
      "Epoch 439/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.3400 - val_accuracy: 0.8747 - val_loss: 1.3250 - learning_rate: 0.0043\n",
      "Epoch 440/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8926 - loss: 0.3388 - val_accuracy: 0.8820 - val_loss: 1.3214 - learning_rate: 0.0043\n",
      "Epoch 441/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8944 - loss: 0.3452 - val_accuracy: 0.8713 - val_loss: 1.3375 - learning_rate: 0.0043\n",
      "Epoch 442/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.3434 - val_accuracy: 0.8720 - val_loss: 1.3290 - learning_rate: 0.0043\n",
      "Epoch 443/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8893 - loss: 0.3549 - val_accuracy: 0.8833 - val_loss: 1.3352 - learning_rate: 0.0043\n",
      "Epoch 444/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.3334 - val_accuracy: 0.8753 - val_loss: 1.3219 - learning_rate: 0.0043\n",
      "Epoch 445/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8933 - loss: 0.3314 - val_accuracy: 0.8800 - val_loss: 1.3211 - learning_rate: 0.0043\n",
      "Epoch 446/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8912 - loss: 0.3459 - val_accuracy: 0.8720 - val_loss: 1.3377 - learning_rate: 0.0043\n",
      "Epoch 447/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9031 - loss: 0.3262 - val_accuracy: 0.8773 - val_loss: 1.3268 - learning_rate: 0.0043\n",
      "Epoch 448/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3352 - val_accuracy: 0.8733 - val_loss: 1.3320 - learning_rate: 0.0043\n",
      "Epoch 449/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8930 - loss: 0.3329 - val_accuracy: 0.8633 - val_loss: 1.3290 - learning_rate: 0.0043\n",
      "Epoch 450/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8912 - loss: 0.3475 - val_accuracy: 0.8713 - val_loss: 1.3514 - learning_rate: 0.0043\n",
      "Epoch 451/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.3340 - val_accuracy: 0.8847 - val_loss: 1.3316 - learning_rate: 0.0043\n",
      "Epoch 452/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8922 - loss: 0.3588 - val_accuracy: 0.8820 - val_loss: 1.3254 - learning_rate: 0.0043\n",
      "Epoch 453/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.3359 - val_accuracy: 0.8713 - val_loss: 1.3273 - learning_rate: 0.0043\n",
      "Epoch 454/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8948 - loss: 0.3391 - val_accuracy: 0.8720 - val_loss: 1.3443 - learning_rate: 0.0043\n",
      "Epoch 455/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8935 - loss: 0.3401 - val_accuracy: 0.8893 - val_loss: 1.3403 - learning_rate: 0.0043\n",
      "Epoch 456/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.3317 - val_accuracy: 0.8867 - val_loss: 1.3381 - learning_rate: 0.0043\n",
      "Epoch 457/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8941 - loss: 0.3405 - val_accuracy: 0.8887 - val_loss: 1.3523 - learning_rate: 0.0043\n",
      "Epoch 458/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8970 - loss: 0.3457 - val_accuracy: 0.8787 - val_loss: 1.3234 - learning_rate: 0.0043\n",
      "Epoch 459/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8967 - loss: 0.3231 - val_accuracy: 0.8713 - val_loss: 1.3392 - learning_rate: 0.0043\n",
      "Epoch 460/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.3219\n",
      "Epoch 460: ReduceLROnPlateau reducing learning rate to 0.0038742044940590858.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9001 - loss: 0.3289 - val_accuracy: 0.8873 - val_loss: 1.3551 - learning_rate: 0.0043\n",
      "Epoch 461/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8940 - loss: 0.3317 - val_accuracy: 0.8900 - val_loss: 1.3419 - learning_rate: 0.0039\n",
      "Epoch 462/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.3290 - val_accuracy: 0.8687 - val_loss: 1.3351 - learning_rate: 0.0039\n",
      "Epoch 463/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8867 - loss: 0.3423 - val_accuracy: 0.8720 - val_loss: 1.3468 - learning_rate: 0.0039\n",
      "Epoch 464/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8931 - loss: 0.3439 - val_accuracy: 0.8787 - val_loss: 1.3410 - learning_rate: 0.0039\n",
      "Epoch 465/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8941 - loss: 0.3364 - val_accuracy: 0.8700 - val_loss: 1.3512 - learning_rate: 0.0039\n",
      "Epoch 466/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8922 - loss: 0.3357 - val_accuracy: 0.8700 - val_loss: 1.3603 - learning_rate: 0.0039\n",
      "Epoch 467/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8884 - loss: 0.3420 - val_accuracy: 0.8740 - val_loss: 1.3555 - learning_rate: 0.0039\n",
      "Epoch 468/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8943 - loss: 0.3346 - val_accuracy: 0.8853 - val_loss: 1.3569 - learning_rate: 0.0039\n",
      "Epoch 469/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8924 - loss: 0.3509 - val_accuracy: 0.8873 - val_loss: 1.3715 - learning_rate: 0.0039\n",
      "Epoch 470/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8931 - loss: 0.3413 - val_accuracy: 0.8807 - val_loss: 1.3654 - learning_rate: 0.0039\n",
      "Epoch 471/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.3258 - val_accuracy: 0.8753 - val_loss: 1.3669 - learning_rate: 0.0039\n",
      "Epoch 472/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8938 - loss: 0.3421 - val_accuracy: 0.8787 - val_loss: 1.3664 - learning_rate: 0.0039\n",
      "Epoch 473/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8939 - loss: 0.3402 - val_accuracy: 0.8833 - val_loss: 1.3605 - learning_rate: 0.0039\n",
      "Epoch 474/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.3397 - val_accuracy: 0.8773 - val_loss: 1.3580 - learning_rate: 0.0039\n",
      "Epoch 475/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8929 - loss: 0.3266 - val_accuracy: 0.8873 - val_loss: 1.3641 - learning_rate: 0.0039\n",
      "Epoch 476/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8968 - loss: 0.3308 - val_accuracy: 0.8773 - val_loss: 1.3654 - learning_rate: 0.0039\n",
      "Epoch 477/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8996 - loss: 0.3378 - val_accuracy: 0.8727 - val_loss: 1.3734 - learning_rate: 0.0039\n",
      "Epoch 478/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8949 - loss: 0.3332 - val_accuracy: 0.8727 - val_loss: 1.3786 - learning_rate: 0.0039\n",
      "Epoch 479/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.3352 - val_accuracy: 0.8727 - val_loss: 1.3737 - learning_rate: 0.0039\n",
      "Epoch 480/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8941 - loss: 0.3441 - val_accuracy: 0.8707 - val_loss: 1.3615 - learning_rate: 0.0039\n",
      "Epoch 481/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8906 - loss: 0.3461 - val_accuracy: 0.8707 - val_loss: 1.3864 - learning_rate: 0.0039\n",
      "Epoch 482/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8918 - loss: 0.3409 - val_accuracy: 0.8707 - val_loss: 1.3738 - learning_rate: 0.0039\n",
      "Epoch 483/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8907 - loss: 0.3333 - val_accuracy: 0.8887 - val_loss: 1.3792 - learning_rate: 0.0039\n",
      "Epoch 484/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9009 - loss: 0.3329 - val_accuracy: 0.8847 - val_loss: 1.3782 - learning_rate: 0.0039\n",
      "Epoch 485/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9010 - loss: 0.3372 - val_accuracy: 0.8907 - val_loss: 1.3848 - learning_rate: 0.0039\n",
      "Epoch 486/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8959 - loss: 0.3276 - val_accuracy: 0.8673 - val_loss: 1.3996 - learning_rate: 0.0039\n",
      "Epoch 487/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8835 - loss: 0.3572 - val_accuracy: 0.8807 - val_loss: 1.3847 - learning_rate: 0.0039\n",
      "Epoch 488/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8931 - loss: 0.3392 - val_accuracy: 0.8800 - val_loss: 1.3971 - learning_rate: 0.0039\n",
      "Epoch 489/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8999 - loss: 0.3213 - val_accuracy: 0.8747 - val_loss: 1.3948 - learning_rate: 0.0039\n",
      "Epoch 490/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8939 - loss: 0.3326 - val_accuracy: 0.8793 - val_loss: 1.3837 - learning_rate: 0.0039\n",
      "Epoch 491/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8921 - loss: 0.3394 - val_accuracy: 0.8800 - val_loss: 1.3992 - learning_rate: 0.0039\n",
      "Epoch 492/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8946 - loss: 0.3398 - val_accuracy: 0.8747 - val_loss: 1.3940 - learning_rate: 0.0039\n",
      "Epoch 493/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8971 - loss: 0.3278 - val_accuracy: 0.8833 - val_loss: 1.4036 - learning_rate: 0.0039\n",
      "Epoch 494/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8966 - loss: 0.3355 - val_accuracy: 0.8753 - val_loss: 1.4057 - learning_rate: 0.0039\n",
      "Epoch 495/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8960 - loss: 0.3306 - val_accuracy: 0.8900 - val_loss: 1.3903 - learning_rate: 0.0039\n",
      "Epoch 496/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9040 - loss: 0.3135 - val_accuracy: 0.8813 - val_loss: 1.4178 - learning_rate: 0.0039\n",
      "Epoch 497/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.3513 - val_accuracy: 0.8853 - val_loss: 1.4089 - learning_rate: 0.0039\n",
      "Epoch 498/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8956 - loss: 0.3356 - val_accuracy: 0.8820 - val_loss: 1.4077 - learning_rate: 0.0039\n",
      "Epoch 499/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.3385 - val_accuracy: 0.8727 - val_loss: 1.4023 - learning_rate: 0.0039\n",
      "Epoch 500/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8956 - loss: 0.3005 \n",
      "Epoch 500: ReduceLROnPlateau reducing learning rate to 0.003486784128472209.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.3202 - val_accuracy: 0.8760 - val_loss: 1.4123 - learning_rate: 0.0039\n",
      "Epoch 501/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9028 - loss: 0.3258 - val_accuracy: 0.8727 - val_loss: 1.4093 - learning_rate: 0.0035\n",
      "Epoch 502/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8920 - loss: 0.3370 - val_accuracy: 0.8827 - val_loss: 1.4036 - learning_rate: 0.0035\n",
      "Epoch 503/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8964 - loss: 0.3343 - val_accuracy: 0.8840 - val_loss: 1.4119 - learning_rate: 0.0035\n",
      "Epoch 504/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.3285 - val_accuracy: 0.8773 - val_loss: 1.4241 - learning_rate: 0.0035\n",
      "Epoch 505/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.3271 - val_accuracy: 0.8720 - val_loss: 1.4344 - learning_rate: 0.0035\n",
      "Epoch 506/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.3357 - val_accuracy: 0.8833 - val_loss: 1.4269 - learning_rate: 0.0035\n",
      "Epoch 507/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8969 - loss: 0.3430 - val_accuracy: 0.8880 - val_loss: 1.4178 - learning_rate: 0.0035\n",
      "Epoch 508/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8994 - loss: 0.3302 - val_accuracy: 0.8800 - val_loss: 1.4415 - learning_rate: 0.0035\n",
      "Epoch 509/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8995 - loss: 0.3224 - val_accuracy: 0.8687 - val_loss: 1.4584 - learning_rate: 0.0035\n",
      "Epoch 510/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8932 - loss: 0.3364 - val_accuracy: 0.8753 - val_loss: 1.4185 - learning_rate: 0.0035\n",
      "Epoch 511/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.3227 - val_accuracy: 0.8807 - val_loss: 1.4211 - learning_rate: 0.0035\n",
      "Epoch 512/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.3118 - val_accuracy: 0.8840 - val_loss: 1.4151 - learning_rate: 0.0035\n",
      "Epoch 513/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.3355 - val_accuracy: 0.8800 - val_loss: 1.4183 - learning_rate: 0.0035\n",
      "Epoch 514/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8951 - loss: 0.3299 - val_accuracy: 0.8873 - val_loss: 1.4155 - learning_rate: 0.0035\n",
      "Epoch 515/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.3262 - val_accuracy: 0.8833 - val_loss: 1.4076 - learning_rate: 0.0035\n",
      "Epoch 516/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.3214 - val_accuracy: 0.8713 - val_loss: 1.4053 - learning_rate: 0.0035\n",
      "Epoch 517/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8929 - loss: 0.3342 - val_accuracy: 0.8787 - val_loss: 1.4168 - learning_rate: 0.0035\n",
      "Epoch 518/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8983 - loss: 0.3288 - val_accuracy: 0.8887 - val_loss: 1.4207 - learning_rate: 0.0035\n",
      "Epoch 519/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.3239 - val_accuracy: 0.8713 - val_loss: 1.4429 - learning_rate: 0.0035\n",
      "Epoch 520/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8961 - loss: 0.3330 - val_accuracy: 0.8840 - val_loss: 1.4340 - learning_rate: 0.0035\n",
      "Epoch 521/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.3274 - val_accuracy: 0.8827 - val_loss: 1.4414 - learning_rate: 0.0035\n",
      "Epoch 522/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.3323 - val_accuracy: 0.8873 - val_loss: 1.4270 - learning_rate: 0.0035\n",
      "Epoch 523/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.3124 - val_accuracy: 0.8600 - val_loss: 1.4274 - learning_rate: 0.0035\n",
      "Epoch 524/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8821 - loss: 0.3630 - val_accuracy: 0.8833 - val_loss: 1.4254 - learning_rate: 0.0035\n",
      "Epoch 525/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3355 - val_accuracy: 0.8807 - val_loss: 1.4317 - learning_rate: 0.0035\n",
      "Epoch 526/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8943 - loss: 0.3332 - val_accuracy: 0.8793 - val_loss: 1.4361 - learning_rate: 0.0035\n",
      "Epoch 527/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8972 - loss: 0.3252 - val_accuracy: 0.8833 - val_loss: 1.4335 - learning_rate: 0.0035\n",
      "Epoch 528/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3268 - val_accuracy: 0.8793 - val_loss: 1.4314 - learning_rate: 0.0035\n",
      "Epoch 529/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.3096 - val_accuracy: 0.8740 - val_loss: 1.4355 - learning_rate: 0.0035\n",
      "Epoch 530/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9010 - loss: 0.3215 - val_accuracy: 0.8800 - val_loss: 1.4457 - learning_rate: 0.0035\n",
      "Epoch 531/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9035 - loss: 0.3211 - val_accuracy: 0.8773 - val_loss: 1.4389 - learning_rate: 0.0035\n",
      "Epoch 532/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.3309 - val_accuracy: 0.8800 - val_loss: 1.4457 - learning_rate: 0.0035\n",
      "Epoch 533/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.3324 - val_accuracy: 0.8840 - val_loss: 1.4552 - learning_rate: 0.0035\n",
      "Epoch 534/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9004 - loss: 0.3312 - val_accuracy: 0.8880 - val_loss: 1.4446 - learning_rate: 0.0035\n",
      "Epoch 535/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8990 - loss: 0.3332 - val_accuracy: 0.8887 - val_loss: 1.4453 - learning_rate: 0.0035\n",
      "Epoch 536/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.3327 - val_accuracy: 0.8820 - val_loss: 1.4481 - learning_rate: 0.0035\n",
      "Epoch 537/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8950 - loss: 0.3367 - val_accuracy: 0.8800 - val_loss: 1.4384 - learning_rate: 0.0035\n",
      "Epoch 538/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8923 - loss: 0.3378 - val_accuracy: 0.8787 - val_loss: 1.4493 - learning_rate: 0.0035\n",
      "Epoch 539/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9016 - loss: 0.3252 - val_accuracy: 0.8740 - val_loss: 1.4677 - learning_rate: 0.0035\n",
      "Epoch 540/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.3555 \n",
      "Epoch 540: ReduceLROnPlateau reducing learning rate to 0.003138105757534504.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8978 - loss: 0.3385 - val_accuracy: 0.8707 - val_loss: 1.4638 - learning_rate: 0.0035\n",
      "Epoch 541/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8936 - loss: 0.3437 - val_accuracy: 0.8827 - val_loss: 1.4423 - learning_rate: 0.0031\n",
      "Epoch 542/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.3226 - val_accuracy: 0.8767 - val_loss: 1.4639 - learning_rate: 0.0031\n",
      "Epoch 543/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8971 - loss: 0.3348 - val_accuracy: 0.8853 - val_loss: 1.4666 - learning_rate: 0.0031\n",
      "Epoch 544/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8986 - loss: 0.3289 - val_accuracy: 0.8760 - val_loss: 1.4781 - learning_rate: 0.0031\n",
      "Epoch 545/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8981 - loss: 0.3202 - val_accuracy: 0.8840 - val_loss: 1.4658 - learning_rate: 0.0031\n",
      "Epoch 546/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8947 - loss: 0.3359 - val_accuracy: 0.8880 - val_loss: 1.4716 - learning_rate: 0.0031\n",
      "Epoch 547/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8947 - loss: 0.3331 - val_accuracy: 0.8880 - val_loss: 1.4745 - learning_rate: 0.0031\n",
      "Epoch 548/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9051 - loss: 0.3201 - val_accuracy: 0.8907 - val_loss: 1.4593 - learning_rate: 0.0031\n",
      "Epoch 549/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9048 - loss: 0.3110 - val_accuracy: 0.8820 - val_loss: 1.4651 - learning_rate: 0.0031\n",
      "Epoch 550/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.3231 - val_accuracy: 0.8900 - val_loss: 1.4668 - learning_rate: 0.0031\n",
      "Epoch 551/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.3191 - val_accuracy: 0.8787 - val_loss: 1.4822 - learning_rate: 0.0031\n",
      "Epoch 552/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8946 - loss: 0.3422 - val_accuracy: 0.8800 - val_loss: 1.4831 - learning_rate: 0.0031\n",
      "Epoch 553/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.3259 - val_accuracy: 0.8873 - val_loss: 1.4813 - learning_rate: 0.0031\n",
      "Epoch 554/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8982 - loss: 0.3290 - val_accuracy: 0.8740 - val_loss: 1.4995 - learning_rate: 0.0031\n",
      "Epoch 555/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8970 - loss: 0.3321 - val_accuracy: 0.8847 - val_loss: 1.5115 - learning_rate: 0.0031\n",
      "Epoch 556/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9005 - loss: 0.3298 - val_accuracy: 0.8940 - val_loss: 1.5084 - learning_rate: 0.0031\n",
      "Epoch 557/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8974 - loss: 0.3373 - val_accuracy: 0.8840 - val_loss: 1.5113 - learning_rate: 0.0031\n",
      "Epoch 558/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8974 - loss: 0.3281 - val_accuracy: 0.8807 - val_loss: 1.5078 - learning_rate: 0.0031\n",
      "Epoch 559/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8992 - loss: 0.3207 - val_accuracy: 0.8873 - val_loss: 1.4979 - learning_rate: 0.0031\n",
      "Epoch 560/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8994 - loss: 0.3259 - val_accuracy: 0.8913 - val_loss: 1.5072 - learning_rate: 0.0031\n",
      "Epoch 561/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.3265 - val_accuracy: 0.8727 - val_loss: 1.5108 - learning_rate: 0.0031\n",
      "Epoch 562/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8910 - loss: 0.3368 - val_accuracy: 0.8780 - val_loss: 1.5143 - learning_rate: 0.0031\n",
      "Epoch 563/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8988 - loss: 0.3328 - val_accuracy: 0.8780 - val_loss: 1.5230 - learning_rate: 0.0031\n",
      "Epoch 564/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.3178 - val_accuracy: 0.8867 - val_loss: 1.5332 - learning_rate: 0.0031\n",
      "Epoch 565/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.3213 - val_accuracy: 0.8833 - val_loss: 1.5274 - learning_rate: 0.0031\n",
      "Epoch 566/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8998 - loss: 0.3213 - val_accuracy: 0.8853 - val_loss: 1.5229 - learning_rate: 0.0031\n",
      "Epoch 567/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8984 - loss: 0.3269 - val_accuracy: 0.8813 - val_loss: 1.5274 - learning_rate: 0.0031\n",
      "Epoch 568/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8991 - loss: 0.3238 - val_accuracy: 0.8727 - val_loss: 1.5167 - learning_rate: 0.0031\n",
      "Epoch 569/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8941 - loss: 0.3310 - val_accuracy: 0.8847 - val_loss: 1.5255 - learning_rate: 0.0031\n",
      "Epoch 570/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9032 - loss: 0.3251 - val_accuracy: 0.8847 - val_loss: 1.5305 - learning_rate: 0.0031\n",
      "Epoch 571/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8970 - loss: 0.3249 - val_accuracy: 0.8767 - val_loss: 1.5326 - learning_rate: 0.0031\n",
      "Epoch 572/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.3319 - val_accuracy: 0.8820 - val_loss: 1.5344 - learning_rate: 0.0031\n",
      "Epoch 573/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8998 - loss: 0.3253 - val_accuracy: 0.8780 - val_loss: 1.5459 - learning_rate: 0.0031\n",
      "Epoch 574/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.3215 - val_accuracy: 0.8727 - val_loss: 1.5437 - learning_rate: 0.0031\n",
      "Epoch 575/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8986 - loss: 0.3254 - val_accuracy: 0.8867 - val_loss: 1.5429 - learning_rate: 0.0031\n",
      "Epoch 576/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.3161 - val_accuracy: 0.8880 - val_loss: 1.5397 - learning_rate: 0.0031\n",
      "Epoch 577/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8996 - loss: 0.3230 - val_accuracy: 0.8907 - val_loss: 1.5598 - learning_rate: 0.0031\n",
      "Epoch 578/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.3384 - val_accuracy: 0.8860 - val_loss: 1.5539 - learning_rate: 0.0031\n",
      "Epoch 579/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.3094 - val_accuracy: 0.8820 - val_loss: 1.5613 - learning_rate: 0.0031\n",
      "Epoch 580/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.3500 \n",
      "Epoch 580: ReduceLROnPlateau reducing learning rate to 0.0028242952656000854.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8981 - loss: 0.3295 - val_accuracy: 0.8780 - val_loss: 1.5707 - learning_rate: 0.0031\n",
      "Epoch 581/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8962 - loss: 0.3371 - val_accuracy: 0.8780 - val_loss: 1.5737 - learning_rate: 0.0028\n",
      "Epoch 582/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8977 - loss: 0.3338 - val_accuracy: 0.8787 - val_loss: 1.5732 - learning_rate: 0.0028\n",
      "Epoch 583/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8975 - loss: 0.3168 - val_accuracy: 0.8700 - val_loss: 1.5793 - learning_rate: 0.0028\n",
      "Epoch 584/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8896 - loss: 0.3496 - val_accuracy: 0.8707 - val_loss: 1.5746 - learning_rate: 0.0028\n",
      "Epoch 585/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9018 - loss: 0.3263 - val_accuracy: 0.8887 - val_loss: 1.5789 - learning_rate: 0.0028\n",
      "Epoch 586/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3053 - val_accuracy: 0.8827 - val_loss: 1.5663 - learning_rate: 0.0028\n",
      "Epoch 587/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8974 - loss: 0.3274 - val_accuracy: 0.8927 - val_loss: 1.5682 - learning_rate: 0.0028\n",
      "Epoch 588/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2986 - val_accuracy: 0.8807 - val_loss: 1.5747 - learning_rate: 0.0028\n",
      "Epoch 589/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.3201 - val_accuracy: 0.8900 - val_loss: 1.5712 - learning_rate: 0.0028\n",
      "Epoch 590/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9013 - loss: 0.3297 - val_accuracy: 0.8687 - val_loss: 1.5833 - learning_rate: 0.0028\n",
      "Epoch 591/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9006 - loss: 0.3096 - val_accuracy: 0.8887 - val_loss: 1.5559 - learning_rate: 0.0028\n",
      "Epoch 592/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9028 - loss: 0.3163 - val_accuracy: 0.8860 - val_loss: 1.5784 - learning_rate: 0.0028\n",
      "Epoch 593/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.3131 - val_accuracy: 0.8867 - val_loss: 1.5834 - learning_rate: 0.0028\n",
      "Epoch 594/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9027 - loss: 0.3250 - val_accuracy: 0.8780 - val_loss: 1.5931 - learning_rate: 0.0028\n",
      "Epoch 595/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8966 - loss: 0.3320 - val_accuracy: 0.8927 - val_loss: 1.5998 - learning_rate: 0.0028\n",
      "Epoch 596/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9008 - loss: 0.3249 - val_accuracy: 0.8813 - val_loss: 1.6062 - learning_rate: 0.0028\n",
      "Epoch 597/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8935 - loss: 0.3451 - val_accuracy: 0.8827 - val_loss: 1.6174 - learning_rate: 0.0028\n",
      "Epoch 598/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.3182 - val_accuracy: 0.8740 - val_loss: 1.6066 - learning_rate: 0.0028\n",
      "Epoch 599/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.3065 - val_accuracy: 0.8727 - val_loss: 1.6174 - learning_rate: 0.0028\n",
      "Epoch 600/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.3221 - val_accuracy: 0.8653 - val_loss: 1.6248 - learning_rate: 0.0028\n",
      "Epoch 601/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8971 - loss: 0.3210 - val_accuracy: 0.8840 - val_loss: 1.6083 - learning_rate: 0.0028\n",
      "Epoch 602/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.3020 - val_accuracy: 0.8893 - val_loss: 1.6061 - learning_rate: 0.0028\n",
      "Epoch 603/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8952 - loss: 0.3314 - val_accuracy: 0.8893 - val_loss: 1.6114 - learning_rate: 0.0028\n",
      "Epoch 604/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.3258 - val_accuracy: 0.8787 - val_loss: 1.6059 - learning_rate: 0.0028\n",
      "Epoch 605/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8973 - loss: 0.3186 - val_accuracy: 0.8807 - val_loss: 1.6129 - learning_rate: 0.0028\n",
      "Epoch 606/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9006 - loss: 0.3134 - val_accuracy: 0.8840 - val_loss: 1.6228 - learning_rate: 0.0028\n",
      "Epoch 607/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8979 - loss: 0.3276 - val_accuracy: 0.8833 - val_loss: 1.6257 - learning_rate: 0.0028\n",
      "Epoch 608/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.3169 - val_accuracy: 0.8920 - val_loss: 1.6252 - learning_rate: 0.0028\n",
      "Epoch 609/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9014 - loss: 0.3342 - val_accuracy: 0.8800 - val_loss: 1.6284 - learning_rate: 0.0028\n",
      "Epoch 610/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8980 - loss: 0.3261 - val_accuracy: 0.8913 - val_loss: 1.6433 - learning_rate: 0.0028\n",
      "Epoch 611/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.3189 - val_accuracy: 0.8847 - val_loss: 1.6312 - learning_rate: 0.0028\n",
      "Epoch 612/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.3298 - val_accuracy: 0.8813 - val_loss: 1.6331 - learning_rate: 0.0028\n",
      "Epoch 613/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.3024 - val_accuracy: 0.8820 - val_loss: 1.6441 - learning_rate: 0.0028\n",
      "Epoch 614/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9049 - loss: 0.3108 - val_accuracy: 0.8767 - val_loss: 1.6359 - learning_rate: 0.0028\n",
      "Epoch 615/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9000 - loss: 0.3268 - val_accuracy: 0.8873 - val_loss: 1.6320 - learning_rate: 0.0028\n",
      "Epoch 616/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.3258 - val_accuracy: 0.8820 - val_loss: 1.6348 - learning_rate: 0.0028\n",
      "Epoch 617/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8984 - loss: 0.3244 - val_accuracy: 0.8847 - val_loss: 1.6343 - learning_rate: 0.0028\n",
      "Epoch 618/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.3210 - val_accuracy: 0.8880 - val_loss: 1.6170 - learning_rate: 0.0028\n",
      "Epoch 619/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.3122 - val_accuracy: 0.8780 - val_loss: 1.6278 - learning_rate: 0.0028\n",
      "Epoch 620/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.3104 2\n",
      "Epoch 620: ReduceLROnPlateau reducing learning rate to 0.0025418657809495927.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9013 - loss: 0.3165 - val_accuracy: 0.8847 - val_loss: 1.6372 - learning_rate: 0.0028\n",
      "Epoch 621/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9014 - loss: 0.3290 - val_accuracy: 0.8673 - val_loss: 1.6376 - learning_rate: 0.0025\n",
      "Epoch 622/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9017 - loss: 0.3091 - val_accuracy: 0.8880 - val_loss: 1.6298 - learning_rate: 0.0025\n",
      "Epoch 623/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.3217 - val_accuracy: 0.8853 - val_loss: 1.6308 - learning_rate: 0.0025\n",
      "Epoch 624/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.3097 - val_accuracy: 0.8867 - val_loss: 1.6433 - learning_rate: 0.0025\n",
      "Epoch 625/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9039 - loss: 0.3137 - val_accuracy: 0.8800 - val_loss: 1.6472 - learning_rate: 0.0025\n",
      "Epoch 626/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.3148 - val_accuracy: 0.8927 - val_loss: 1.6518 - learning_rate: 0.0025\n",
      "Epoch 627/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9022 - loss: 0.3214 - val_accuracy: 0.8887 - val_loss: 1.6526 - learning_rate: 0.0025\n",
      "Epoch 628/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.3179 - val_accuracy: 0.8853 - val_loss: 1.6699 - learning_rate: 0.0025\n",
      "Epoch 629/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.3168 - val_accuracy: 0.8860 - val_loss: 1.6573 - learning_rate: 0.0025\n",
      "Epoch 630/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.3079 - val_accuracy: 0.8907 - val_loss: 1.6706 - learning_rate: 0.0025\n",
      "Epoch 631/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.3164 - val_accuracy: 0.8873 - val_loss: 1.6600 - learning_rate: 0.0025\n",
      "Epoch 632/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.3110 - val_accuracy: 0.8847 - val_loss: 1.6703 - learning_rate: 0.0025\n",
      "Epoch 633/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9021 - loss: 0.3275 - val_accuracy: 0.8907 - val_loss: 1.6620 - learning_rate: 0.0025\n",
      "Epoch 634/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.3117 - val_accuracy: 0.8867 - val_loss: 1.6733 - learning_rate: 0.0025\n",
      "Epoch 635/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9021 - loss: 0.3136 - val_accuracy: 0.8887 - val_loss: 1.6626 - learning_rate: 0.0025\n",
      "Epoch 636/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9007 - loss: 0.3227 - val_accuracy: 0.8913 - val_loss: 1.6910 - learning_rate: 0.0025\n",
      "Epoch 637/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8976 - loss: 0.3273 - val_accuracy: 0.8880 - val_loss: 1.6732 - learning_rate: 0.0025\n",
      "Epoch 638/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.3098 - val_accuracy: 0.8927 - val_loss: 1.6920 - learning_rate: 0.0025\n",
      "Epoch 639/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9001 - loss: 0.3195 - val_accuracy: 0.8860 - val_loss: 1.6913 - learning_rate: 0.0025\n",
      "Epoch 640/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9044 - loss: 0.3148 - val_accuracy: 0.8840 - val_loss: 1.6858 - learning_rate: 0.0025\n",
      "Epoch 641/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.3131 - val_accuracy: 0.8793 - val_loss: 1.6846 - learning_rate: 0.0025\n",
      "Epoch 642/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8966 - loss: 0.3311 - val_accuracy: 0.8767 - val_loss: 1.6931 - learning_rate: 0.0025\n",
      "Epoch 643/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9019 - loss: 0.3223 - val_accuracy: 0.8767 - val_loss: 1.6886 - learning_rate: 0.0025\n",
      "Epoch 644/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8988 - loss: 0.3243 - val_accuracy: 0.8887 - val_loss: 1.6999 - learning_rate: 0.0025\n",
      "Epoch 645/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.3093 - val_accuracy: 0.8813 - val_loss: 1.6950 - learning_rate: 0.0025\n",
      "Epoch 646/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.3106 - val_accuracy: 0.8847 - val_loss: 1.6995 - learning_rate: 0.0025\n",
      "Epoch 647/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.3207 - val_accuracy: 0.8873 - val_loss: 1.7036 - learning_rate: 0.0025\n",
      "Epoch 648/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.3185 - val_accuracy: 0.8860 - val_loss: 1.7063 - learning_rate: 0.0025\n",
      "Epoch 649/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.3183 - val_accuracy: 0.8827 - val_loss: 1.6997 - learning_rate: 0.0025\n",
      "Epoch 650/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.3105 - val_accuracy: 0.8900 - val_loss: 1.6994 - learning_rate: 0.0025\n",
      "Epoch 651/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9035 - loss: 0.3195 - val_accuracy: 0.8880 - val_loss: 1.7093 - learning_rate: 0.0025\n",
      "Epoch 652/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.3232 - val_accuracy: 0.8933 - val_loss: 1.7061 - learning_rate: 0.0025\n",
      "Epoch 653/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9029 - loss: 0.3208 - val_accuracy: 0.8847 - val_loss: 1.6959 - learning_rate: 0.0025\n",
      "Epoch 654/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.3032 - val_accuracy: 0.8907 - val_loss: 1.6948 - learning_rate: 0.0025\n",
      "Epoch 655/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.3103 - val_accuracy: 0.8773 - val_loss: 1.7064 - learning_rate: 0.0025\n",
      "Epoch 656/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9047 - loss: 0.3067 - val_accuracy: 0.8893 - val_loss: 1.7213 - learning_rate: 0.0025\n",
      "Epoch 657/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8937 - loss: 0.3310 - val_accuracy: 0.8920 - val_loss: 1.7107 - learning_rate: 0.0025\n",
      "Epoch 658/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9076 - loss: 0.3171 - val_accuracy: 0.8747 - val_loss: 1.7200 - learning_rate: 0.0025\n",
      "Epoch 659/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.3068 - val_accuracy: 0.8893 - val_loss: 1.7192 - learning_rate: 0.0025\n",
      "Epoch 660/5000\n",
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9038 - loss: 0.3233  \n",
      "Epoch 660: ReduceLROnPlateau reducing learning rate to 0.0022876791190356016.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.3230 - val_accuracy: 0.8887 - val_loss: 1.7374 - learning_rate: 0.0025\n",
      "Epoch 661/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.3092 - val_accuracy: 0.8907 - val_loss: 1.7293 - learning_rate: 0.0023\n",
      "Epoch 662/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9046 - loss: 0.3096 - val_accuracy: 0.8907 - val_loss: 1.7382 - learning_rate: 0.0023\n",
      "Epoch 663/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.3021 - val_accuracy: 0.8800 - val_loss: 1.7467 - learning_rate: 0.0023\n",
      "Epoch 664/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8998 - loss: 0.3223 - val_accuracy: 0.8893 - val_loss: 1.7207 - learning_rate: 0.0023\n",
      "Epoch 665/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.3141 - val_accuracy: 0.8840 - val_loss: 1.7381 - learning_rate: 0.0023\n",
      "Epoch 666/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9015 - loss: 0.3183 - val_accuracy: 0.8933 - val_loss: 1.7289 - learning_rate: 0.0023\n",
      "Epoch 667/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.3025 - val_accuracy: 0.8907 - val_loss: 1.7382 - learning_rate: 0.0023\n",
      "Epoch 668/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.3041 - val_accuracy: 0.8907 - val_loss: 1.7412 - learning_rate: 0.0023\n",
      "Epoch 669/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.3046 - val_accuracy: 0.8820 - val_loss: 1.7439 - learning_rate: 0.0023\n",
      "Epoch 670/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.3115 - val_accuracy: 0.8873 - val_loss: 1.7458 - learning_rate: 0.0023\n",
      "Epoch 671/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9037 - loss: 0.3103 - val_accuracy: 0.8873 - val_loss: 1.7512 - learning_rate: 0.0023\n",
      "Epoch 672/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9013 - loss: 0.3142 - val_accuracy: 0.8900 - val_loss: 1.7380 - learning_rate: 0.0023\n",
      "Epoch 673/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.3161 - val_accuracy: 0.8847 - val_loss: 1.7569 - learning_rate: 0.0023\n",
      "Epoch 674/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9037 - loss: 0.3148 - val_accuracy: 0.8900 - val_loss: 1.7573 - learning_rate: 0.0023\n",
      "Epoch 675/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8972 - loss: 0.3291 - val_accuracy: 0.8927 - val_loss: 1.7528 - learning_rate: 0.0023\n",
      "Epoch 676/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.3012 - val_accuracy: 0.8913 - val_loss: 1.7545 - learning_rate: 0.0023\n",
      "Epoch 677/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9020 - loss: 0.3119 - val_accuracy: 0.8900 - val_loss: 1.7676 - learning_rate: 0.0023\n",
      "Epoch 678/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9012 - loss: 0.3251 - val_accuracy: 0.8900 - val_loss: 1.7551 - learning_rate: 0.0023\n",
      "Epoch 679/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9036 - loss: 0.3114 - val_accuracy: 0.8880 - val_loss: 1.7743 - learning_rate: 0.0023\n",
      "Epoch 680/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.3095 - val_accuracy: 0.8887 - val_loss: 1.7710 - learning_rate: 0.0023\n",
      "Epoch 681/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9042 - loss: 0.3115 - val_accuracy: 0.8880 - val_loss: 1.7647 - learning_rate: 0.0023\n",
      "Epoch 682/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2912 - val_accuracy: 0.8833 - val_loss: 1.7733 - learning_rate: 0.0023\n",
      "Epoch 683/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9035 - loss: 0.3146 - val_accuracy: 0.8907 - val_loss: 1.7694 - learning_rate: 0.0023\n",
      "Epoch 684/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.3111 - val_accuracy: 0.8920 - val_loss: 1.7703 - learning_rate: 0.0023\n",
      "Epoch 685/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9059 - loss: 0.3035 - val_accuracy: 0.8847 - val_loss: 1.7671 - learning_rate: 0.0023\n",
      "Epoch 686/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.3011 - val_accuracy: 0.8900 - val_loss: 1.7774 - learning_rate: 0.0023\n",
      "Epoch 687/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9033 - loss: 0.3167 - val_accuracy: 0.8893 - val_loss: 1.7780 - learning_rate: 0.0023\n",
      "Epoch 688/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3054 - val_accuracy: 0.8893 - val_loss: 1.7827 - learning_rate: 0.0023\n",
      "Epoch 689/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.3000 - val_accuracy: 0.8867 - val_loss: 1.7721 - learning_rate: 0.0023\n",
      "Epoch 690/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9009 - loss: 0.3148 - val_accuracy: 0.8887 - val_loss: 1.7940 - learning_rate: 0.0023\n",
      "Epoch 691/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3308 - val_accuracy: 0.8893 - val_loss: 1.7874 - learning_rate: 0.0023\n",
      "Epoch 692/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9025 - loss: 0.3177 - val_accuracy: 0.8893 - val_loss: 1.7814 - learning_rate: 0.0023\n",
      "Epoch 693/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.3126 - val_accuracy: 0.8873 - val_loss: 1.7883 - learning_rate: 0.0023\n",
      "Epoch 694/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.3062 - val_accuracy: 0.8787 - val_loss: 1.7973 - learning_rate: 0.0023\n",
      "Epoch 695/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8999 - loss: 0.3119 - val_accuracy: 0.8913 - val_loss: 1.7850 - learning_rate: 0.0023\n",
      "Epoch 696/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.3043 - val_accuracy: 0.8893 - val_loss: 1.8014 - learning_rate: 0.0023\n",
      "Epoch 697/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.3068 - val_accuracy: 0.8927 - val_loss: 1.7884 - learning_rate: 0.0023\n",
      "Epoch 698/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2978 - val_accuracy: 0.8873 - val_loss: 1.7854 - learning_rate: 0.0023\n",
      "Epoch 699/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.3154 - val_accuracy: 0.8887 - val_loss: 1.7895 - learning_rate: 0.0023\n",
      "Epoch 700/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2640 \n",
      "Epoch 700: ReduceLROnPlateau reducing learning rate to 0.0020589112071320416.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2936 - val_accuracy: 0.8913 - val_loss: 1.7967 - learning_rate: 0.0023\n",
      "Epoch 701/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9052 - loss: 0.3094 - val_accuracy: 0.8920 - val_loss: 1.8038 - learning_rate: 0.0021\n",
      "Epoch 702/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.3070 - val_accuracy: 0.8927 - val_loss: 1.7974 - learning_rate: 0.0021\n",
      "Epoch 703/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2989 - val_accuracy: 0.8893 - val_loss: 1.7799 - learning_rate: 0.0021\n",
      "Epoch 704/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.3039 - val_accuracy: 0.8880 - val_loss: 1.7887 - learning_rate: 0.0021\n",
      "Epoch 705/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.3034 - val_accuracy: 0.8927 - val_loss: 1.7959 - learning_rate: 0.0021\n",
      "Epoch 706/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.3245 - val_accuracy: 0.8873 - val_loss: 1.8098 - learning_rate: 0.0021\n",
      "Epoch 707/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9069 - loss: 0.3146 - val_accuracy: 0.8933 - val_loss: 1.7990 - learning_rate: 0.0021\n",
      "Epoch 708/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9043 - loss: 0.3051 - val_accuracy: 0.8907 - val_loss: 1.8085 - learning_rate: 0.0021\n",
      "Epoch 709/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.3083 - val_accuracy: 0.8900 - val_loss: 1.8044 - learning_rate: 0.0021\n",
      "Epoch 710/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9029 - loss: 0.3195 - val_accuracy: 0.8893 - val_loss: 1.8120 - learning_rate: 0.0021\n",
      "Epoch 711/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2978 - val_accuracy: 0.8887 - val_loss: 1.8109 - learning_rate: 0.0021\n",
      "Epoch 712/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9014 - loss: 0.3159 - val_accuracy: 0.8820 - val_loss: 1.8227 - learning_rate: 0.0021\n",
      "Epoch 713/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.3165 - val_accuracy: 0.8887 - val_loss: 1.8125 - learning_rate: 0.0021\n",
      "Epoch 714/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9030 - loss: 0.3222 - val_accuracy: 0.8827 - val_loss: 1.8201 - learning_rate: 0.0021\n",
      "Epoch 715/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9034 - loss: 0.3181 - val_accuracy: 0.8887 - val_loss: 1.8401 - learning_rate: 0.0021\n",
      "Epoch 716/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8979 - loss: 0.3242 - val_accuracy: 0.8860 - val_loss: 1.8178 - learning_rate: 0.0021\n",
      "Epoch 717/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.3084 - val_accuracy: 0.8880 - val_loss: 1.8092 - learning_rate: 0.0021\n",
      "Epoch 718/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.3099 - val_accuracy: 0.8853 - val_loss: 1.8119 - learning_rate: 0.0021\n",
      "Epoch 719/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.3022 - val_accuracy: 0.8907 - val_loss: 1.8246 - learning_rate: 0.0021\n",
      "Epoch 720/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8960 - loss: 0.3271 - val_accuracy: 0.8913 - val_loss: 1.8132 - learning_rate: 0.0021\n",
      "Epoch 721/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9019 - loss: 0.3147 - val_accuracy: 0.8920 - val_loss: 1.8125 - learning_rate: 0.0021\n",
      "Epoch 722/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.3021 - val_accuracy: 0.8940 - val_loss: 1.8090 - learning_rate: 0.0021\n",
      "Epoch 723/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.3091 - val_accuracy: 0.8887 - val_loss: 1.8166 - learning_rate: 0.0021\n",
      "Epoch 724/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2935 - val_accuracy: 0.8927 - val_loss: 1.8065 - learning_rate: 0.0021\n",
      "Epoch 725/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.3007 - val_accuracy: 0.8940 - val_loss: 1.8217 - learning_rate: 0.0021\n",
      "Epoch 726/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.3062 - val_accuracy: 0.8907 - val_loss: 1.7967 - learning_rate: 0.0021\n",
      "Epoch 727/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.3161 - val_accuracy: 0.8913 - val_loss: 1.8066 - learning_rate: 0.0021\n",
      "Epoch 728/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.3077 - val_accuracy: 0.8913 - val_loss: 1.8096 - learning_rate: 0.0021\n",
      "Epoch 729/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9060 - loss: 0.3105 - val_accuracy: 0.8780 - val_loss: 1.8095 - learning_rate: 0.0021\n",
      "Epoch 730/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8980 - loss: 0.3223 - val_accuracy: 0.8873 - val_loss: 1.8162 - learning_rate: 0.0021\n",
      "Epoch 731/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.3105 - val_accuracy: 0.8873 - val_loss: 1.8194 - learning_rate: 0.0021\n",
      "Epoch 732/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9056 - loss: 0.3104 - val_accuracy: 0.8887 - val_loss: 1.8181 - learning_rate: 0.0021\n",
      "Epoch 733/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.3100 - val_accuracy: 0.8927 - val_loss: 1.8142 - learning_rate: 0.0021\n",
      "Epoch 734/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.3103 - val_accuracy: 0.8927 - val_loss: 1.8189 - learning_rate: 0.0021\n",
      "Epoch 735/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.3137 - val_accuracy: 0.8820 - val_loss: 1.8250 - learning_rate: 0.0021\n",
      "Epoch 736/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9032 - loss: 0.3088 - val_accuracy: 0.8893 - val_loss: 1.8230 - learning_rate: 0.0021\n",
      "Epoch 737/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9043 - loss: 0.3105 - val_accuracy: 0.8853 - val_loss: 1.8255 - learning_rate: 0.0021\n",
      "Epoch 738/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.3043 - val_accuracy: 0.8873 - val_loss: 1.8287 - learning_rate: 0.0021\n",
      "Epoch 739/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.3079 - val_accuracy: 0.8873 - val_loss: 1.8253 - learning_rate: 0.0021\n",
      "Epoch 740/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9008 - loss: 0.3331\n",
      "Epoch 740: ReduceLROnPlateau reducing learning rate to 0.0018530200235545636.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.3110 - val_accuracy: 0.8927 - val_loss: 1.8257 - learning_rate: 0.0021\n",
      "Epoch 741/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9026 - loss: 0.3188 - val_accuracy: 0.8853 - val_loss: 1.8297 - learning_rate: 0.0019\n",
      "Epoch 742/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8997 - loss: 0.3162 - val_accuracy: 0.8900 - val_loss: 1.8322 - learning_rate: 0.0019\n",
      "Epoch 743/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.3102 - val_accuracy: 0.8920 - val_loss: 1.8321 - learning_rate: 0.0019\n",
      "Epoch 744/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.3021 - val_accuracy: 0.8927 - val_loss: 1.8298 - learning_rate: 0.0019\n",
      "Epoch 745/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2925 - val_accuracy: 0.8920 - val_loss: 1.8215 - learning_rate: 0.0019\n",
      "Epoch 746/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.3026 - val_accuracy: 0.8927 - val_loss: 1.8328 - learning_rate: 0.0019\n",
      "Epoch 747/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.3088 - val_accuracy: 0.8847 - val_loss: 1.8318 - learning_rate: 0.0019\n",
      "Epoch 748/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2973 - val_accuracy: 0.8853 - val_loss: 1.8358 - learning_rate: 0.0019\n",
      "Epoch 749/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2978 - val_accuracy: 0.8887 - val_loss: 1.8327 - learning_rate: 0.0019\n",
      "Epoch 750/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2992 - val_accuracy: 0.8907 - val_loss: 1.8391 - learning_rate: 0.0019\n",
      "Epoch 751/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.3022 - val_accuracy: 0.8893 - val_loss: 1.8301 - learning_rate: 0.0019\n",
      "Epoch 752/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9030 - loss: 0.3112 - val_accuracy: 0.8913 - val_loss: 1.8267 - learning_rate: 0.0019\n",
      "Epoch 753/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9040 - loss: 0.3167 - val_accuracy: 0.8893 - val_loss: 1.8419 - learning_rate: 0.0019\n",
      "Epoch 754/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.3055 - val_accuracy: 0.8873 - val_loss: 1.8479 - learning_rate: 0.0019\n",
      "Epoch 755/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2923 - val_accuracy: 0.8907 - val_loss: 1.8499 - learning_rate: 0.0019\n",
      "Epoch 756/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2890 - val_accuracy: 0.8847 - val_loss: 1.8402 - learning_rate: 0.0019\n",
      "Epoch 757/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.3089 - val_accuracy: 0.8913 - val_loss: 1.8385 - learning_rate: 0.0019\n",
      "Epoch 758/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2949 - val_accuracy: 0.8953 - val_loss: 1.8352 - learning_rate: 0.0019\n",
      "Epoch 759/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.3082 - val_accuracy: 0.8907 - val_loss: 1.8405 - learning_rate: 0.0019\n",
      "Epoch 760/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.3026 - val_accuracy: 0.8913 - val_loss: 1.8274 - learning_rate: 0.0019\n",
      "Epoch 761/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9031 - loss: 0.3230 - val_accuracy: 0.8927 - val_loss: 1.8473 - learning_rate: 0.0019\n",
      "Epoch 762/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.3046 - val_accuracy: 0.8893 - val_loss: 1.8408 - learning_rate: 0.0019\n",
      "Epoch 763/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2974 - val_accuracy: 0.8940 - val_loss: 1.8396 - learning_rate: 0.0019\n",
      "Epoch 764/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.3043 - val_accuracy: 0.8927 - val_loss: 1.8533 - learning_rate: 0.0019\n",
      "Epoch 765/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.3110 - val_accuracy: 0.8913 - val_loss: 1.8465 - learning_rate: 0.0019\n",
      "Epoch 766/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.3032 - val_accuracy: 0.8827 - val_loss: 1.8411 - learning_rate: 0.0019\n",
      "Epoch 767/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2970 - val_accuracy: 0.8860 - val_loss: 1.8451 - learning_rate: 0.0019\n",
      "Epoch 768/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2898 - val_accuracy: 0.8927 - val_loss: 1.8552 - learning_rate: 0.0019\n",
      "Epoch 769/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.3048 - val_accuracy: 0.8887 - val_loss: 1.8529 - learning_rate: 0.0019\n",
      "Epoch 770/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9035 - loss: 0.3118 - val_accuracy: 0.8927 - val_loss: 1.8534 - learning_rate: 0.0019\n",
      "Epoch 771/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.3048 - val_accuracy: 0.8867 - val_loss: 1.8521 - learning_rate: 0.0019\n",
      "Epoch 772/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.3063 - val_accuracy: 0.8960 - val_loss: 1.8505 - learning_rate: 0.0019\n",
      "Epoch 773/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3039 - val_accuracy: 0.8967 - val_loss: 1.8556 - learning_rate: 0.0019\n",
      "Epoch 774/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.3089 - val_accuracy: 0.8927 - val_loss: 1.8557 - learning_rate: 0.0019\n",
      "Epoch 775/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8990 - loss: 0.3156 - val_accuracy: 0.8927 - val_loss: 1.8734 - learning_rate: 0.0019\n",
      "Epoch 776/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.3030 - val_accuracy: 0.8927 - val_loss: 1.8726 - learning_rate: 0.0019\n",
      "Epoch 777/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.3125 - val_accuracy: 0.8920 - val_loss: 1.8717 - learning_rate: 0.0019\n",
      "Epoch 778/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9045 - loss: 0.3119 - val_accuracy: 0.8920 - val_loss: 1.8645 - learning_rate: 0.0019\n",
      "Epoch 779/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2977 - val_accuracy: 0.8913 - val_loss: 1.8582 - learning_rate: 0.0019\n",
      "Epoch 780/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9092 - loss: 0.2876 \n",
      "Epoch 780: ReduceLROnPlateau reducing learning rate to 0.0016677180421538651.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.3008 - val_accuracy: 0.8900 - val_loss: 1.8704 - learning_rate: 0.0019\n",
      "Epoch 781/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9001 - loss: 0.3207 - val_accuracy: 0.8947 - val_loss: 1.8624 - learning_rate: 0.0017\n",
      "Epoch 782/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.3126 - val_accuracy: 0.8907 - val_loss: 1.8593 - learning_rate: 0.0017\n",
      "Epoch 783/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.3067 - val_accuracy: 0.8933 - val_loss: 1.8621 - learning_rate: 0.0017\n",
      "Epoch 784/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2972 - val_accuracy: 0.8920 - val_loss: 1.8650 - learning_rate: 0.0017\n",
      "Epoch 785/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.3093 - val_accuracy: 0.8933 - val_loss: 1.8567 - learning_rate: 0.0017\n",
      "Epoch 786/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2894 - val_accuracy: 0.8933 - val_loss: 1.8574 - learning_rate: 0.0017\n",
      "Epoch 787/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2997 - val_accuracy: 0.8887 - val_loss: 1.8645 - learning_rate: 0.0017\n",
      "Epoch 788/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.3032 - val_accuracy: 0.8940 - val_loss: 1.8618 - learning_rate: 0.0017\n",
      "Epoch 789/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.3033 - val_accuracy: 0.8927 - val_loss: 1.8603 - learning_rate: 0.0017\n",
      "Epoch 790/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2997 - val_accuracy: 0.8887 - val_loss: 1.8657 - learning_rate: 0.0017\n",
      "Epoch 791/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2968 - val_accuracy: 0.8920 - val_loss: 1.8684 - learning_rate: 0.0017\n",
      "Epoch 792/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.3022 - val_accuracy: 0.8933 - val_loss: 1.8613 - learning_rate: 0.0017\n",
      "Epoch 793/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2911 - val_accuracy: 0.8880 - val_loss: 1.8756 - learning_rate: 0.0017\n",
      "Epoch 794/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2864 - val_accuracy: 0.8920 - val_loss: 1.8782 - learning_rate: 0.0017\n",
      "Epoch 795/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2957 - val_accuracy: 0.8920 - val_loss: 1.8763 - learning_rate: 0.0017\n",
      "Epoch 796/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2949 - val_accuracy: 0.8947 - val_loss: 1.8690 - learning_rate: 0.0017\n",
      "Epoch 797/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9009 - loss: 0.3124 - val_accuracy: 0.8900 - val_loss: 1.8757 - learning_rate: 0.0017\n",
      "Epoch 798/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2979 - val_accuracy: 0.8947 - val_loss: 1.8752 - learning_rate: 0.0017\n",
      "Epoch 799/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2994 - val_accuracy: 0.8893 - val_loss: 1.8801 - learning_rate: 0.0017\n",
      "Epoch 800/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9003 - loss: 0.3150 - val_accuracy: 0.8927 - val_loss: 1.8815 - learning_rate: 0.0017\n",
      "Epoch 801/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2941 - val_accuracy: 0.8887 - val_loss: 1.8832 - learning_rate: 0.0017\n",
      "Epoch 802/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2928 - val_accuracy: 0.8940 - val_loss: 1.8934 - learning_rate: 0.0017\n",
      "Epoch 803/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2984 - val_accuracy: 0.8933 - val_loss: 1.8833 - learning_rate: 0.0017\n",
      "Epoch 804/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.3128 - val_accuracy: 0.8887 - val_loss: 1.8914 - learning_rate: 0.0017\n",
      "Epoch 805/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.3108 - val_accuracy: 0.8933 - val_loss: 1.8980 - learning_rate: 0.0017\n",
      "Epoch 806/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2977 - val_accuracy: 0.8887 - val_loss: 1.8975 - learning_rate: 0.0017\n",
      "Epoch 807/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.3104 - val_accuracy: 0.8913 - val_loss: 1.9023 - learning_rate: 0.0017\n",
      "Epoch 808/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9093 - loss: 0.3059 - val_accuracy: 0.8913 - val_loss: 1.8950 - learning_rate: 0.0017\n",
      "Epoch 809/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2887 - val_accuracy: 0.8873 - val_loss: 1.9002 - learning_rate: 0.0017\n",
      "Epoch 810/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2996 - val_accuracy: 0.8867 - val_loss: 1.8899 - learning_rate: 0.0017\n",
      "Epoch 811/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.3079 - val_accuracy: 0.8960 - val_loss: 1.8929 - learning_rate: 0.0017\n",
      "Epoch 812/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2955 - val_accuracy: 0.8933 - val_loss: 1.8951 - learning_rate: 0.0017\n",
      "Epoch 813/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.3075 - val_accuracy: 0.8920 - val_loss: 1.8897 - learning_rate: 0.0017\n",
      "Epoch 814/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9103 - loss: 0.2881 - val_accuracy: 0.8927 - val_loss: 1.8927 - learning_rate: 0.0017\n",
      "Epoch 815/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2978 - val_accuracy: 0.8927 - val_loss: 1.8984 - learning_rate: 0.0017\n",
      "Epoch 816/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.3011 - val_accuracy: 0.8933 - val_loss: 1.8936 - learning_rate: 0.0017\n",
      "Epoch 817/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2806 - val_accuracy: 0.8913 - val_loss: 1.8985 - learning_rate: 0.0017\n",
      "Epoch 818/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.3095 - val_accuracy: 0.8920 - val_loss: 1.8961 - learning_rate: 0.0017\n",
      "Epoch 819/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2999 - val_accuracy: 0.8807 - val_loss: 1.8963 - learning_rate: 0.0017\n",
      "Epoch 820/5000\n",
      "\u001b[1m 5/24\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2870 \n",
      "Epoch 820: ReduceLROnPlateau reducing learning rate to 0.0015009462484158575.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2947 - val_accuracy: 0.8967 - val_loss: 1.8976 - learning_rate: 0.0017\n",
      "Epoch 821/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9071 - loss: 0.3012 - val_accuracy: 0.8947 - val_loss: 1.9000 - learning_rate: 0.0015\n",
      "Epoch 822/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.3057 - val_accuracy: 0.8907 - val_loss: 1.8962 - learning_rate: 0.0015\n",
      "Epoch 823/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2942 - val_accuracy: 0.8927 - val_loss: 1.8996 - learning_rate: 0.0015\n",
      "Epoch 824/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2867 - val_accuracy: 0.8940 - val_loss: 1.8913 - learning_rate: 0.0015\n",
      "Epoch 825/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2989 - val_accuracy: 0.8967 - val_loss: 1.8941 - learning_rate: 0.0015\n",
      "Epoch 826/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.3076 - val_accuracy: 0.8940 - val_loss: 1.8942 - learning_rate: 0.0015\n",
      "Epoch 827/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9115 - loss: 0.3022 - val_accuracy: 0.8927 - val_loss: 1.8962 - learning_rate: 0.0015\n",
      "Epoch 828/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9096 - loss: 0.3050 - val_accuracy: 0.8907 - val_loss: 1.8999 - learning_rate: 0.0015\n",
      "Epoch 829/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.3007 - val_accuracy: 0.8927 - val_loss: 1.9064 - learning_rate: 0.0015\n",
      "Epoch 830/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.3023 - val_accuracy: 0.8953 - val_loss: 1.8998 - learning_rate: 0.0015\n",
      "Epoch 831/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2999 - val_accuracy: 0.8873 - val_loss: 1.9123 - learning_rate: 0.0015\n",
      "Epoch 832/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.3022 - val_accuracy: 0.8933 - val_loss: 1.9115 - learning_rate: 0.0015\n",
      "Epoch 833/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9058 - loss: 0.3055 - val_accuracy: 0.8920 - val_loss: 1.9051 - learning_rate: 0.0015\n",
      "Epoch 834/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2997 - val_accuracy: 0.8947 - val_loss: 1.9063 - learning_rate: 0.0015\n",
      "Epoch 835/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.3011 - val_accuracy: 0.8940 - val_loss: 1.8931 - learning_rate: 0.0015\n",
      "Epoch 836/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.3023 - val_accuracy: 0.8967 - val_loss: 1.9062 - learning_rate: 0.0015\n",
      "Epoch 837/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9041 - loss: 0.3162 - val_accuracy: 0.8913 - val_loss: 1.8977 - learning_rate: 0.0015\n",
      "Epoch 838/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2938 - val_accuracy: 0.8900 - val_loss: 1.9059 - learning_rate: 0.0015\n",
      "Epoch 839/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9080 - loss: 0.3033 - val_accuracy: 0.8947 - val_loss: 1.9090 - learning_rate: 0.0015\n",
      "Epoch 840/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2973 - val_accuracy: 0.8893 - val_loss: 1.8998 - learning_rate: 0.0015\n",
      "Epoch 841/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2896 - val_accuracy: 0.8913 - val_loss: 1.9001 - learning_rate: 0.0015\n",
      "Epoch 842/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.3086 - val_accuracy: 0.8940 - val_loss: 1.9080 - learning_rate: 0.0015\n",
      "Epoch 843/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.3015 - val_accuracy: 0.8880 - val_loss: 1.8996 - learning_rate: 0.0015\n",
      "Epoch 844/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2919 - val_accuracy: 0.8920 - val_loss: 1.9100 - learning_rate: 0.0015\n",
      "Epoch 845/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.3043 - val_accuracy: 0.8953 - val_loss: 1.9040 - learning_rate: 0.0015\n",
      "Epoch 846/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3161 - val_accuracy: 0.8907 - val_loss: 1.9118 - learning_rate: 0.0015\n",
      "Epoch 847/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2963 - val_accuracy: 0.8927 - val_loss: 1.9051 - learning_rate: 0.0015\n",
      "Epoch 848/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.3010 - val_accuracy: 0.8953 - val_loss: 1.9112 - learning_rate: 0.0015\n",
      "Epoch 849/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.3033 - val_accuracy: 0.8927 - val_loss: 1.9058 - learning_rate: 0.0015\n",
      "Epoch 850/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2821 - val_accuracy: 0.8913 - val_loss: 1.9144 - learning_rate: 0.0015\n",
      "Epoch 851/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2746 - val_accuracy: 0.8913 - val_loss: 1.9092 - learning_rate: 0.0015\n",
      "Epoch 852/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9124 - loss: 0.2943 - val_accuracy: 0.8907 - val_loss: 1.9147 - learning_rate: 0.0015\n",
      "Epoch 853/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9082 - loss: 0.3121 - val_accuracy: 0.8920 - val_loss: 1.9101 - learning_rate: 0.0015\n",
      "Epoch 854/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2907 - val_accuracy: 0.8820 - val_loss: 1.9138 - learning_rate: 0.0015\n",
      "Epoch 855/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.2981 - val_accuracy: 0.8893 - val_loss: 1.9037 - learning_rate: 0.0015\n",
      "Epoch 856/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9040 - loss: 0.3170 - val_accuracy: 0.8907 - val_loss: 1.9121 - learning_rate: 0.0015\n",
      "Epoch 857/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9064 - loss: 0.3133 - val_accuracy: 0.8913 - val_loss: 1.9131 - learning_rate: 0.0015\n",
      "Epoch 858/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9042 - loss: 0.3111 - val_accuracy: 0.8900 - val_loss: 1.9167 - learning_rate: 0.0015\n",
      "Epoch 859/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2981 - val_accuracy: 0.8947 - val_loss: 1.9172 - learning_rate: 0.0015\n",
      "Epoch 860/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9017 - loss: 0.3011 \n",
      "Epoch 860: ReduceLROnPlateau reducing learning rate to 0.0013508516130968928.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2956 - val_accuracy: 0.8887 - val_loss: 1.9246 - learning_rate: 0.0015\n",
      "Epoch 861/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2989 - val_accuracy: 0.8900 - val_loss: 1.9202 - learning_rate: 0.0014\n",
      "Epoch 862/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9067 - loss: 0.2977 - val_accuracy: 0.8960 - val_loss: 1.9088 - learning_rate: 0.0014\n",
      "Epoch 863/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.3040 - val_accuracy: 0.8913 - val_loss: 1.9145 - learning_rate: 0.0014\n",
      "Epoch 864/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9043 - loss: 0.3029 - val_accuracy: 0.8927 - val_loss: 1.9217 - learning_rate: 0.0014\n",
      "Epoch 865/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2914 - val_accuracy: 0.8900 - val_loss: 1.9139 - learning_rate: 0.0014\n",
      "Epoch 866/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.3006 - val_accuracy: 0.8927 - val_loss: 1.9094 - learning_rate: 0.0014\n",
      "Epoch 867/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9073 - loss: 0.3077 - val_accuracy: 0.8953 - val_loss: 1.9104 - learning_rate: 0.0014\n",
      "Epoch 868/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2954 - val_accuracy: 0.8913 - val_loss: 1.9078 - learning_rate: 0.0014\n",
      "Epoch 869/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2966 - val_accuracy: 0.8933 - val_loss: 1.9093 - learning_rate: 0.0014\n",
      "Epoch 870/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2914 - val_accuracy: 0.8900 - val_loss: 1.9157 - learning_rate: 0.0014\n",
      "Epoch 871/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2961 - val_accuracy: 0.8920 - val_loss: 1.9188 - learning_rate: 0.0014\n",
      "Epoch 872/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2958 - val_accuracy: 0.8933 - val_loss: 1.9120 - learning_rate: 0.0014\n",
      "Epoch 873/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.3034 - val_accuracy: 0.8900 - val_loss: 1.9175 - learning_rate: 0.0014\n",
      "Epoch 874/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.3097 - val_accuracy: 0.8947 - val_loss: 1.9210 - learning_rate: 0.0014\n",
      "Epoch 875/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9084 - loss: 0.3070 - val_accuracy: 0.8920 - val_loss: 1.9037 - learning_rate: 0.0014\n",
      "Epoch 876/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2854 - val_accuracy: 0.8927 - val_loss: 1.9135 - learning_rate: 0.0014\n",
      "Epoch 877/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.3048 - val_accuracy: 0.8907 - val_loss: 1.9105 - learning_rate: 0.0014\n",
      "Epoch 878/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.3063 - val_accuracy: 0.8913 - val_loss: 1.9154 - learning_rate: 0.0014\n",
      "Epoch 879/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2867 - val_accuracy: 0.8933 - val_loss: 1.9184 - learning_rate: 0.0014\n",
      "Epoch 880/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.3061 - val_accuracy: 0.8920 - val_loss: 1.9238 - learning_rate: 0.0014\n",
      "Epoch 881/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.3103 - val_accuracy: 0.8927 - val_loss: 1.9193 - learning_rate: 0.0014\n",
      "Epoch 882/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2954 - val_accuracy: 0.8947 - val_loss: 1.9142 - learning_rate: 0.0014\n",
      "Epoch 883/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.3002 - val_accuracy: 0.8913 - val_loss: 1.9220 - learning_rate: 0.0014\n",
      "Epoch 884/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2963 - val_accuracy: 0.8933 - val_loss: 1.9174 - learning_rate: 0.0014\n",
      "Epoch 885/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.3078 - val_accuracy: 0.8927 - val_loss: 1.9219 - learning_rate: 0.0014\n",
      "Epoch 886/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2858 - val_accuracy: 0.8913 - val_loss: 1.9282 - learning_rate: 0.0014\n",
      "Epoch 887/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2922 - val_accuracy: 0.8920 - val_loss: 1.9265 - learning_rate: 0.0014\n",
      "Epoch 888/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2865 - val_accuracy: 0.8927 - val_loss: 1.9290 - learning_rate: 0.0014\n",
      "Epoch 889/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.3059 - val_accuracy: 0.8967 - val_loss: 1.9275 - learning_rate: 0.0014\n",
      "Epoch 890/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.3014 - val_accuracy: 0.8893 - val_loss: 1.9263 - learning_rate: 0.0014\n",
      "Epoch 891/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9039 - loss: 0.3132 - val_accuracy: 0.8900 - val_loss: 1.9349 - learning_rate: 0.0014\n",
      "Epoch 892/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.3042 - val_accuracy: 0.8953 - val_loss: 1.9314 - learning_rate: 0.0014\n",
      "Epoch 893/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2886 - val_accuracy: 0.8927 - val_loss: 1.9160 - learning_rate: 0.0014\n",
      "Epoch 894/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.3010 - val_accuracy: 0.8920 - val_loss: 1.9163 - learning_rate: 0.0014\n",
      "Epoch 895/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.3045 - val_accuracy: 0.8947 - val_loss: 1.9230 - learning_rate: 0.0014\n",
      "Epoch 896/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2945 - val_accuracy: 0.8887 - val_loss: 1.9252 - learning_rate: 0.0014\n",
      "Epoch 897/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2983 - val_accuracy: 0.8947 - val_loss: 1.9214 - learning_rate: 0.0014\n",
      "Epoch 898/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2898 - val_accuracy: 0.8927 - val_loss: 1.9212 - learning_rate: 0.0014\n",
      "Epoch 899/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2897 - val_accuracy: 0.8900 - val_loss: 1.9288 - learning_rate: 0.0014\n",
      "Epoch 900/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2969 \n",
      "Epoch 900: ReduceLROnPlateau reducing learning rate to 0.0012157664517872036.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.3004 - val_accuracy: 0.8907 - val_loss: 1.9239 - learning_rate: 0.0014\n",
      "Epoch 901/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.3026 - val_accuracy: 0.8940 - val_loss: 1.9253 - learning_rate: 0.0012\n",
      "Epoch 902/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2936 - val_accuracy: 0.8920 - val_loss: 1.9197 - learning_rate: 0.0012\n",
      "Epoch 903/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2948 - val_accuracy: 0.8887 - val_loss: 1.9327 - learning_rate: 0.0012\n",
      "Epoch 904/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2845 - val_accuracy: 0.8913 - val_loss: 1.9269 - learning_rate: 0.0012\n",
      "Epoch 905/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2881 - val_accuracy: 0.8913 - val_loss: 1.9328 - learning_rate: 0.0012\n",
      "Epoch 906/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2859 - val_accuracy: 0.8900 - val_loss: 1.9319 - learning_rate: 0.0012\n",
      "Epoch 907/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9067 - loss: 0.3024 - val_accuracy: 0.8927 - val_loss: 1.9279 - learning_rate: 0.0012\n",
      "Epoch 908/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2965 - val_accuracy: 0.8913 - val_loss: 1.9290 - learning_rate: 0.0012\n",
      "Epoch 909/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2788 - val_accuracy: 0.8893 - val_loss: 1.9384 - learning_rate: 0.0012\n",
      "Epoch 910/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9055 - loss: 0.3029 - val_accuracy: 0.8920 - val_loss: 1.9326 - learning_rate: 0.0012\n",
      "Epoch 911/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9092 - loss: 0.2878 - val_accuracy: 0.8927 - val_loss: 1.9258 - learning_rate: 0.0012\n",
      "Epoch 912/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2930 - val_accuracy: 0.8853 - val_loss: 1.9374 - learning_rate: 0.0012\n",
      "Epoch 913/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.3052 - val_accuracy: 0.8953 - val_loss: 1.9254 - learning_rate: 0.0012\n",
      "Epoch 914/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2863 - val_accuracy: 0.8927 - val_loss: 1.9272 - learning_rate: 0.0012\n",
      "Epoch 915/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2944 - val_accuracy: 0.8920 - val_loss: 1.9305 - learning_rate: 0.0012\n",
      "Epoch 916/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2880 - val_accuracy: 0.8840 - val_loss: 1.9389 - learning_rate: 0.0012\n",
      "Epoch 917/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9024 - loss: 0.3020 - val_accuracy: 0.8900 - val_loss: 1.9302 - learning_rate: 0.0012\n",
      "Epoch 918/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2881 - val_accuracy: 0.8913 - val_loss: 1.9381 - learning_rate: 0.0012\n",
      "Epoch 919/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2887 - val_accuracy: 0.8927 - val_loss: 1.9410 - learning_rate: 0.0012\n",
      "Epoch 920/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2965 - val_accuracy: 0.8893 - val_loss: 1.9282 - learning_rate: 0.0012\n",
      "Epoch 921/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9052 - loss: 0.3127 - val_accuracy: 0.8913 - val_loss: 1.9393 - learning_rate: 0.0012\n",
      "Epoch 922/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9148 - loss: 0.2909 - val_accuracy: 0.8920 - val_loss: 1.9433 - learning_rate: 0.0012\n",
      "Epoch 923/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2924 - val_accuracy: 0.8927 - val_loss: 1.9388 - learning_rate: 0.0012\n",
      "Epoch 924/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9061 - loss: 0.3035 - val_accuracy: 0.8953 - val_loss: 1.9340 - learning_rate: 0.0012\n",
      "Epoch 925/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2941 - val_accuracy: 0.8953 - val_loss: 1.9358 - learning_rate: 0.0012\n",
      "Epoch 926/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2837 - val_accuracy: 0.8927 - val_loss: 1.9394 - learning_rate: 0.0012\n",
      "Epoch 927/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2932 - val_accuracy: 0.8920 - val_loss: 1.9434 - learning_rate: 0.0012\n",
      "Epoch 928/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.2928 - val_accuracy: 0.8940 - val_loss: 1.9338 - learning_rate: 0.0012\n",
      "Epoch 929/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2940 - val_accuracy: 0.8913 - val_loss: 1.9404 - learning_rate: 0.0012\n",
      "Epoch 930/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9051 - loss: 0.3069 - val_accuracy: 0.8900 - val_loss: 1.9388 - learning_rate: 0.0012\n",
      "Epoch 931/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2971 - val_accuracy: 0.8933 - val_loss: 1.9365 - learning_rate: 0.0012\n",
      "Epoch 932/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2908 - val_accuracy: 0.8927 - val_loss: 1.9458 - learning_rate: 0.0012\n",
      "Epoch 933/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.3005 - val_accuracy: 0.8893 - val_loss: 1.9418 - learning_rate: 0.0012\n",
      "Epoch 934/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2929 - val_accuracy: 0.8920 - val_loss: 1.9381 - learning_rate: 0.0012\n",
      "Epoch 935/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2992 - val_accuracy: 0.8900 - val_loss: 1.9391 - learning_rate: 0.0012\n",
      "Epoch 936/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9074 - loss: 0.2958 - val_accuracy: 0.8933 - val_loss: 1.9306 - learning_rate: 0.0012\n",
      "Epoch 937/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2970 - val_accuracy: 0.8973 - val_loss: 1.9463 - learning_rate: 0.0012\n",
      "Epoch 938/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2933 - val_accuracy: 0.8900 - val_loss: 1.9397 - learning_rate: 0.0012\n",
      "Epoch 939/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2912 - val_accuracy: 0.8920 - val_loss: 1.9466 - learning_rate: 0.0012\n",
      "Epoch 940/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 741us/step - accuracy: 0.9200 - loss: 0.2655\n",
      "Epoch 940: ReduceLROnPlateau reducing learning rate to 0.0010941897751763463.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2922 - val_accuracy: 0.8940 - val_loss: 1.9416 - learning_rate: 0.0012\n",
      "Epoch 941/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2861 - val_accuracy: 0.8880 - val_loss: 1.9410 - learning_rate: 0.0011\n",
      "Epoch 942/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2963 - val_accuracy: 0.8893 - val_loss: 1.9411 - learning_rate: 0.0011\n",
      "Epoch 943/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2954 - val_accuracy: 0.8947 - val_loss: 1.9382 - learning_rate: 0.0011\n",
      "Epoch 944/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2965 - val_accuracy: 0.8947 - val_loss: 1.9431 - learning_rate: 0.0011\n",
      "Epoch 945/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2853 - val_accuracy: 0.8933 - val_loss: 1.9404 - learning_rate: 0.0011\n",
      "Epoch 946/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2832 - val_accuracy: 0.8933 - val_loss: 1.9453 - learning_rate: 0.0011\n",
      "Epoch 947/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2888 - val_accuracy: 0.8920 - val_loss: 1.9387 - learning_rate: 0.0011\n",
      "Epoch 948/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2915 - val_accuracy: 0.8913 - val_loss: 1.9428 - learning_rate: 0.0011\n",
      "Epoch 949/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2979 - val_accuracy: 0.8953 - val_loss: 1.9425 - learning_rate: 0.0011\n",
      "Epoch 950/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2920 - val_accuracy: 0.8933 - val_loss: 1.9438 - learning_rate: 0.0011\n",
      "Epoch 951/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.3049 - val_accuracy: 0.8933 - val_loss: 1.9368 - learning_rate: 0.0011\n",
      "Epoch 952/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2855 - val_accuracy: 0.8920 - val_loss: 1.9384 - learning_rate: 0.0011\n",
      "Epoch 953/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2805 - val_accuracy: 0.8927 - val_loss: 1.9416 - learning_rate: 0.0011\n",
      "Epoch 954/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2853 - val_accuracy: 0.8953 - val_loss: 1.9422 - learning_rate: 0.0011\n",
      "Epoch 955/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2844 - val_accuracy: 0.8920 - val_loss: 1.9521 - learning_rate: 0.0011\n",
      "Epoch 956/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2800 - val_accuracy: 0.8920 - val_loss: 1.9456 - learning_rate: 0.0011\n",
      "Epoch 957/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2906 - val_accuracy: 0.8900 - val_loss: 1.9427 - learning_rate: 0.0011\n",
      "Epoch 958/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 1.9480 - learning_rate: 0.0011\n",
      "Epoch 959/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2823 - val_accuracy: 0.8953 - val_loss: 1.9430 - learning_rate: 0.0011\n",
      "Epoch 960/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2935 - val_accuracy: 0.8900 - val_loss: 1.9479 - learning_rate: 0.0011\n",
      "Epoch 961/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9138 - loss: 0.2873 - val_accuracy: 0.8927 - val_loss: 1.9436 - learning_rate: 0.0011\n",
      "Epoch 962/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2920 - val_accuracy: 0.8927 - val_loss: 1.9524 - learning_rate: 0.0011\n",
      "Epoch 963/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2899 - val_accuracy: 0.8927 - val_loss: 1.9513 - learning_rate: 0.0011\n",
      "Epoch 964/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2764 - val_accuracy: 0.8940 - val_loss: 1.9534 - learning_rate: 0.0011\n",
      "Epoch 965/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2832 - val_accuracy: 0.8933 - val_loss: 1.9608 - learning_rate: 0.0011\n",
      "Epoch 966/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2900 - val_accuracy: 0.8947 - val_loss: 1.9543 - learning_rate: 0.0011\n",
      "Epoch 967/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2895 - val_accuracy: 0.8933 - val_loss: 1.9456 - learning_rate: 0.0011\n",
      "Epoch 968/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9089 - loss: 0.2916 - val_accuracy: 0.8933 - val_loss: 1.9531 - learning_rate: 0.0011\n",
      "Epoch 969/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2886 - val_accuracy: 0.8947 - val_loss: 1.9479 - learning_rate: 0.0011\n",
      "Epoch 970/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2938 - val_accuracy: 0.8860 - val_loss: 1.9535 - learning_rate: 0.0011\n",
      "Epoch 971/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2907 - val_accuracy: 0.8933 - val_loss: 1.9491 - learning_rate: 0.0011\n",
      "Epoch 972/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2910 - val_accuracy: 0.8940 - val_loss: 1.9507 - learning_rate: 0.0011\n",
      "Epoch 973/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.2960 - val_accuracy: 0.8933 - val_loss: 1.9508 - learning_rate: 0.0011\n",
      "Epoch 974/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2769 - val_accuracy: 0.8913 - val_loss: 1.9491 - learning_rate: 0.0011\n",
      "Epoch 975/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2903 - val_accuracy: 0.8953 - val_loss: 1.9539 - learning_rate: 0.0011\n",
      "Epoch 976/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2986 - val_accuracy: 0.8947 - val_loss: 1.9488 - learning_rate: 0.0011\n",
      "Epoch 977/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9049 - loss: 0.2997 - val_accuracy: 0.8973 - val_loss: 1.9457 - learning_rate: 0.0011\n",
      "Epoch 978/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.3049 - val_accuracy: 0.8927 - val_loss: 1.9514 - learning_rate: 0.0011\n",
      "Epoch 979/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2847 - val_accuracy: 0.8960 - val_loss: 1.9437 - learning_rate: 0.0011\n",
      "Epoch 980/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8933 - loss: 0.3168 \n",
      "Epoch 980: ReduceLROnPlateau reducing learning rate to 0.0009847708395682275.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2950 - val_accuracy: 0.8967 - val_loss: 1.9528 - learning_rate: 0.0011\n",
      "Epoch 981/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2971 - val_accuracy: 0.8953 - val_loss: 1.9447 - learning_rate: 9.8477e-04\n",
      "Epoch 982/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2961 - val_accuracy: 0.8940 - val_loss: 1.9522 - learning_rate: 9.8477e-04\n",
      "Epoch 983/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2948 - val_accuracy: 0.8920 - val_loss: 1.9479 - learning_rate: 9.8477e-04\n",
      "Epoch 984/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2840 - val_accuracy: 0.8947 - val_loss: 1.9452 - learning_rate: 9.8477e-04\n",
      "Epoch 985/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2880 - val_accuracy: 0.8933 - val_loss: 1.9519 - learning_rate: 9.8477e-04\n",
      "Epoch 986/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9203 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 1.9567 - learning_rate: 9.8477e-04\n",
      "Epoch 987/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2917 - val_accuracy: 0.8960 - val_loss: 1.9573 - learning_rate: 9.8477e-04\n",
      "Epoch 988/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2881 - val_accuracy: 0.8927 - val_loss: 1.9541 - learning_rate: 9.8477e-04\n",
      "Epoch 989/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2829 - val_accuracy: 0.8953 - val_loss: 1.9538 - learning_rate: 9.8477e-04\n",
      "Epoch 990/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2878 - val_accuracy: 0.8953 - val_loss: 1.9568 - learning_rate: 9.8477e-04\n",
      "Epoch 991/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2859 - val_accuracy: 0.8947 - val_loss: 1.9539 - learning_rate: 9.8477e-04\n",
      "Epoch 992/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9054 - loss: 0.2957 - val_accuracy: 0.8960 - val_loss: 1.9587 - learning_rate: 9.8477e-04\n",
      "Epoch 993/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2930 - val_accuracy: 0.8947 - val_loss: 1.9604 - learning_rate: 9.8477e-04\n",
      "Epoch 994/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2931 - val_accuracy: 0.8940 - val_loss: 1.9561 - learning_rate: 9.8477e-04\n",
      "Epoch 995/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2841 - val_accuracy: 0.8940 - val_loss: 1.9561 - learning_rate: 9.8477e-04\n",
      "Epoch 996/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2860 - val_accuracy: 0.8933 - val_loss: 1.9540 - learning_rate: 9.8477e-04\n",
      "Epoch 997/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2847 - val_accuracy: 0.8940 - val_loss: 1.9546 - learning_rate: 9.8477e-04\n",
      "Epoch 998/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2862 - val_accuracy: 0.8980 - val_loss: 1.9599 - learning_rate: 9.8477e-04\n",
      "Epoch 999/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2928 - val_accuracy: 0.8953 - val_loss: 1.9570 - learning_rate: 9.8477e-04\n",
      "Epoch 1000/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2869 - val_accuracy: 0.8920 - val_loss: 1.9583 - learning_rate: 9.8477e-04\n",
      "Epoch 1001/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2986 - val_accuracy: 0.8940 - val_loss: 1.9568 - learning_rate: 9.8477e-04\n",
      "Epoch 1002/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2938 - val_accuracy: 0.8967 - val_loss: 1.9603 - learning_rate: 9.8477e-04\n",
      "Epoch 1003/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.3001 - val_accuracy: 0.8933 - val_loss: 1.9639 - learning_rate: 9.8477e-04\n",
      "Epoch 1004/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2892 - val_accuracy: 0.8940 - val_loss: 1.9638 - learning_rate: 9.8477e-04\n",
      "Epoch 1005/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9063 - loss: 0.2930 - val_accuracy: 0.8960 - val_loss: 1.9638 - learning_rate: 9.8477e-04\n",
      "Epoch 1006/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2879 - val_accuracy: 0.8927 - val_loss: 1.9675 - learning_rate: 9.8477e-04\n",
      "Epoch 1007/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2857 - val_accuracy: 0.8953 - val_loss: 1.9649 - learning_rate: 9.8477e-04\n",
      "Epoch 1008/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2857 - val_accuracy: 0.8927 - val_loss: 1.9729 - learning_rate: 9.8477e-04\n",
      "Epoch 1009/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2890 - val_accuracy: 0.8960 - val_loss: 1.9707 - learning_rate: 9.8477e-04\n",
      "Epoch 1010/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2857 - val_accuracy: 0.8967 - val_loss: 1.9714 - learning_rate: 9.8477e-04\n",
      "Epoch 1011/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2853 - val_accuracy: 0.8947 - val_loss: 1.9683 - learning_rate: 9.8477e-04\n",
      "Epoch 1012/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2840 - val_accuracy: 0.8940 - val_loss: 1.9585 - learning_rate: 9.8477e-04\n",
      "Epoch 1013/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.3024 - val_accuracy: 0.8953 - val_loss: 1.9659 - learning_rate: 9.8477e-04\n",
      "Epoch 1014/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2896 - val_accuracy: 0.8913 - val_loss: 1.9671 - learning_rate: 9.8477e-04\n",
      "Epoch 1015/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2979 - val_accuracy: 0.8947 - val_loss: 1.9703 - learning_rate: 9.8477e-04\n",
      "Epoch 1016/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2966 - val_accuracy: 0.8940 - val_loss: 1.9690 - learning_rate: 9.8477e-04\n",
      "Epoch 1017/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2965 - val_accuracy: 0.8953 - val_loss: 1.9697 - learning_rate: 9.8477e-04\n",
      "Epoch 1018/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.2982 - val_accuracy: 0.8960 - val_loss: 1.9661 - learning_rate: 9.8477e-04\n",
      "Epoch 1019/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2693 - val_accuracy: 0.8927 - val_loss: 1.9734 - learning_rate: 9.8477e-04\n",
      "Epoch 1020/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9242 - loss: 0.2827 \n",
      "Epoch 1020: ReduceLROnPlateau reducing learning rate to 0.0008862937451340258.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2856 - val_accuracy: 0.8940 - val_loss: 1.9724 - learning_rate: 9.8477e-04\n",
      "Epoch 1021/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2813 - val_accuracy: 0.8933 - val_loss: 1.9663 - learning_rate: 8.8629e-04\n",
      "Epoch 1022/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2874 - val_accuracy: 0.8933 - val_loss: 1.9668 - learning_rate: 8.8629e-04\n",
      "Epoch 1023/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2775 - val_accuracy: 0.8960 - val_loss: 1.9651 - learning_rate: 8.8629e-04\n",
      "Epoch 1024/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2996 - val_accuracy: 0.8927 - val_loss: 1.9620 - learning_rate: 8.8629e-04\n",
      "Epoch 1025/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2925 - val_accuracy: 0.8940 - val_loss: 1.9655 - learning_rate: 8.8629e-04\n",
      "Epoch 1026/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2807 - val_accuracy: 0.8933 - val_loss: 1.9702 - learning_rate: 8.8629e-04\n",
      "Epoch 1027/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2874 - val_accuracy: 0.8933 - val_loss: 1.9640 - learning_rate: 8.8629e-04\n",
      "Epoch 1028/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2846 - val_accuracy: 0.8927 - val_loss: 1.9667 - learning_rate: 8.8629e-04\n",
      "Epoch 1029/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2877 - val_accuracy: 0.8920 - val_loss: 1.9716 - learning_rate: 8.8629e-04\n",
      "Epoch 1030/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.2966 - val_accuracy: 0.8940 - val_loss: 1.9720 - learning_rate: 8.8629e-04\n",
      "Epoch 1031/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2857 - val_accuracy: 0.8953 - val_loss: 1.9694 - learning_rate: 8.8629e-04\n",
      "Epoch 1032/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2912 - val_accuracy: 0.8933 - val_loss: 1.9702 - learning_rate: 8.8629e-04\n",
      "Epoch 1033/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2959 - val_accuracy: 0.8933 - val_loss: 1.9685 - learning_rate: 8.8629e-04\n",
      "Epoch 1034/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2867 - val_accuracy: 0.8940 - val_loss: 1.9723 - learning_rate: 8.8629e-04\n",
      "Epoch 1035/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2889 - val_accuracy: 0.8947 - val_loss: 1.9684 - learning_rate: 8.8629e-04\n",
      "Epoch 1036/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2846 - val_accuracy: 0.8940 - val_loss: 1.9673 - learning_rate: 8.8629e-04\n",
      "Epoch 1037/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.2990 - val_accuracy: 0.8940 - val_loss: 1.9736 - learning_rate: 8.8629e-04\n",
      "Epoch 1038/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2914 - val_accuracy: 0.8927 - val_loss: 1.9722 - learning_rate: 8.8629e-04\n",
      "Epoch 1039/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2743 - val_accuracy: 0.8913 - val_loss: 1.9740 - learning_rate: 8.8629e-04\n",
      "Epoch 1040/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2924 - val_accuracy: 0.8947 - val_loss: 1.9694 - learning_rate: 8.8629e-04\n",
      "Epoch 1041/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2855 - val_accuracy: 0.8933 - val_loss: 1.9736 - learning_rate: 8.8629e-04\n",
      "Epoch 1042/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2869 - val_accuracy: 0.8933 - val_loss: 1.9735 - learning_rate: 8.8629e-04\n",
      "Epoch 1043/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2896 - val_accuracy: 0.8953 - val_loss: 1.9773 - learning_rate: 8.8629e-04\n",
      "Epoch 1044/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2936 - val_accuracy: 0.8940 - val_loss: 1.9742 - learning_rate: 8.8629e-04\n",
      "Epoch 1045/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2859 - val_accuracy: 0.8953 - val_loss: 1.9772 - learning_rate: 8.8629e-04\n",
      "Epoch 1046/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2796 - val_accuracy: 0.8927 - val_loss: 1.9839 - learning_rate: 8.8629e-04\n",
      "Epoch 1047/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2748 - val_accuracy: 0.8933 - val_loss: 1.9752 - learning_rate: 8.8629e-04\n",
      "Epoch 1048/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2866 - val_accuracy: 0.8927 - val_loss: 1.9775 - learning_rate: 8.8629e-04\n",
      "Epoch 1049/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2862 - val_accuracy: 0.8927 - val_loss: 1.9788 - learning_rate: 8.8629e-04\n",
      "Epoch 1050/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2893 - val_accuracy: 0.8933 - val_loss: 1.9787 - learning_rate: 8.8629e-04\n",
      "Epoch 1051/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9078 - loss: 0.2952 - val_accuracy: 0.8947 - val_loss: 1.9802 - learning_rate: 8.8629e-04\n",
      "Epoch 1052/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2918 - val_accuracy: 0.8940 - val_loss: 1.9796 - learning_rate: 8.8629e-04\n",
      "Epoch 1053/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9062 - loss: 0.2996 - val_accuracy: 0.8933 - val_loss: 1.9755 - learning_rate: 8.8629e-04\n",
      "Epoch 1054/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2910 - val_accuracy: 0.8933 - val_loss: 1.9805 - learning_rate: 8.8629e-04\n",
      "Epoch 1055/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2950 - val_accuracy: 0.8940 - val_loss: 1.9777 - learning_rate: 8.8629e-04\n",
      "Epoch 1056/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2830 - val_accuracy: 0.8940 - val_loss: 1.9823 - learning_rate: 8.8629e-04\n",
      "Epoch 1057/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2821 - val_accuracy: 0.8933 - val_loss: 1.9753 - learning_rate: 8.8629e-04\n",
      "Epoch 1058/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2883 - val_accuracy: 0.8953 - val_loss: 1.9772 - learning_rate: 8.8629e-04\n",
      "Epoch 1059/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2852 - val_accuracy: 0.8947 - val_loss: 1.9843 - learning_rate: 8.8629e-04\n",
      "Epoch 1060/5000\n",
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2457  \n",
      "Epoch 1060: ReduceLROnPlateau reducing learning rate to 0.0007976643915753812.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2807 - val_accuracy: 0.8967 - val_loss: 1.9763 - learning_rate: 8.8629e-04\n",
      "Epoch 1061/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9073 - loss: 0.2982 - val_accuracy: 0.8933 - val_loss: 1.9792 - learning_rate: 7.9766e-04\n",
      "Epoch 1062/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2886 - val_accuracy: 0.8933 - val_loss: 1.9789 - learning_rate: 7.9766e-04\n",
      "Epoch 1063/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2891 - val_accuracy: 0.8933 - val_loss: 1.9825 - learning_rate: 7.9766e-04\n",
      "Epoch 1064/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2851 - val_accuracy: 0.8933 - val_loss: 1.9789 - learning_rate: 7.9766e-04\n",
      "Epoch 1065/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2905 - val_accuracy: 0.8933 - val_loss: 1.9782 - learning_rate: 7.9766e-04\n",
      "Epoch 1066/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2766 - val_accuracy: 0.8953 - val_loss: 1.9861 - learning_rate: 7.9766e-04\n",
      "Epoch 1067/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2820 - val_accuracy: 0.8927 - val_loss: 1.9831 - learning_rate: 7.9766e-04\n",
      "Epoch 1068/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2838 - val_accuracy: 0.8933 - val_loss: 1.9830 - learning_rate: 7.9766e-04\n",
      "Epoch 1069/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2772 - val_accuracy: 0.8927 - val_loss: 1.9807 - learning_rate: 7.9766e-04\n",
      "Epoch 1070/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 1.9815 - learning_rate: 7.9766e-04\n",
      "Epoch 1071/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2916 - val_accuracy: 0.8927 - val_loss: 1.9871 - learning_rate: 7.9766e-04\n",
      "Epoch 1072/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2786 - val_accuracy: 0.8933 - val_loss: 1.9813 - learning_rate: 7.9766e-04\n",
      "Epoch 1073/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.2961 - val_accuracy: 0.8953 - val_loss: 1.9842 - learning_rate: 7.9766e-04\n",
      "Epoch 1074/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2825 - val_accuracy: 0.8953 - val_loss: 1.9801 - learning_rate: 7.9766e-04\n",
      "Epoch 1075/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2975 - val_accuracy: 0.8947 - val_loss: 1.9802 - learning_rate: 7.9766e-04\n",
      "Epoch 1076/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2744 - val_accuracy: 0.8933 - val_loss: 1.9800 - learning_rate: 7.9766e-04\n",
      "Epoch 1077/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2953 - val_accuracy: 0.8940 - val_loss: 1.9819 - learning_rate: 7.9766e-04\n",
      "Epoch 1078/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2806 - val_accuracy: 0.8940 - val_loss: 1.9797 - learning_rate: 7.9766e-04\n",
      "Epoch 1079/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2796 - val_accuracy: 0.8953 - val_loss: 1.9840 - learning_rate: 7.9766e-04\n",
      "Epoch 1080/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2824 - val_accuracy: 0.8907 - val_loss: 1.9853 - learning_rate: 7.9766e-04\n",
      "Epoch 1081/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2988 - val_accuracy: 0.8953 - val_loss: 1.9812 - learning_rate: 7.9766e-04\n",
      "Epoch 1082/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2839 - val_accuracy: 0.8927 - val_loss: 1.9899 - learning_rate: 7.9766e-04\n",
      "Epoch 1083/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2903 - val_accuracy: 0.8940 - val_loss: 1.9829 - learning_rate: 7.9766e-04\n",
      "Epoch 1084/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2900 - val_accuracy: 0.8927 - val_loss: 1.9834 - learning_rate: 7.9766e-04\n",
      "Epoch 1085/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2968 - val_accuracy: 0.8927 - val_loss: 1.9866 - learning_rate: 7.9766e-04\n",
      "Epoch 1086/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2872 - val_accuracy: 0.8947 - val_loss: 1.9865 - learning_rate: 7.9766e-04\n",
      "Epoch 1087/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2771 - val_accuracy: 0.8940 - val_loss: 1.9910 - learning_rate: 7.9766e-04\n",
      "Epoch 1088/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2982 - val_accuracy: 0.8933 - val_loss: 1.9821 - learning_rate: 7.9766e-04\n",
      "Epoch 1089/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2818 - val_accuracy: 0.8927 - val_loss: 1.9844 - learning_rate: 7.9766e-04\n",
      "Epoch 1090/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2929 - val_accuracy: 0.8933 - val_loss: 1.9827 - learning_rate: 7.9766e-04\n",
      "Epoch 1091/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2870 - val_accuracy: 0.8933 - val_loss: 1.9835 - learning_rate: 7.9766e-04\n",
      "Epoch 1092/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2807 - val_accuracy: 0.8940 - val_loss: 1.9878 - learning_rate: 7.9766e-04\n",
      "Epoch 1093/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2867 - val_accuracy: 0.8940 - val_loss: 1.9864 - learning_rate: 7.9766e-04\n",
      "Epoch 1094/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 1.9847 - learning_rate: 7.9766e-04\n",
      "Epoch 1095/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2782 - val_accuracy: 0.8920 - val_loss: 1.9901 - learning_rate: 7.9766e-04\n",
      "Epoch 1096/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2841 - val_accuracy: 0.8953 - val_loss: 1.9872 - learning_rate: 7.9766e-04\n",
      "Epoch 1097/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 1.9889 - learning_rate: 7.9766e-04\n",
      "Epoch 1098/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2888 - val_accuracy: 0.8947 - val_loss: 1.9853 - learning_rate: 7.9766e-04\n",
      "Epoch 1099/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2952 - val_accuracy: 0.8953 - val_loss: 1.9897 - learning_rate: 7.9766e-04\n",
      "Epoch 1100/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 858us/step - accuracy: 0.9146 - loss: 0.2787\n",
      "Epoch 1100: ReduceLROnPlateau reducing learning rate to 0.0007178979576565325.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2828 - val_accuracy: 0.8907 - val_loss: 1.9900 - learning_rate: 7.9766e-04\n",
      "Epoch 1101/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2845 - val_accuracy: 0.8933 - val_loss: 1.9908 - learning_rate: 7.1790e-04\n",
      "Epoch 1102/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2818 - val_accuracy: 0.8933 - val_loss: 1.9892 - learning_rate: 7.1790e-04\n",
      "Epoch 1103/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2866 - val_accuracy: 0.8940 - val_loss: 1.9849 - learning_rate: 7.1790e-04\n",
      "Epoch 1104/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2854 - val_accuracy: 0.8933 - val_loss: 1.9907 - learning_rate: 7.1790e-04\n",
      "Epoch 1105/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2835 - val_accuracy: 0.8927 - val_loss: 1.9922 - learning_rate: 7.1790e-04\n",
      "Epoch 1106/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 1.9923 - learning_rate: 7.1790e-04\n",
      "Epoch 1107/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2880 - val_accuracy: 0.8940 - val_loss: 1.9871 - learning_rate: 7.1790e-04\n",
      "Epoch 1108/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 1.9905 - learning_rate: 7.1790e-04\n",
      "Epoch 1109/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9092 - loss: 0.2889 - val_accuracy: 0.8940 - val_loss: 1.9871 - learning_rate: 7.1790e-04\n",
      "Epoch 1110/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.3016 - val_accuracy: 0.8933 - val_loss: 1.9917 - learning_rate: 7.1790e-04\n",
      "Epoch 1111/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2847 - val_accuracy: 0.8960 - val_loss: 1.9906 - learning_rate: 7.1790e-04\n",
      "Epoch 1112/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2913 - val_accuracy: 0.8947 - val_loss: 1.9869 - learning_rate: 7.1790e-04\n",
      "Epoch 1113/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2711 - val_accuracy: 0.8933 - val_loss: 1.9910 - learning_rate: 7.1790e-04\n",
      "Epoch 1114/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2820 - val_accuracy: 0.8953 - val_loss: 1.9932 - learning_rate: 7.1790e-04\n",
      "Epoch 1115/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2851 - val_accuracy: 0.8920 - val_loss: 1.9898 - learning_rate: 7.1790e-04\n",
      "Epoch 1116/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2943 - val_accuracy: 0.8933 - val_loss: 1.9932 - learning_rate: 7.1790e-04\n",
      "Epoch 1117/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2854 - val_accuracy: 0.8927 - val_loss: 1.9875 - learning_rate: 7.1790e-04\n",
      "Epoch 1118/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2829 - val_accuracy: 0.8947 - val_loss: 1.9883 - learning_rate: 7.1790e-04\n",
      "Epoch 1119/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2800 - val_accuracy: 0.8960 - val_loss: 1.9866 - learning_rate: 7.1790e-04\n",
      "Epoch 1120/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9138 - loss: 0.2878 - val_accuracy: 0.8927 - val_loss: 1.9856 - learning_rate: 7.1790e-04\n",
      "Epoch 1121/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2858 - val_accuracy: 0.8920 - val_loss: 1.9865 - learning_rate: 7.1790e-04\n",
      "Epoch 1122/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2793 - val_accuracy: 0.8960 - val_loss: 1.9876 - learning_rate: 7.1790e-04\n",
      "Epoch 1123/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.2915 - val_accuracy: 0.8940 - val_loss: 1.9870 - learning_rate: 7.1790e-04\n",
      "Epoch 1124/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2885 - val_accuracy: 0.8933 - val_loss: 1.9809 - learning_rate: 7.1790e-04\n",
      "Epoch 1125/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2893 - val_accuracy: 0.8933 - val_loss: 1.9859 - learning_rate: 7.1790e-04\n",
      "Epoch 1126/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2841 - val_accuracy: 0.8927 - val_loss: 1.9864 - learning_rate: 7.1790e-04\n",
      "Epoch 1127/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2693 - val_accuracy: 0.8940 - val_loss: 1.9901 - learning_rate: 7.1790e-04\n",
      "Epoch 1128/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2784 - val_accuracy: 0.8933 - val_loss: 1.9860 - learning_rate: 7.1790e-04\n",
      "Epoch 1129/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2858 - val_accuracy: 0.8980 - val_loss: 1.9850 - learning_rate: 7.1790e-04\n",
      "Epoch 1130/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2905 - val_accuracy: 0.8933 - val_loss: 1.9816 - learning_rate: 7.1790e-04\n",
      "Epoch 1131/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.2990 - val_accuracy: 0.8927 - val_loss: 1.9849 - learning_rate: 7.1790e-04\n",
      "Epoch 1132/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9069 - loss: 0.2902 - val_accuracy: 0.8940 - val_loss: 1.9899 - learning_rate: 7.1790e-04\n",
      "Epoch 1133/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2906 - val_accuracy: 0.8953 - val_loss: 1.9833 - learning_rate: 7.1790e-04\n",
      "Epoch 1134/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2925 - val_accuracy: 0.8933 - val_loss: 1.9801 - learning_rate: 7.1790e-04\n",
      "Epoch 1135/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2768 - val_accuracy: 0.8907 - val_loss: 1.9883 - learning_rate: 7.1790e-04\n",
      "Epoch 1136/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2883 - val_accuracy: 0.8953 - val_loss: 1.9896 - learning_rate: 7.1790e-04\n",
      "Epoch 1137/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9138 - loss: 0.2827 - val_accuracy: 0.8953 - val_loss: 1.9857 - learning_rate: 7.1790e-04\n",
      "Epoch 1138/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2807 - val_accuracy: 0.8960 - val_loss: 1.9877 - learning_rate: 7.1790e-04\n",
      "Epoch 1139/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2758 - val_accuracy: 0.8940 - val_loss: 1.9907 - learning_rate: 7.1790e-04\n",
      "Epoch 1140/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9200 - loss: 0.2558\n",
      "Epoch 1140: ReduceLROnPlateau reducing learning rate to 0.0006461081618908793.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2777 - val_accuracy: 0.8967 - val_loss: 1.9865 - learning_rate: 7.1790e-04\n",
      "Epoch 1141/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 1.9918 - learning_rate: 6.4611e-04\n",
      "Epoch 1142/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2847 - val_accuracy: 0.8920 - val_loss: 1.9907 - learning_rate: 6.4611e-04\n",
      "Epoch 1143/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2896 - val_accuracy: 0.8907 - val_loss: 1.9912 - learning_rate: 6.4611e-04\n",
      "Epoch 1144/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2904 - val_accuracy: 0.8947 - val_loss: 1.9898 - learning_rate: 6.4611e-04\n",
      "Epoch 1145/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2762 - val_accuracy: 0.8940 - val_loss: 1.9956 - learning_rate: 6.4611e-04\n",
      "Epoch 1146/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2932 - val_accuracy: 0.8953 - val_loss: 1.9929 - learning_rate: 6.4611e-04\n",
      "Epoch 1147/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2968 - val_accuracy: 0.8953 - val_loss: 1.9927 - learning_rate: 6.4611e-04\n",
      "Epoch 1148/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2809 - val_accuracy: 0.8953 - val_loss: 1.9916 - learning_rate: 6.4611e-04\n",
      "Epoch 1149/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2765 - val_accuracy: 0.8900 - val_loss: 1.9877 - learning_rate: 6.4611e-04\n",
      "Epoch 1150/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2871 - val_accuracy: 0.8947 - val_loss: 1.9901 - learning_rate: 6.4611e-04\n",
      "Epoch 1151/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 1.9920 - learning_rate: 6.4611e-04\n",
      "Epoch 1152/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2916 - val_accuracy: 0.8940 - val_loss: 1.9953 - learning_rate: 6.4611e-04\n",
      "Epoch 1153/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 1.9922 - learning_rate: 6.4611e-04\n",
      "Epoch 1154/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2841 - val_accuracy: 0.8987 - val_loss: 1.9975 - learning_rate: 6.4611e-04\n",
      "Epoch 1155/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2811 - val_accuracy: 0.8940 - val_loss: 1.9939 - learning_rate: 6.4611e-04\n",
      "Epoch 1156/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.3050 - val_accuracy: 0.8940 - val_loss: 1.9939 - learning_rate: 6.4611e-04\n",
      "Epoch 1157/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2749 - val_accuracy: 0.8940 - val_loss: 1.9949 - learning_rate: 6.4611e-04\n",
      "Epoch 1158/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2809 - val_accuracy: 0.8940 - val_loss: 1.9919 - learning_rate: 6.4611e-04\n",
      "Epoch 1159/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 1.9926 - learning_rate: 6.4611e-04\n",
      "Epoch 1160/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2707 - val_accuracy: 0.8927 - val_loss: 1.9941 - learning_rate: 6.4611e-04\n",
      "Epoch 1161/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 1.9940 - learning_rate: 6.4611e-04\n",
      "Epoch 1162/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2798 - val_accuracy: 0.8953 - val_loss: 1.9933 - learning_rate: 6.4611e-04\n",
      "Epoch 1163/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2835 - val_accuracy: 0.8900 - val_loss: 1.9932 - learning_rate: 6.4611e-04\n",
      "Epoch 1164/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 1.9931 - learning_rate: 6.4611e-04\n",
      "Epoch 1165/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 1.9886 - learning_rate: 6.4611e-04\n",
      "Epoch 1166/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2878 - val_accuracy: 0.8947 - val_loss: 1.9893 - learning_rate: 6.4611e-04\n",
      "Epoch 1167/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2824 - val_accuracy: 0.8953 - val_loss: 1.9937 - learning_rate: 6.4611e-04\n",
      "Epoch 1168/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.3008 - val_accuracy: 0.8953 - val_loss: 1.9944 - learning_rate: 6.4611e-04\n",
      "Epoch 1169/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 1.9928 - learning_rate: 6.4611e-04\n",
      "Epoch 1170/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2739 - val_accuracy: 0.8940 - val_loss: 1.9938 - learning_rate: 6.4611e-04\n",
      "Epoch 1171/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2760 - val_accuracy: 0.8940 - val_loss: 1.9959 - learning_rate: 6.4611e-04\n",
      "Epoch 1172/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2822 - val_accuracy: 0.8933 - val_loss: 1.9961 - learning_rate: 6.4611e-04\n",
      "Epoch 1173/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.2909 - val_accuracy: 0.8933 - val_loss: 1.9959 - learning_rate: 6.4611e-04\n",
      "Epoch 1174/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2744 - val_accuracy: 0.8953 - val_loss: 1.9946 - learning_rate: 6.4611e-04\n",
      "Epoch 1175/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2838 - val_accuracy: 0.8933 - val_loss: 1.9914 - learning_rate: 6.4611e-04\n",
      "Epoch 1176/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2696 - val_accuracy: 0.8920 - val_loss: 1.9950 - learning_rate: 6.4611e-04\n",
      "Epoch 1177/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9177 - loss: 0.2727 - val_accuracy: 0.8940 - val_loss: 1.9987 - learning_rate: 6.4611e-04\n",
      "Epoch 1178/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.0010 - learning_rate: 6.4611e-04\n",
      "Epoch 1179/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2784 - val_accuracy: 0.8940 - val_loss: 1.9989 - learning_rate: 6.4611e-04\n",
      "Epoch 1180/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 776us/step - accuracy: 0.9108 - loss: 0.2876\n",
      "Epoch 1180: ReduceLROnPlateau reducing learning rate to 0.0005814973614178598.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2844 - val_accuracy: 0.8940 - val_loss: 1.9996 - learning_rate: 6.4611e-04\n",
      "Epoch 1181/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.3016 - val_accuracy: 0.8953 - val_loss: 1.9982 - learning_rate: 5.8150e-04\n",
      "Epoch 1182/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2828 - val_accuracy: 0.8933 - val_loss: 2.0010 - learning_rate: 5.8150e-04\n",
      "Epoch 1183/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9059 - loss: 0.2962 - val_accuracy: 0.8933 - val_loss: 2.0014 - learning_rate: 5.8150e-04\n",
      "Epoch 1184/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2893 - val_accuracy: 0.8927 - val_loss: 2.0036 - learning_rate: 5.8150e-04\n",
      "Epoch 1185/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2878 - val_accuracy: 0.8947 - val_loss: 2.0026 - learning_rate: 5.8150e-04\n",
      "Epoch 1186/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2993 - val_accuracy: 0.8947 - val_loss: 2.0068 - learning_rate: 5.8150e-04\n",
      "Epoch 1187/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.0066 - learning_rate: 5.8150e-04\n",
      "Epoch 1188/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.0032 - learning_rate: 5.8150e-04\n",
      "Epoch 1189/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2936 - val_accuracy: 0.8960 - val_loss: 2.0054 - learning_rate: 5.8150e-04\n",
      "Epoch 1190/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.0019 - learning_rate: 5.8150e-04\n",
      "Epoch 1191/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9052 - loss: 0.2940 - val_accuracy: 0.8953 - val_loss: 2.0047 - learning_rate: 5.8150e-04\n",
      "Epoch 1192/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.0059 - learning_rate: 5.8150e-04\n",
      "Epoch 1193/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2834 - val_accuracy: 0.8940 - val_loss: 2.0084 - learning_rate: 5.8150e-04\n",
      "Epoch 1194/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2973 - val_accuracy: 0.8953 - val_loss: 2.0084 - learning_rate: 5.8150e-04\n",
      "Epoch 1195/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2817 - val_accuracy: 0.8940 - val_loss: 2.0078 - learning_rate: 5.8150e-04\n",
      "Epoch 1196/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2893 - val_accuracy: 0.8953 - val_loss: 2.0105 - learning_rate: 5.8150e-04\n",
      "Epoch 1197/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2909 - val_accuracy: 0.8940 - val_loss: 2.0097 - learning_rate: 5.8150e-04\n",
      "Epoch 1198/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2879 - val_accuracy: 0.8900 - val_loss: 2.0113 - learning_rate: 5.8150e-04\n",
      "Epoch 1199/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2947 - val_accuracy: 0.8940 - val_loss: 2.0122 - learning_rate: 5.8150e-04\n",
      "Epoch 1200/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2912 - val_accuracy: 0.8953 - val_loss: 2.0069 - learning_rate: 5.8150e-04\n",
      "Epoch 1201/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2732 - val_accuracy: 0.8927 - val_loss: 2.0122 - learning_rate: 5.8150e-04\n",
      "Epoch 1202/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2787 - val_accuracy: 0.8940 - val_loss: 2.0060 - learning_rate: 5.8150e-04\n",
      "Epoch 1203/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2944 - val_accuracy: 0.8947 - val_loss: 2.0095 - learning_rate: 5.8150e-04\n",
      "Epoch 1204/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2776 - val_accuracy: 0.8940 - val_loss: 2.0090 - learning_rate: 5.8150e-04\n",
      "Epoch 1205/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.0085 - learning_rate: 5.8150e-04\n",
      "Epoch 1206/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2789 - val_accuracy: 0.8953 - val_loss: 2.0119 - learning_rate: 5.8150e-04\n",
      "Epoch 1207/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2749 - val_accuracy: 0.8933 - val_loss: 2.0109 - learning_rate: 5.8150e-04\n",
      "Epoch 1208/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2832 - val_accuracy: 0.8953 - val_loss: 2.0097 - learning_rate: 5.8150e-04\n",
      "Epoch 1209/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2788 - val_accuracy: 0.8940 - val_loss: 2.0149 - learning_rate: 5.8150e-04\n",
      "Epoch 1210/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2850 - val_accuracy: 0.8947 - val_loss: 2.0145 - learning_rate: 5.8150e-04\n",
      "Epoch 1211/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2821 - val_accuracy: 0.8947 - val_loss: 2.0127 - learning_rate: 5.8150e-04\n",
      "Epoch 1212/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2729 - val_accuracy: 0.8933 - val_loss: 2.0166 - learning_rate: 5.8150e-04\n",
      "Epoch 1213/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2806 - val_accuracy: 0.8940 - val_loss: 2.0126 - learning_rate: 5.8150e-04\n",
      "Epoch 1214/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2831 - val_accuracy: 0.8947 - val_loss: 2.0099 - learning_rate: 5.8150e-04\n",
      "Epoch 1215/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2890 - val_accuracy: 0.8947 - val_loss: 2.0115 - learning_rate: 5.8150e-04\n",
      "Epoch 1216/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2761 - val_accuracy: 0.8933 - val_loss: 2.0133 - learning_rate: 5.8150e-04\n",
      "Epoch 1217/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2937 - val_accuracy: 0.8927 - val_loss: 2.0151 - learning_rate: 5.8150e-04\n",
      "Epoch 1218/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2725 - val_accuracy: 0.8953 - val_loss: 2.0129 - learning_rate: 5.8150e-04\n",
      "Epoch 1219/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2764 - val_accuracy: 0.8927 - val_loss: 2.0138 - learning_rate: 5.8150e-04\n",
      "Epoch 1220/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2531 \n",
      "Epoch 1220: ReduceLROnPlateau reducing learning rate to 0.0005233476462308317.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2651 - val_accuracy: 0.8947 - val_loss: 2.0120 - learning_rate: 5.8150e-04\n",
      "Epoch 1221/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2928 - val_accuracy: 0.8940 - val_loss: 2.0108 - learning_rate: 5.2335e-04\n",
      "Epoch 1222/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2810 - val_accuracy: 0.8933 - val_loss: 2.0143 - learning_rate: 5.2335e-04\n",
      "Epoch 1223/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2836 - val_accuracy: 0.8940 - val_loss: 2.0163 - learning_rate: 5.2335e-04\n",
      "Epoch 1224/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2827 - val_accuracy: 0.8940 - val_loss: 2.0168 - learning_rate: 5.2335e-04\n",
      "Epoch 1225/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2856 - val_accuracy: 0.8927 - val_loss: 2.0164 - learning_rate: 5.2335e-04\n",
      "Epoch 1226/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2679 - val_accuracy: 0.8933 - val_loss: 2.0174 - learning_rate: 5.2335e-04\n",
      "Epoch 1227/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2830 - val_accuracy: 0.8947 - val_loss: 2.0153 - learning_rate: 5.2335e-04\n",
      "Epoch 1228/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9092 - loss: 0.2888 - val_accuracy: 0.8927 - val_loss: 2.0179 - learning_rate: 5.2335e-04\n",
      "Epoch 1229/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2695 - val_accuracy: 0.8953 - val_loss: 2.0189 - learning_rate: 5.2335e-04\n",
      "Epoch 1230/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.2672 - val_accuracy: 0.8933 - val_loss: 2.0161 - learning_rate: 5.2335e-04\n",
      "Epoch 1231/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2805 - val_accuracy: 0.8947 - val_loss: 2.0178 - learning_rate: 5.2335e-04\n",
      "Epoch 1232/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2799 - val_accuracy: 0.8940 - val_loss: 2.0172 - learning_rate: 5.2335e-04\n",
      "Epoch 1233/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2810 - val_accuracy: 0.8940 - val_loss: 2.0169 - learning_rate: 5.2335e-04\n",
      "Epoch 1234/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2895 - val_accuracy: 0.8940 - val_loss: 2.0213 - learning_rate: 5.2335e-04\n",
      "Epoch 1235/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2817 - val_accuracy: 0.8927 - val_loss: 2.0200 - learning_rate: 5.2335e-04\n",
      "Epoch 1236/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2841 - val_accuracy: 0.8940 - val_loss: 2.0183 - learning_rate: 5.2335e-04\n",
      "Epoch 1237/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2829 - val_accuracy: 0.8947 - val_loss: 2.0214 - learning_rate: 5.2335e-04\n",
      "Epoch 1238/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2933 - val_accuracy: 0.8940 - val_loss: 2.0218 - learning_rate: 5.2335e-04\n",
      "Epoch 1239/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2800 - val_accuracy: 0.8933 - val_loss: 2.0193 - learning_rate: 5.2335e-04\n",
      "Epoch 1240/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2841 - val_accuracy: 0.8947 - val_loss: 2.0207 - learning_rate: 5.2335e-04\n",
      "Epoch 1241/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2921 - val_accuracy: 0.8947 - val_loss: 2.0216 - learning_rate: 5.2335e-04\n",
      "Epoch 1242/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2792 - val_accuracy: 0.8933 - val_loss: 2.0229 - learning_rate: 5.2335e-04\n",
      "Epoch 1243/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.0202 - learning_rate: 5.2335e-04\n",
      "Epoch 1244/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9096 - loss: 0.2926 - val_accuracy: 0.8933 - val_loss: 2.0254 - learning_rate: 5.2335e-04\n",
      "Epoch 1245/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2897 - val_accuracy: 0.8940 - val_loss: 2.0221 - learning_rate: 5.2335e-04\n",
      "Epoch 1246/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.0220 - learning_rate: 5.2335e-04\n",
      "Epoch 1247/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2857 - val_accuracy: 0.8947 - val_loss: 2.0250 - learning_rate: 5.2335e-04\n",
      "Epoch 1248/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9066 - loss: 0.2951 - val_accuracy: 0.8940 - val_loss: 2.0254 - learning_rate: 5.2335e-04\n",
      "Epoch 1249/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2881 - val_accuracy: 0.8940 - val_loss: 2.0283 - learning_rate: 5.2335e-04\n",
      "Epoch 1250/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2817 - val_accuracy: 0.8927 - val_loss: 2.0278 - learning_rate: 5.2335e-04\n",
      "Epoch 1251/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.0237 - learning_rate: 5.2335e-04\n",
      "Epoch 1252/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2753 - val_accuracy: 0.8927 - val_loss: 2.0289 - learning_rate: 5.2335e-04\n",
      "Epoch 1253/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2797 - val_accuracy: 0.8933 - val_loss: 2.0286 - learning_rate: 5.2335e-04\n",
      "Epoch 1254/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2711 - val_accuracy: 0.8927 - val_loss: 2.0261 - learning_rate: 5.2335e-04\n",
      "Epoch 1255/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.0272 - learning_rate: 5.2335e-04\n",
      "Epoch 1256/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2778 - val_accuracy: 0.8953 - val_loss: 2.0293 - learning_rate: 5.2335e-04\n",
      "Epoch 1257/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2789 - val_accuracy: 0.8933 - val_loss: 2.0310 - learning_rate: 5.2335e-04\n",
      "Epoch 1258/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2810 - val_accuracy: 0.8940 - val_loss: 2.0308 - learning_rate: 5.2335e-04\n",
      "Epoch 1259/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2850 - val_accuracy: 0.8947 - val_loss: 2.0296 - learning_rate: 5.2335e-04\n",
      "Epoch 1260/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 726us/step - accuracy: 0.9058 - loss: 0.2936\n",
      "Epoch 1260: ReduceLROnPlateau reducing learning rate to 0.0004710128763690591.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2853 - val_accuracy: 0.8940 - val_loss: 2.0315 - learning_rate: 5.2335e-04\n",
      "Epoch 1261/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2731 - val_accuracy: 0.8933 - val_loss: 2.0318 - learning_rate: 4.7101e-04\n",
      "Epoch 1262/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2818 - val_accuracy: 0.8940 - val_loss: 2.0325 - learning_rate: 4.7101e-04\n",
      "Epoch 1263/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9045 - loss: 0.3040 - val_accuracy: 0.8947 - val_loss: 2.0309 - learning_rate: 4.7101e-04\n",
      "Epoch 1264/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2842 - val_accuracy: 0.8927 - val_loss: 2.0331 - learning_rate: 4.7101e-04\n",
      "Epoch 1265/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2712 - val_accuracy: 0.8940 - val_loss: 2.0294 - learning_rate: 4.7101e-04\n",
      "Epoch 1266/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2874 - val_accuracy: 0.8947 - val_loss: 2.0349 - learning_rate: 4.7101e-04\n",
      "Epoch 1267/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2804 - val_accuracy: 0.8940 - val_loss: 2.0316 - learning_rate: 4.7101e-04\n",
      "Epoch 1268/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2827 - val_accuracy: 0.8953 - val_loss: 2.0369 - learning_rate: 4.7101e-04\n",
      "Epoch 1269/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2737 - val_accuracy: 0.8927 - val_loss: 2.0364 - learning_rate: 4.7101e-04\n",
      "Epoch 1270/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2898 - val_accuracy: 0.8933 - val_loss: 2.0374 - learning_rate: 4.7101e-04\n",
      "Epoch 1271/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.0340 - learning_rate: 4.7101e-04\n",
      "Epoch 1272/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2858 - val_accuracy: 0.8940 - val_loss: 2.0374 - learning_rate: 4.7101e-04\n",
      "Epoch 1273/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.0376 - learning_rate: 4.7101e-04\n",
      "Epoch 1274/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2688 - val_accuracy: 0.8933 - val_loss: 2.0359 - learning_rate: 4.7101e-04\n",
      "Epoch 1275/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2864 - val_accuracy: 0.8947 - val_loss: 2.0359 - learning_rate: 4.7101e-04\n",
      "Epoch 1276/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2836 - val_accuracy: 0.8927 - val_loss: 2.0383 - learning_rate: 4.7101e-04\n",
      "Epoch 1277/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2854 - val_accuracy: 0.8953 - val_loss: 2.0408 - learning_rate: 4.7101e-04\n",
      "Epoch 1278/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2683 - val_accuracy: 0.8933 - val_loss: 2.0434 - learning_rate: 4.7101e-04\n",
      "Epoch 1279/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2732 - val_accuracy: 0.8940 - val_loss: 2.0395 - learning_rate: 4.7101e-04\n",
      "Epoch 1280/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2821 - val_accuracy: 0.8947 - val_loss: 2.0404 - learning_rate: 4.7101e-04\n",
      "Epoch 1281/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2883 - val_accuracy: 0.8953 - val_loss: 2.0380 - learning_rate: 4.7101e-04\n",
      "Epoch 1282/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2798 - val_accuracy: 0.8940 - val_loss: 2.0377 - learning_rate: 4.7101e-04\n",
      "Epoch 1283/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.0421 - learning_rate: 4.7101e-04\n",
      "Epoch 1284/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2740 - val_accuracy: 0.8933 - val_loss: 2.0407 - learning_rate: 4.7101e-04\n",
      "Epoch 1285/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2779 - val_accuracy: 0.8933 - val_loss: 2.0408 - learning_rate: 4.7101e-04\n",
      "Epoch 1286/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2786 - val_accuracy: 0.8953 - val_loss: 2.0420 - learning_rate: 4.7101e-04\n",
      "Epoch 1287/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.0442 - learning_rate: 4.7101e-04\n",
      "Epoch 1288/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.0443 - learning_rate: 4.7101e-04\n",
      "Epoch 1289/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2896 - val_accuracy: 0.8940 - val_loss: 2.0447 - learning_rate: 4.7101e-04\n",
      "Epoch 1290/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2864 - val_accuracy: 0.8940 - val_loss: 2.0454 - learning_rate: 4.7101e-04\n",
      "Epoch 1291/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2707 - val_accuracy: 0.8933 - val_loss: 2.0441 - learning_rate: 4.7101e-04\n",
      "Epoch 1292/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2903 - val_accuracy: 0.8940 - val_loss: 2.0418 - learning_rate: 4.7101e-04\n",
      "Epoch 1293/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2785 - val_accuracy: 0.8953 - val_loss: 2.0464 - learning_rate: 4.7101e-04\n",
      "Epoch 1294/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2797 - val_accuracy: 0.8933 - val_loss: 2.0482 - learning_rate: 4.7101e-04\n",
      "Epoch 1295/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2804 - val_accuracy: 0.8953 - val_loss: 2.0493 - learning_rate: 4.7101e-04\n",
      "Epoch 1296/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2707 - val_accuracy: 0.8940 - val_loss: 2.0479 - learning_rate: 4.7101e-04\n",
      "Epoch 1297/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9076 - loss: 0.2890 - val_accuracy: 0.8947 - val_loss: 2.0445 - learning_rate: 4.7101e-04\n",
      "Epoch 1298/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2741 - val_accuracy: 0.8953 - val_loss: 2.0457 - learning_rate: 4.7101e-04\n",
      "Epoch 1299/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2831 - val_accuracy: 0.8940 - val_loss: 2.0474 - learning_rate: 4.7101e-04\n",
      "Epoch 1300/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 859us/step - accuracy: 0.9230 - loss: 0.2764\n",
      "Epoch 1300: ReduceLROnPlateau reducing learning rate to 0.0004239115834934637.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.0467 - learning_rate: 4.7101e-04\n",
      "Epoch 1301/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2706 - val_accuracy: 0.8940 - val_loss: 2.0506 - learning_rate: 4.2391e-04\n",
      "Epoch 1302/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2806 - val_accuracy: 0.8940 - val_loss: 2.0473 - learning_rate: 4.2391e-04\n",
      "Epoch 1303/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.0483 - learning_rate: 4.2391e-04\n",
      "Epoch 1304/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2896 - val_accuracy: 0.8947 - val_loss: 2.0455 - learning_rate: 4.2391e-04\n",
      "Epoch 1305/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.0468 - learning_rate: 4.2391e-04\n",
      "Epoch 1306/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2673 - val_accuracy: 0.8953 - val_loss: 2.0485 - learning_rate: 4.2391e-04\n",
      "Epoch 1307/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2841 - val_accuracy: 0.8940 - val_loss: 2.0493 - learning_rate: 4.2391e-04\n",
      "Epoch 1308/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2858 - val_accuracy: 0.8940 - val_loss: 2.0452 - learning_rate: 4.2391e-04\n",
      "Epoch 1309/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2859 - val_accuracy: 0.8933 - val_loss: 2.0483 - learning_rate: 4.2391e-04\n",
      "Epoch 1310/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2818 - val_accuracy: 0.8933 - val_loss: 2.0479 - learning_rate: 4.2391e-04\n",
      "Epoch 1311/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2822 - val_accuracy: 0.8940 - val_loss: 2.0494 - learning_rate: 4.2391e-04\n",
      "Epoch 1312/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2777 - val_accuracy: 0.8933 - val_loss: 2.0550 - learning_rate: 4.2391e-04\n",
      "Epoch 1313/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2874 - val_accuracy: 0.8960 - val_loss: 2.0483 - learning_rate: 4.2391e-04\n",
      "Epoch 1314/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2834 - val_accuracy: 0.8947 - val_loss: 2.0521 - learning_rate: 4.2391e-04\n",
      "Epoch 1315/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2813 - val_accuracy: 0.8953 - val_loss: 2.0497 - learning_rate: 4.2391e-04\n",
      "Epoch 1316/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.0532 - learning_rate: 4.2391e-04\n",
      "Epoch 1317/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.0509 - learning_rate: 4.2391e-04\n",
      "Epoch 1318/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9138 - loss: 0.2851 - val_accuracy: 0.8933 - val_loss: 2.0512 - learning_rate: 4.2391e-04\n",
      "Epoch 1319/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2830 - val_accuracy: 0.8947 - val_loss: 2.0521 - learning_rate: 4.2391e-04\n",
      "Epoch 1320/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2815 - val_accuracy: 0.8967 - val_loss: 2.0542 - learning_rate: 4.2391e-04\n",
      "Epoch 1321/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2681 - val_accuracy: 0.8953 - val_loss: 2.0527 - learning_rate: 4.2391e-04\n",
      "Epoch 1322/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2807 - val_accuracy: 0.8953 - val_loss: 2.0532 - learning_rate: 4.2391e-04\n",
      "Epoch 1323/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2884 - val_accuracy: 0.8953 - val_loss: 2.0558 - learning_rate: 4.2391e-04\n",
      "Epoch 1324/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9086 - loss: 0.2874 - val_accuracy: 0.8953 - val_loss: 2.0560 - learning_rate: 4.2391e-04\n",
      "Epoch 1325/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.0561 - learning_rate: 4.2391e-04\n",
      "Epoch 1326/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.0581 - learning_rate: 4.2391e-04\n",
      "Epoch 1327/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2774 - val_accuracy: 0.8953 - val_loss: 2.0585 - learning_rate: 4.2391e-04\n",
      "Epoch 1328/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2770 - val_accuracy: 0.8940 - val_loss: 2.0585 - learning_rate: 4.2391e-04\n",
      "Epoch 1329/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.0571 - learning_rate: 4.2391e-04\n",
      "Epoch 1330/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.0612 - learning_rate: 4.2391e-04\n",
      "Epoch 1331/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2760 - val_accuracy: 0.8953 - val_loss: 2.0588 - learning_rate: 4.2391e-04\n",
      "Epoch 1332/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2830 - val_accuracy: 0.8953 - val_loss: 2.0619 - learning_rate: 4.2391e-04\n",
      "Epoch 1333/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2683 - val_accuracy: 0.8940 - val_loss: 2.0597 - learning_rate: 4.2391e-04\n",
      "Epoch 1334/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2837 - val_accuracy: 0.8947 - val_loss: 2.0621 - learning_rate: 4.2391e-04\n",
      "Epoch 1335/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.0617 - learning_rate: 4.2391e-04\n",
      "Epoch 1336/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2775 - val_accuracy: 0.8933 - val_loss: 2.0589 - learning_rate: 4.2391e-04\n",
      "Epoch 1337/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9163 - loss: 0.2717 - val_accuracy: 0.8927 - val_loss: 2.0621 - learning_rate: 4.2391e-04\n",
      "Epoch 1338/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2852 - val_accuracy: 0.8933 - val_loss: 2.0619 - learning_rate: 4.2391e-04\n",
      "Epoch 1339/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2848 - val_accuracy: 0.8927 - val_loss: 2.0619 - learning_rate: 4.2391e-04\n",
      "Epoch 1340/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 877us/step - accuracy: 0.9143 - loss: 0.2697\n",
      "Epoch 1340: ReduceLROnPlateau reducing learning rate to 0.0003815204225247726.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2762 - val_accuracy: 0.8960 - val_loss: 2.0669 - learning_rate: 4.2391e-04\n",
      "Epoch 1341/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2684 - val_accuracy: 0.8940 - val_loss: 2.0655 - learning_rate: 3.8152e-04\n",
      "Epoch 1342/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2759 - val_accuracy: 0.8953 - val_loss: 2.0629 - learning_rate: 3.8152e-04\n",
      "Epoch 1343/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9061 - loss: 0.2869 - val_accuracy: 0.8940 - val_loss: 2.0641 - learning_rate: 3.8152e-04\n",
      "Epoch 1344/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.2891 - val_accuracy: 0.8933 - val_loss: 2.0656 - learning_rate: 3.8152e-04\n",
      "Epoch 1345/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2786 - val_accuracy: 0.8953 - val_loss: 2.0664 - learning_rate: 3.8152e-04\n",
      "Epoch 1346/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2897 - val_accuracy: 0.8947 - val_loss: 2.0694 - learning_rate: 3.8152e-04\n",
      "Epoch 1347/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2712 - val_accuracy: 0.8940 - val_loss: 2.0686 - learning_rate: 3.8152e-04\n",
      "Epoch 1348/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.0687 - learning_rate: 3.8152e-04\n",
      "Epoch 1349/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.0696 - learning_rate: 3.8152e-04\n",
      "Epoch 1350/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2811 - val_accuracy: 0.8927 - val_loss: 2.0667 - learning_rate: 3.8152e-04\n",
      "Epoch 1351/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2769 - val_accuracy: 0.8927 - val_loss: 2.0667 - learning_rate: 3.8152e-04\n",
      "Epoch 1352/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2838 - val_accuracy: 0.8940 - val_loss: 2.0705 - learning_rate: 3.8152e-04\n",
      "Epoch 1353/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2675 - val_accuracy: 0.8933 - val_loss: 2.0691 - learning_rate: 3.8152e-04\n",
      "Epoch 1354/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2713 - val_accuracy: 0.8940 - val_loss: 2.0690 - learning_rate: 3.8152e-04\n",
      "Epoch 1355/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2796 - val_accuracy: 0.8933 - val_loss: 2.0702 - learning_rate: 3.8152e-04\n",
      "Epoch 1356/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2826 - val_accuracy: 0.8933 - val_loss: 2.0671 - learning_rate: 3.8152e-04\n",
      "Epoch 1357/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2724 - val_accuracy: 0.8933 - val_loss: 2.0710 - learning_rate: 3.8152e-04\n",
      "Epoch 1358/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2774 - val_accuracy: 0.8927 - val_loss: 2.0746 - learning_rate: 3.8152e-04\n",
      "Epoch 1359/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2701 - val_accuracy: 0.8933 - val_loss: 2.0713 - learning_rate: 3.8152e-04\n",
      "Epoch 1360/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2739 - val_accuracy: 0.8933 - val_loss: 2.0735 - learning_rate: 3.8152e-04\n",
      "Epoch 1361/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2768 - val_accuracy: 0.8933 - val_loss: 2.0723 - learning_rate: 3.8152e-04\n",
      "Epoch 1362/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2755 - val_accuracy: 0.8940 - val_loss: 2.0726 - learning_rate: 3.8152e-04\n",
      "Epoch 1363/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2703 - val_accuracy: 0.8927 - val_loss: 2.0735 - learning_rate: 3.8152e-04\n",
      "Epoch 1364/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2667 - val_accuracy: 0.8940 - val_loss: 2.0730 - learning_rate: 3.8152e-04\n",
      "Epoch 1365/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2848 - val_accuracy: 0.8927 - val_loss: 2.0743 - learning_rate: 3.8152e-04\n",
      "Epoch 1366/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2755 - val_accuracy: 0.8933 - val_loss: 2.0742 - learning_rate: 3.8152e-04\n",
      "Epoch 1367/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2891 - val_accuracy: 0.8933 - val_loss: 2.0698 - learning_rate: 3.8152e-04\n",
      "Epoch 1368/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2659 - val_accuracy: 0.8933 - val_loss: 2.0702 - learning_rate: 3.8152e-04\n",
      "Epoch 1369/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2899 - val_accuracy: 0.8940 - val_loss: 2.0745 - learning_rate: 3.8152e-04\n",
      "Epoch 1370/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2743 - val_accuracy: 0.8940 - val_loss: 2.0728 - learning_rate: 3.8152e-04\n",
      "Epoch 1371/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2867 - val_accuracy: 0.8940 - val_loss: 2.0713 - learning_rate: 3.8152e-04\n",
      "Epoch 1372/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2850 - val_accuracy: 0.8920 - val_loss: 2.0751 - learning_rate: 3.8152e-04\n",
      "Epoch 1373/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2721 - val_accuracy: 0.8940 - val_loss: 2.0741 - learning_rate: 3.8152e-04\n",
      "Epoch 1374/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2888 - val_accuracy: 0.8933 - val_loss: 2.0760 - learning_rate: 3.8152e-04\n",
      "Epoch 1375/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2787 - val_accuracy: 0.8927 - val_loss: 2.0722 - learning_rate: 3.8152e-04\n",
      "Epoch 1376/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2763 - val_accuracy: 0.8940 - val_loss: 2.0777 - learning_rate: 3.8152e-04\n",
      "Epoch 1377/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.0755 - learning_rate: 3.8152e-04\n",
      "Epoch 1378/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2858 - val_accuracy: 0.8933 - val_loss: 2.0791 - learning_rate: 3.8152e-04\n",
      "Epoch 1379/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2794 - val_accuracy: 0.8927 - val_loss: 2.0772 - learning_rate: 3.8152e-04\n",
      "Epoch 1380/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 960us/step - accuracy: 0.9219 - loss: 0.2587\n",
      "Epoch 1380: ReduceLROnPlateau reducing learning rate to 0.0003433683828916401.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2744 - val_accuracy: 0.8940 - val_loss: 2.0771 - learning_rate: 3.8152e-04\n",
      "Epoch 1381/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2725 - val_accuracy: 0.8940 - val_loss: 2.0778 - learning_rate: 3.4337e-04\n",
      "Epoch 1382/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2786 - val_accuracy: 0.8933 - val_loss: 2.0787 - learning_rate: 3.4337e-04\n",
      "Epoch 1383/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2810 - val_accuracy: 0.8933 - val_loss: 2.0817 - learning_rate: 3.4337e-04\n",
      "Epoch 1384/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.0790 - learning_rate: 3.4337e-04\n",
      "Epoch 1385/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9180 - loss: 0.2638 - val_accuracy: 0.8940 - val_loss: 2.0762 - learning_rate: 3.4337e-04\n",
      "Epoch 1386/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2826 - val_accuracy: 0.8927 - val_loss: 2.0774 - learning_rate: 3.4337e-04\n",
      "Epoch 1387/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2741 - val_accuracy: 0.8933 - val_loss: 2.0796 - learning_rate: 3.4337e-04\n",
      "Epoch 1388/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.0789 - learning_rate: 3.4337e-04\n",
      "Epoch 1389/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2786 - val_accuracy: 0.8933 - val_loss: 2.0777 - learning_rate: 3.4337e-04\n",
      "Epoch 1390/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2746 - val_accuracy: 0.8940 - val_loss: 2.0795 - learning_rate: 3.4337e-04\n",
      "Epoch 1391/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2710 - val_accuracy: 0.8933 - val_loss: 2.0812 - learning_rate: 3.4337e-04\n",
      "Epoch 1392/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.2963 - val_accuracy: 0.8947 - val_loss: 2.0789 - learning_rate: 3.4337e-04\n",
      "Epoch 1393/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2768 - val_accuracy: 0.8940 - val_loss: 2.0800 - learning_rate: 3.4337e-04\n",
      "Epoch 1394/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9058 - loss: 0.2975 - val_accuracy: 0.8940 - val_loss: 2.0798 - learning_rate: 3.4337e-04\n",
      "Epoch 1395/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2788 - val_accuracy: 0.8927 - val_loss: 2.0790 - learning_rate: 3.4337e-04\n",
      "Epoch 1396/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2885 - val_accuracy: 0.8947 - val_loss: 2.0814 - learning_rate: 3.4337e-04\n",
      "Epoch 1397/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2782 - val_accuracy: 0.8933 - val_loss: 2.0813 - learning_rate: 3.4337e-04\n",
      "Epoch 1398/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.0824 - learning_rate: 3.4337e-04\n",
      "Epoch 1399/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2978 - val_accuracy: 0.8940 - val_loss: 2.0829 - learning_rate: 3.4337e-04\n",
      "Epoch 1400/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.0826 - learning_rate: 3.4337e-04\n",
      "Epoch 1401/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.0808 - learning_rate: 3.4337e-04\n",
      "Epoch 1402/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.0836 - learning_rate: 3.4337e-04\n",
      "Epoch 1403/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2804 - val_accuracy: 0.8940 - val_loss: 2.0831 - learning_rate: 3.4337e-04\n",
      "Epoch 1404/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2767 - val_accuracy: 0.8933 - val_loss: 2.0853 - learning_rate: 3.4337e-04\n",
      "Epoch 1405/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.0841 - learning_rate: 3.4337e-04\n",
      "Epoch 1406/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.0832 - learning_rate: 3.4337e-04\n",
      "Epoch 1407/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2834 - val_accuracy: 0.8933 - val_loss: 2.0850 - learning_rate: 3.4337e-04\n",
      "Epoch 1408/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2824 - val_accuracy: 0.8940 - val_loss: 2.0834 - learning_rate: 3.4337e-04\n",
      "Epoch 1409/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.0819 - learning_rate: 3.4337e-04\n",
      "Epoch 1410/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.0843 - learning_rate: 3.4337e-04\n",
      "Epoch 1411/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9183 - loss: 0.2680 - val_accuracy: 0.8933 - val_loss: 2.0846 - learning_rate: 3.4337e-04\n",
      "Epoch 1412/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2939 - val_accuracy: 0.8947 - val_loss: 2.0821 - learning_rate: 3.4337e-04\n",
      "Epoch 1413/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2751 - val_accuracy: 0.8933 - val_loss: 2.0872 - learning_rate: 3.4337e-04\n",
      "Epoch 1414/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2879 - val_accuracy: 0.8947 - val_loss: 2.0874 - learning_rate: 3.4337e-04\n",
      "Epoch 1415/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2839 - val_accuracy: 0.8947 - val_loss: 2.0851 - learning_rate: 3.4337e-04\n",
      "Epoch 1416/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2823 - val_accuracy: 0.8940 - val_loss: 2.0841 - learning_rate: 3.4337e-04\n",
      "Epoch 1417/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2623 - val_accuracy: 0.8940 - val_loss: 2.0869 - learning_rate: 3.4337e-04\n",
      "Epoch 1418/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2791 - val_accuracy: 0.8933 - val_loss: 2.0890 - learning_rate: 3.4337e-04\n",
      "Epoch 1419/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9096 - loss: 0.2866 - val_accuracy: 0.8953 - val_loss: 2.0871 - learning_rate: 3.4337e-04\n",
      "Epoch 1420/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 728us/step - accuracy: 0.9133 - loss: 0.2375\n",
      "Epoch 1420: ReduceLROnPlateau reducing learning rate to 0.0003090315498411656.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2768 - val_accuracy: 0.8940 - val_loss: 2.0868 - learning_rate: 3.4337e-04\n",
      "Epoch 1421/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9207 - loss: 0.2606 - val_accuracy: 0.8940 - val_loss: 2.0872 - learning_rate: 3.0903e-04\n",
      "Epoch 1422/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2811 - val_accuracy: 0.8927 - val_loss: 2.0880 - learning_rate: 3.0903e-04\n",
      "Epoch 1423/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2698 - val_accuracy: 0.8933 - val_loss: 2.0902 - learning_rate: 3.0903e-04\n",
      "Epoch 1424/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2766 - val_accuracy: 0.8933 - val_loss: 2.0870 - learning_rate: 3.0903e-04\n",
      "Epoch 1425/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9177 - loss: 0.2698 - val_accuracy: 0.8933 - val_loss: 2.0896 - learning_rate: 3.0903e-04\n",
      "Epoch 1426/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.0901 - learning_rate: 3.0903e-04\n",
      "Epoch 1427/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2619 - val_accuracy: 0.8940 - val_loss: 2.0897 - learning_rate: 3.0903e-04\n",
      "Epoch 1428/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2845 - val_accuracy: 0.8927 - val_loss: 2.0905 - learning_rate: 3.0903e-04\n",
      "Epoch 1429/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2838 - val_accuracy: 0.8940 - val_loss: 2.0914 - learning_rate: 3.0903e-04\n",
      "Epoch 1430/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.0924 - learning_rate: 3.0903e-04\n",
      "Epoch 1431/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2760 - val_accuracy: 0.8940 - val_loss: 2.0914 - learning_rate: 3.0903e-04\n",
      "Epoch 1432/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2795 - val_accuracy: 0.8940 - val_loss: 2.0928 - learning_rate: 3.0903e-04\n",
      "Epoch 1433/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.0935 - learning_rate: 3.0903e-04\n",
      "Epoch 1434/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2774 - val_accuracy: 0.8933 - val_loss: 2.0932 - learning_rate: 3.0903e-04\n",
      "Epoch 1435/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9074 - loss: 0.2819 - val_accuracy: 0.8933 - val_loss: 2.0927 - learning_rate: 3.0903e-04\n",
      "Epoch 1436/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2826 - val_accuracy: 0.8960 - val_loss: 2.0926 - learning_rate: 3.0903e-04\n",
      "Epoch 1437/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2908 - val_accuracy: 0.8940 - val_loss: 2.0908 - learning_rate: 3.0903e-04\n",
      "Epoch 1438/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2710 - val_accuracy: 0.8940 - val_loss: 2.0933 - learning_rate: 3.0903e-04\n",
      "Epoch 1439/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.0952 - learning_rate: 3.0903e-04\n",
      "Epoch 1440/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2801 - val_accuracy: 0.8940 - val_loss: 2.0957 - learning_rate: 3.0903e-04\n",
      "Epoch 1441/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2777 - val_accuracy: 0.8940 - val_loss: 2.0966 - learning_rate: 3.0903e-04\n",
      "Epoch 1442/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2762 - val_accuracy: 0.8940 - val_loss: 2.0955 - learning_rate: 3.0903e-04\n",
      "Epoch 1443/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2656 - val_accuracy: 0.8940 - val_loss: 2.0972 - learning_rate: 3.0903e-04\n",
      "Epoch 1444/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.0963 - learning_rate: 3.0903e-04\n",
      "Epoch 1445/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2773 - val_accuracy: 0.8940 - val_loss: 2.0970 - learning_rate: 3.0903e-04\n",
      "Epoch 1446/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.0953 - learning_rate: 3.0903e-04\n",
      "Epoch 1447/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.0958 - learning_rate: 3.0903e-04\n",
      "Epoch 1448/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2900 - val_accuracy: 0.8947 - val_loss: 2.0974 - learning_rate: 3.0903e-04\n",
      "Epoch 1449/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2823 - val_accuracy: 0.8940 - val_loss: 2.0972 - learning_rate: 3.0903e-04\n",
      "Epoch 1450/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.0975 - learning_rate: 3.0903e-04\n",
      "Epoch 1451/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2813 - val_accuracy: 0.8940 - val_loss: 2.0956 - learning_rate: 3.0903e-04\n",
      "Epoch 1452/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2859 - val_accuracy: 0.8947 - val_loss: 2.0973 - learning_rate: 3.0903e-04\n",
      "Epoch 1453/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2937 - val_accuracy: 0.8940 - val_loss: 2.0968 - learning_rate: 3.0903e-04\n",
      "Epoch 1454/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2872 - val_accuracy: 0.8940 - val_loss: 2.0973 - learning_rate: 3.0903e-04\n",
      "Epoch 1455/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.0988 - learning_rate: 3.0903e-04\n",
      "Epoch 1456/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2844 - val_accuracy: 0.8940 - val_loss: 2.0989 - learning_rate: 3.0903e-04\n",
      "Epoch 1457/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2729 - val_accuracy: 0.8933 - val_loss: 2.1019 - learning_rate: 3.0903e-04\n",
      "Epoch 1458/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.0995 - learning_rate: 3.0903e-04\n",
      "Epoch 1459/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2806 - val_accuracy: 0.8940 - val_loss: 2.1026 - learning_rate: 3.0903e-04\n",
      "Epoch 1460/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 723us/step - accuracy: 0.9126 - loss: 0.2727\n",
      "Epoch 1460: ReduceLROnPlateau reducing learning rate to 0.00027812838961835954.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2783 - val_accuracy: 0.8940 - val_loss: 2.1014 - learning_rate: 3.0903e-04\n",
      "Epoch 1461/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2715 - val_accuracy: 0.8940 - val_loss: 2.1028 - learning_rate: 2.7813e-04\n",
      "Epoch 1462/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2760 - val_accuracy: 0.8940 - val_loss: 2.1017 - learning_rate: 2.7813e-04\n",
      "Epoch 1463/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2838 - val_accuracy: 0.8940 - val_loss: 2.1005 - learning_rate: 2.7813e-04\n",
      "Epoch 1464/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2744 - val_accuracy: 0.8933 - val_loss: 2.1033 - learning_rate: 2.7813e-04\n",
      "Epoch 1465/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2721 - val_accuracy: 0.8940 - val_loss: 2.1032 - learning_rate: 2.7813e-04\n",
      "Epoch 1466/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2903 - val_accuracy: 0.8940 - val_loss: 2.1034 - learning_rate: 2.7813e-04\n",
      "Epoch 1467/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2766 - val_accuracy: 0.8933 - val_loss: 2.1055 - learning_rate: 2.7813e-04\n",
      "Epoch 1468/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.2766 - val_accuracy: 0.8940 - val_loss: 2.1054 - learning_rate: 2.7813e-04\n",
      "Epoch 1469/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2859 - val_accuracy: 0.8947 - val_loss: 2.1057 - learning_rate: 2.7813e-04\n",
      "Epoch 1470/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.1083 - learning_rate: 2.7813e-04\n",
      "Epoch 1471/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9079 - loss: 0.2871 - val_accuracy: 0.8947 - val_loss: 2.1066 - learning_rate: 2.7813e-04\n",
      "Epoch 1472/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2767 - val_accuracy: 0.8933 - val_loss: 2.1080 - learning_rate: 2.7813e-04\n",
      "Epoch 1473/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.1058 - learning_rate: 2.7813e-04\n",
      "Epoch 1474/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2858 - val_accuracy: 0.8947 - val_loss: 2.1066 - learning_rate: 2.7813e-04\n",
      "Epoch 1475/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2813 - val_accuracy: 0.8940 - val_loss: 2.1045 - learning_rate: 2.7813e-04\n",
      "Epoch 1476/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2691 - val_accuracy: 0.8933 - val_loss: 2.1040 - learning_rate: 2.7813e-04\n",
      "Epoch 1477/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2840 - val_accuracy: 0.8933 - val_loss: 2.1061 - learning_rate: 2.7813e-04\n",
      "Epoch 1478/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2717 - val_accuracy: 0.8933 - val_loss: 2.1048 - learning_rate: 2.7813e-04\n",
      "Epoch 1479/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2673 - val_accuracy: 0.8940 - val_loss: 2.1070 - learning_rate: 2.7813e-04\n",
      "Epoch 1480/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2747 - val_accuracy: 0.8933 - val_loss: 2.1053 - learning_rate: 2.7813e-04\n",
      "Epoch 1481/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2773 - val_accuracy: 0.8933 - val_loss: 2.1067 - learning_rate: 2.7813e-04\n",
      "Epoch 1482/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2767 - val_accuracy: 0.8940 - val_loss: 2.1065 - learning_rate: 2.7813e-04\n",
      "Epoch 1483/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2677 - val_accuracy: 0.8933 - val_loss: 2.1094 - learning_rate: 2.7813e-04\n",
      "Epoch 1484/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2776 - val_accuracy: 0.8933 - val_loss: 2.1101 - learning_rate: 2.7813e-04\n",
      "Epoch 1485/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2780 - val_accuracy: 0.8940 - val_loss: 2.1078 - learning_rate: 2.7813e-04\n",
      "Epoch 1486/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2682 - val_accuracy: 0.8940 - val_loss: 2.1122 - learning_rate: 2.7813e-04\n",
      "Epoch 1487/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2831 - val_accuracy: 0.8933 - val_loss: 2.1090 - learning_rate: 2.7813e-04\n",
      "Epoch 1488/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2770 - val_accuracy: 0.8940 - val_loss: 2.1110 - learning_rate: 2.7813e-04\n",
      "Epoch 1489/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2732 - val_accuracy: 0.8927 - val_loss: 2.1127 - learning_rate: 2.7813e-04\n",
      "Epoch 1490/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2770 - val_accuracy: 0.8933 - val_loss: 2.1107 - learning_rate: 2.7813e-04\n",
      "Epoch 1491/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2674 - val_accuracy: 0.8933 - val_loss: 2.1111 - learning_rate: 2.7813e-04\n",
      "Epoch 1492/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2735 - val_accuracy: 0.8933 - val_loss: 2.1124 - learning_rate: 2.7813e-04\n",
      "Epoch 1493/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9057 - loss: 0.2844 - val_accuracy: 0.8940 - val_loss: 2.1128 - learning_rate: 2.7813e-04\n",
      "Epoch 1494/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2739 - val_accuracy: 0.8933 - val_loss: 2.1129 - learning_rate: 2.7813e-04\n",
      "Epoch 1495/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2749 - val_accuracy: 0.8927 - val_loss: 2.1117 - learning_rate: 2.7813e-04\n",
      "Epoch 1496/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2797 - val_accuracy: 0.8940 - val_loss: 2.1143 - learning_rate: 2.7813e-04\n",
      "Epoch 1497/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2778 - val_accuracy: 0.8920 - val_loss: 2.1149 - learning_rate: 2.7813e-04\n",
      "Epoch 1498/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2825 - val_accuracy: 0.8933 - val_loss: 2.1121 - learning_rate: 2.7813e-04\n",
      "Epoch 1499/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9179 - loss: 0.2692 - val_accuracy: 0.8933 - val_loss: 2.1154 - learning_rate: 2.7813e-04\n",
      "Epoch 1500/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2548 \n",
      "Epoch 1500: ReduceLROnPlateau reducing learning rate to 0.00025031555851455777.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.1150 - learning_rate: 2.7813e-04\n",
      "Epoch 1501/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2819 - val_accuracy: 0.8927 - val_loss: 2.1148 - learning_rate: 2.5032e-04\n",
      "Epoch 1502/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2782 - val_accuracy: 0.8933 - val_loss: 2.1156 - learning_rate: 2.5032e-04\n",
      "Epoch 1503/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2787 - val_accuracy: 0.8940 - val_loss: 2.1179 - learning_rate: 2.5032e-04\n",
      "Epoch 1504/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2703 - val_accuracy: 0.8940 - val_loss: 2.1163 - learning_rate: 2.5032e-04\n",
      "Epoch 1505/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2728 - val_accuracy: 0.8940 - val_loss: 2.1165 - learning_rate: 2.5032e-04\n",
      "Epoch 1506/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2766 - val_accuracy: 0.8933 - val_loss: 2.1158 - learning_rate: 2.5032e-04\n",
      "Epoch 1507/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2682 - val_accuracy: 0.8927 - val_loss: 2.1168 - learning_rate: 2.5032e-04\n",
      "Epoch 1508/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2741 - val_accuracy: 0.8940 - val_loss: 2.1170 - learning_rate: 2.5032e-04\n",
      "Epoch 1509/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2778 - val_accuracy: 0.8933 - val_loss: 2.1157 - learning_rate: 2.5032e-04\n",
      "Epoch 1510/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2827 - val_accuracy: 0.8933 - val_loss: 2.1168 - learning_rate: 2.5032e-04\n",
      "Epoch 1511/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2753 - val_accuracy: 0.8933 - val_loss: 2.1152 - learning_rate: 2.5032e-04\n",
      "Epoch 1512/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2703 - val_accuracy: 0.8933 - val_loss: 2.1192 - learning_rate: 2.5032e-04\n",
      "Epoch 1513/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2878 - val_accuracy: 0.8933 - val_loss: 2.1185 - learning_rate: 2.5032e-04\n",
      "Epoch 1514/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2853 - val_accuracy: 0.8940 - val_loss: 2.1194 - learning_rate: 2.5032e-04\n",
      "Epoch 1515/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2665 - val_accuracy: 0.8940 - val_loss: 2.1177 - learning_rate: 2.5032e-04\n",
      "Epoch 1516/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2702 - val_accuracy: 0.8940 - val_loss: 2.1193 - learning_rate: 2.5032e-04\n",
      "Epoch 1517/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9067 - loss: 0.2878 - val_accuracy: 0.8933 - val_loss: 2.1180 - learning_rate: 2.5032e-04\n",
      "Epoch 1518/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2848 - val_accuracy: 0.8940 - val_loss: 2.1197 - learning_rate: 2.5032e-04\n",
      "Epoch 1519/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2825 - val_accuracy: 0.8940 - val_loss: 2.1194 - learning_rate: 2.5032e-04\n",
      "Epoch 1520/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2728 - val_accuracy: 0.8940 - val_loss: 2.1196 - learning_rate: 2.5032e-04\n",
      "Epoch 1521/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2814 - val_accuracy: 0.8940 - val_loss: 2.1214 - learning_rate: 2.5032e-04\n",
      "Epoch 1522/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2698 - val_accuracy: 0.8933 - val_loss: 2.1206 - learning_rate: 2.5032e-04\n",
      "Epoch 1523/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2788 - val_accuracy: 0.8940 - val_loss: 2.1200 - learning_rate: 2.5032e-04\n",
      "Epoch 1524/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2692 - val_accuracy: 0.8933 - val_loss: 2.1214 - learning_rate: 2.5032e-04\n",
      "Epoch 1525/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2776 - val_accuracy: 0.8940 - val_loss: 2.1210 - learning_rate: 2.5032e-04\n",
      "Epoch 1526/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2820 - val_accuracy: 0.8933 - val_loss: 2.1211 - learning_rate: 2.5032e-04\n",
      "Epoch 1527/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2774 - val_accuracy: 0.8927 - val_loss: 2.1208 - learning_rate: 2.5032e-04\n",
      "Epoch 1528/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2738 - val_accuracy: 0.8940 - val_loss: 2.1198 - learning_rate: 2.5032e-04\n",
      "Epoch 1529/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2830 - val_accuracy: 0.8927 - val_loss: 2.1215 - learning_rate: 2.5032e-04\n",
      "Epoch 1530/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9055 - loss: 0.2879 - val_accuracy: 0.8933 - val_loss: 2.1210 - learning_rate: 2.5032e-04\n",
      "Epoch 1531/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2867 - val_accuracy: 0.8940 - val_loss: 2.1236 - learning_rate: 2.5032e-04\n",
      "Epoch 1532/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2900 - val_accuracy: 0.8940 - val_loss: 2.1203 - learning_rate: 2.5032e-04\n",
      "Epoch 1533/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2754 - val_accuracy: 0.8940 - val_loss: 2.1225 - learning_rate: 2.5032e-04\n",
      "Epoch 1534/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9184 - loss: 0.2657 - val_accuracy: 0.8933 - val_loss: 2.1244 - learning_rate: 2.5032e-04\n",
      "Epoch 1535/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2748 - val_accuracy: 0.8940 - val_loss: 2.1233 - learning_rate: 2.5032e-04\n",
      "Epoch 1536/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2799 - val_accuracy: 0.8933 - val_loss: 2.1247 - learning_rate: 2.5032e-04\n",
      "Epoch 1537/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2830 - val_accuracy: 0.8940 - val_loss: 2.1255 - learning_rate: 2.5032e-04\n",
      "Epoch 1538/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.1250 - learning_rate: 2.5032e-04\n",
      "Epoch 1539/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2879 - val_accuracy: 0.8933 - val_loss: 2.1269 - learning_rate: 2.5032e-04\n",
      "Epoch 1540/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9000 - loss: 0.2991\n",
      "Epoch 1540: ReduceLROnPlateau reducing learning rate to 0.00022528400004375725.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2837 - val_accuracy: 0.8933 - val_loss: 2.1258 - learning_rate: 2.5032e-04\n",
      "Epoch 1541/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2702 - val_accuracy: 0.8940 - val_loss: 2.1258 - learning_rate: 2.2528e-04\n",
      "Epoch 1542/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2602 - val_accuracy: 0.8940 - val_loss: 2.1268 - learning_rate: 2.2528e-04\n",
      "Epoch 1543/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2648 - val_accuracy: 0.8933 - val_loss: 2.1285 - learning_rate: 2.2528e-04\n",
      "Epoch 1544/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2725 - val_accuracy: 0.8940 - val_loss: 2.1292 - learning_rate: 2.2528e-04\n",
      "Epoch 1545/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9182 - loss: 0.2623 - val_accuracy: 0.8940 - val_loss: 2.1288 - learning_rate: 2.2528e-04\n",
      "Epoch 1546/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2803 - val_accuracy: 0.8933 - val_loss: 2.1293 - learning_rate: 2.2528e-04\n",
      "Epoch 1547/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2750 - val_accuracy: 0.8940 - val_loss: 2.1298 - learning_rate: 2.2528e-04\n",
      "Epoch 1548/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2771 - val_accuracy: 0.8940 - val_loss: 2.1269 - learning_rate: 2.2528e-04\n",
      "Epoch 1549/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2788 - val_accuracy: 0.8940 - val_loss: 2.1283 - learning_rate: 2.2528e-04\n",
      "Epoch 1550/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2640 - val_accuracy: 0.8940 - val_loss: 2.1280 - learning_rate: 2.2528e-04\n",
      "Epoch 1551/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2775 - val_accuracy: 0.8933 - val_loss: 2.1269 - learning_rate: 2.2528e-04\n",
      "Epoch 1552/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.1299 - learning_rate: 2.2528e-04\n",
      "Epoch 1553/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2622 - val_accuracy: 0.8940 - val_loss: 2.1284 - learning_rate: 2.2528e-04\n",
      "Epoch 1554/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2828 - val_accuracy: 0.8933 - val_loss: 2.1305 - learning_rate: 2.2528e-04\n",
      "Epoch 1555/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2782 - val_accuracy: 0.8933 - val_loss: 2.1295 - learning_rate: 2.2528e-04\n",
      "Epoch 1556/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2743 - val_accuracy: 0.8933 - val_loss: 2.1294 - learning_rate: 2.2528e-04\n",
      "Epoch 1557/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2682 - val_accuracy: 0.8933 - val_loss: 2.1293 - learning_rate: 2.2528e-04\n",
      "Epoch 1558/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2752 - val_accuracy: 0.8933 - val_loss: 2.1317 - learning_rate: 2.2528e-04\n",
      "Epoch 1559/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2720 - val_accuracy: 0.8940 - val_loss: 2.1295 - learning_rate: 2.2528e-04\n",
      "Epoch 1560/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2825 - val_accuracy: 0.8940 - val_loss: 2.1296 - learning_rate: 2.2528e-04\n",
      "Epoch 1561/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2804 - val_accuracy: 0.8940 - val_loss: 2.1287 - learning_rate: 2.2528e-04\n",
      "Epoch 1562/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2848 - val_accuracy: 0.8940 - val_loss: 2.1302 - learning_rate: 2.2528e-04\n",
      "Epoch 1563/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2837 - val_accuracy: 0.8940 - val_loss: 2.1312 - learning_rate: 2.2528e-04\n",
      "Epoch 1564/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2806 - val_accuracy: 0.8933 - val_loss: 2.1299 - learning_rate: 2.2528e-04\n",
      "Epoch 1565/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2726 - val_accuracy: 0.8933 - val_loss: 2.1298 - learning_rate: 2.2528e-04\n",
      "Epoch 1566/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2833 - val_accuracy: 0.8947 - val_loss: 2.1302 - learning_rate: 2.2528e-04\n",
      "Epoch 1567/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2841 - val_accuracy: 0.8947 - val_loss: 2.1310 - learning_rate: 2.2528e-04\n",
      "Epoch 1568/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2718 - val_accuracy: 0.8940 - val_loss: 2.1311 - learning_rate: 2.2528e-04\n",
      "Epoch 1569/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2788 - val_accuracy: 0.8940 - val_loss: 2.1303 - learning_rate: 2.2528e-04\n",
      "Epoch 1570/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.1308 - learning_rate: 2.2528e-04\n",
      "Epoch 1571/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2834 - val_accuracy: 0.8933 - val_loss: 2.1329 - learning_rate: 2.2528e-04\n",
      "Epoch 1572/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2704 - val_accuracy: 0.8940 - val_loss: 2.1333 - learning_rate: 2.2528e-04\n",
      "Epoch 1573/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2700 - val_accuracy: 0.8933 - val_loss: 2.1306 - learning_rate: 2.2528e-04\n",
      "Epoch 1574/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2716 - val_accuracy: 0.8940 - val_loss: 2.1333 - learning_rate: 2.2528e-04\n",
      "Epoch 1575/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2823 - val_accuracy: 0.8933 - val_loss: 2.1322 - learning_rate: 2.2528e-04\n",
      "Epoch 1576/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2701 - val_accuracy: 0.8933 - val_loss: 2.1333 - learning_rate: 2.2528e-04\n",
      "Epoch 1577/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2684 - val_accuracy: 0.8940 - val_loss: 2.1330 - learning_rate: 2.2528e-04\n",
      "Epoch 1578/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2682 - val_accuracy: 0.8940 - val_loss: 2.1351 - learning_rate: 2.2528e-04\n",
      "Epoch 1579/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2790 - val_accuracy: 0.8933 - val_loss: 2.1351 - learning_rate: 2.2528e-04\n",
      "Epoch 1580/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 785us/step - accuracy: 0.9050 - loss: 0.2776\n",
      "Epoch 1580: ReduceLROnPlateau reducing learning rate to 0.000202755605278071.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2764 - val_accuracy: 0.8940 - val_loss: 2.1357 - learning_rate: 2.2528e-04\n",
      "Epoch 1581/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2736 - val_accuracy: 0.8933 - val_loss: 2.1354 - learning_rate: 2.0276e-04\n",
      "Epoch 1582/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2702 - val_accuracy: 0.8940 - val_loss: 2.1345 - learning_rate: 2.0276e-04\n",
      "Epoch 1583/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2844 - val_accuracy: 0.8940 - val_loss: 2.1335 - learning_rate: 2.0276e-04\n",
      "Epoch 1584/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2618 - val_accuracy: 0.8933 - val_loss: 2.1364 - learning_rate: 2.0276e-04\n",
      "Epoch 1585/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2711 - val_accuracy: 0.8927 - val_loss: 2.1359 - learning_rate: 2.0276e-04\n",
      "Epoch 1586/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2633 - val_accuracy: 0.8927 - val_loss: 2.1372 - learning_rate: 2.0276e-04\n",
      "Epoch 1587/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9178 - loss: 0.2638 - val_accuracy: 0.8940 - val_loss: 2.1361 - learning_rate: 2.0276e-04\n",
      "Epoch 1588/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2773 - val_accuracy: 0.8933 - val_loss: 2.1364 - learning_rate: 2.0276e-04\n",
      "Epoch 1589/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2698 - val_accuracy: 0.8940 - val_loss: 2.1366 - learning_rate: 2.0276e-04\n",
      "Epoch 1590/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2744 - val_accuracy: 0.8933 - val_loss: 2.1371 - learning_rate: 2.0276e-04\n",
      "Epoch 1591/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2788 - val_accuracy: 0.8940 - val_loss: 2.1372 - learning_rate: 2.0276e-04\n",
      "Epoch 1592/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2841 - val_accuracy: 0.8940 - val_loss: 2.1389 - learning_rate: 2.0276e-04\n",
      "Epoch 1593/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2734 - val_accuracy: 0.8933 - val_loss: 2.1361 - learning_rate: 2.0276e-04\n",
      "Epoch 1594/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2706 - val_accuracy: 0.8940 - val_loss: 2.1377 - learning_rate: 2.0276e-04\n",
      "Epoch 1595/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2710 - val_accuracy: 0.8933 - val_loss: 2.1400 - learning_rate: 2.0276e-04\n",
      "Epoch 1596/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2754 - val_accuracy: 0.8940 - val_loss: 2.1391 - learning_rate: 2.0276e-04\n",
      "Epoch 1597/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2685 - val_accuracy: 0.8933 - val_loss: 2.1374 - learning_rate: 2.0276e-04\n",
      "Epoch 1598/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2720 - val_accuracy: 0.8940 - val_loss: 2.1368 - learning_rate: 2.0276e-04\n",
      "Epoch 1599/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2742 - val_accuracy: 0.8933 - val_loss: 2.1377 - learning_rate: 2.0276e-04\n",
      "Epoch 1600/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2817 - val_accuracy: 0.8933 - val_loss: 2.1394 - learning_rate: 2.0276e-04\n",
      "Epoch 1601/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2814 - val_accuracy: 0.8927 - val_loss: 2.1386 - learning_rate: 2.0276e-04\n",
      "Epoch 1602/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2791 - val_accuracy: 0.8927 - val_loss: 2.1389 - learning_rate: 2.0276e-04\n",
      "Epoch 1603/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2732 - val_accuracy: 0.8940 - val_loss: 2.1390 - learning_rate: 2.0276e-04\n",
      "Epoch 1604/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2705 - val_accuracy: 0.8933 - val_loss: 2.1398 - learning_rate: 2.0276e-04\n",
      "Epoch 1605/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2701 - val_accuracy: 0.8940 - val_loss: 2.1409 - learning_rate: 2.0276e-04\n",
      "Epoch 1606/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2727 - val_accuracy: 0.8933 - val_loss: 2.1406 - learning_rate: 2.0276e-04\n",
      "Epoch 1607/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9101 - loss: 0.2768 - val_accuracy: 0.8940 - val_loss: 2.1404 - learning_rate: 2.0276e-04\n",
      "Epoch 1608/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2738 - val_accuracy: 0.8940 - val_loss: 2.1406 - learning_rate: 2.0276e-04\n",
      "Epoch 1609/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2741 - val_accuracy: 0.8940 - val_loss: 2.1411 - learning_rate: 2.0276e-04\n",
      "Epoch 1610/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2825 - val_accuracy: 0.8940 - val_loss: 2.1423 - learning_rate: 2.0276e-04\n",
      "Epoch 1611/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2883 - val_accuracy: 0.8940 - val_loss: 2.1409 - learning_rate: 2.0276e-04\n",
      "Epoch 1612/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2782 - val_accuracy: 0.8940 - val_loss: 2.1415 - learning_rate: 2.0276e-04\n",
      "Epoch 1613/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2714 - val_accuracy: 0.8933 - val_loss: 2.1412 - learning_rate: 2.0276e-04\n",
      "Epoch 1614/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2731 - val_accuracy: 0.8940 - val_loss: 2.1431 - learning_rate: 2.0276e-04\n",
      "Epoch 1615/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2805 - val_accuracy: 0.8947 - val_loss: 2.1433 - learning_rate: 2.0276e-04\n",
      "Epoch 1616/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2738 - val_accuracy: 0.8933 - val_loss: 2.1437 - learning_rate: 2.0276e-04\n",
      "Epoch 1617/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2787 - val_accuracy: 0.8933 - val_loss: 2.1436 - learning_rate: 2.0276e-04\n",
      "Epoch 1618/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2780 - val_accuracy: 0.8940 - val_loss: 2.1437 - learning_rate: 2.0276e-04\n",
      "Epoch 1619/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9080 - loss: 0.2834 - val_accuracy: 0.8933 - val_loss: 2.1423 - learning_rate: 2.0276e-04\n",
      "Epoch 1620/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 749us/step - accuracy: 0.9150 - loss: 0.2802\n",
      "Epoch 1620: ReduceLROnPlateau reducing learning rate to 0.00018248004344059154.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2794 - val_accuracy: 0.8933 - val_loss: 2.1426 - learning_rate: 2.0276e-04\n",
      "Epoch 1621/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2798 - val_accuracy: 0.8927 - val_loss: 2.1423 - learning_rate: 1.8248e-04\n",
      "Epoch 1622/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2752 - val_accuracy: 0.8933 - val_loss: 2.1425 - learning_rate: 1.8248e-04\n",
      "Epoch 1623/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2858 - val_accuracy: 0.8933 - val_loss: 2.1431 - learning_rate: 1.8248e-04\n",
      "Epoch 1624/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2778 - val_accuracy: 0.8933 - val_loss: 2.1434 - learning_rate: 1.8248e-04\n",
      "Epoch 1625/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9097 - loss: 0.2820 - val_accuracy: 0.8933 - val_loss: 2.1429 - learning_rate: 1.8248e-04\n",
      "Epoch 1626/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2729 - val_accuracy: 0.8940 - val_loss: 2.1432 - learning_rate: 1.8248e-04\n",
      "Epoch 1627/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2848 - val_accuracy: 0.8940 - val_loss: 2.1438 - learning_rate: 1.8248e-04\n",
      "Epoch 1628/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2783 - val_accuracy: 0.8933 - val_loss: 2.1450 - learning_rate: 1.8248e-04\n",
      "Epoch 1629/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2774 - val_accuracy: 0.8940 - val_loss: 2.1434 - learning_rate: 1.8248e-04\n",
      "Epoch 1630/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2727 - val_accuracy: 0.8940 - val_loss: 2.1438 - learning_rate: 1.8248e-04\n",
      "Epoch 1631/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2723 - val_accuracy: 0.8940 - val_loss: 2.1445 - learning_rate: 1.8248e-04\n",
      "Epoch 1632/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2796 - val_accuracy: 0.8940 - val_loss: 2.1440 - learning_rate: 1.8248e-04\n",
      "Epoch 1633/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2708 - val_accuracy: 0.8940 - val_loss: 2.1454 - learning_rate: 1.8248e-04\n",
      "Epoch 1634/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2721 - val_accuracy: 0.8940 - val_loss: 2.1454 - learning_rate: 1.8248e-04\n",
      "Epoch 1635/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2720 - val_accuracy: 0.8940 - val_loss: 2.1446 - learning_rate: 1.8248e-04\n",
      "Epoch 1636/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2736 - val_accuracy: 0.8940 - val_loss: 2.1451 - learning_rate: 1.8248e-04\n",
      "Epoch 1637/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2744 - val_accuracy: 0.8940 - val_loss: 2.1468 - learning_rate: 1.8248e-04\n",
      "Epoch 1638/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2870 - val_accuracy: 0.8940 - val_loss: 2.1470 - learning_rate: 1.8248e-04\n",
      "Epoch 1639/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2705 - val_accuracy: 0.8940 - val_loss: 2.1461 - learning_rate: 1.8248e-04\n",
      "Epoch 1640/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2691 - val_accuracy: 0.8940 - val_loss: 2.1464 - learning_rate: 1.8248e-04\n",
      "Epoch 1641/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2675 - val_accuracy: 0.8933 - val_loss: 2.1467 - learning_rate: 1.8248e-04\n",
      "Epoch 1642/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2771 - val_accuracy: 0.8940 - val_loss: 2.1470 - learning_rate: 1.8248e-04\n",
      "Epoch 1643/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2900 - val_accuracy: 0.8940 - val_loss: 2.1479 - learning_rate: 1.8248e-04\n",
      "Epoch 1644/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2864 - val_accuracy: 0.8933 - val_loss: 2.1491 - learning_rate: 1.8248e-04\n",
      "Epoch 1645/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2810 - val_accuracy: 0.8933 - val_loss: 2.1485 - learning_rate: 1.8248e-04\n",
      "Epoch 1646/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9092 - loss: 0.2869 - val_accuracy: 0.8940 - val_loss: 2.1479 - learning_rate: 1.8248e-04\n",
      "Epoch 1647/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2750 - val_accuracy: 0.8933 - val_loss: 2.1483 - learning_rate: 1.8248e-04\n",
      "Epoch 1648/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2773 - val_accuracy: 0.8940 - val_loss: 2.1474 - learning_rate: 1.8248e-04\n",
      "Epoch 1649/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2741 - val_accuracy: 0.8940 - val_loss: 2.1493 - learning_rate: 1.8248e-04\n",
      "Epoch 1650/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2721 - val_accuracy: 0.8940 - val_loss: 2.1479 - learning_rate: 1.8248e-04\n",
      "Epoch 1651/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.2682 - val_accuracy: 0.8933 - val_loss: 2.1481 - learning_rate: 1.8248e-04\n",
      "Epoch 1652/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2806 - val_accuracy: 0.8933 - val_loss: 2.1493 - learning_rate: 1.8248e-04\n",
      "Epoch 1653/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2675 - val_accuracy: 0.8940 - val_loss: 2.1502 - learning_rate: 1.8248e-04\n",
      "Epoch 1654/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2873 - val_accuracy: 0.8940 - val_loss: 2.1488 - learning_rate: 1.8248e-04\n",
      "Epoch 1655/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2734 - val_accuracy: 0.8940 - val_loss: 2.1491 - learning_rate: 1.8248e-04\n",
      "Epoch 1656/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2894 - val_accuracy: 0.8940 - val_loss: 2.1475 - learning_rate: 1.8248e-04\n",
      "Epoch 1657/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2705 - val_accuracy: 0.8940 - val_loss: 2.1488 - learning_rate: 1.8248e-04\n",
      "Epoch 1658/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2650 - val_accuracy: 0.8933 - val_loss: 2.1504 - learning_rate: 1.8248e-04\n",
      "Epoch 1659/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2750 - val_accuracy: 0.8940 - val_loss: 2.1482 - learning_rate: 1.8248e-04\n",
      "Epoch 1660/5000\n",
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2668  \n",
      "Epoch 1660: ReduceLROnPlateau reducing learning rate to 0.00016423203778686004.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2677 - val_accuracy: 0.8933 - val_loss: 2.1488 - learning_rate: 1.8248e-04\n",
      "Epoch 1661/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2851 - val_accuracy: 0.8940 - val_loss: 2.1502 - learning_rate: 1.6423e-04\n",
      "Epoch 1662/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2717 - val_accuracy: 0.8940 - val_loss: 2.1499 - learning_rate: 1.6423e-04\n",
      "Epoch 1663/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2703 - val_accuracy: 0.8940 - val_loss: 2.1513 - learning_rate: 1.6423e-04\n",
      "Epoch 1664/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2682 - val_accuracy: 0.8940 - val_loss: 2.1510 - learning_rate: 1.6423e-04\n",
      "Epoch 1665/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2833 - val_accuracy: 0.8947 - val_loss: 2.1497 - learning_rate: 1.6423e-04\n",
      "Epoch 1666/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2758 - val_accuracy: 0.8933 - val_loss: 2.1523 - learning_rate: 1.6423e-04\n",
      "Epoch 1667/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2757 - val_accuracy: 0.8940 - val_loss: 2.1522 - learning_rate: 1.6423e-04\n",
      "Epoch 1668/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2761 - val_accuracy: 0.8933 - val_loss: 2.1513 - learning_rate: 1.6423e-04\n",
      "Epoch 1669/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2711 - val_accuracy: 0.8933 - val_loss: 2.1490 - learning_rate: 1.6423e-04\n",
      "Epoch 1670/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2723 - val_accuracy: 0.8940 - val_loss: 2.1520 - learning_rate: 1.6423e-04\n",
      "Epoch 1671/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2695 - val_accuracy: 0.8940 - val_loss: 2.1497 - learning_rate: 1.6423e-04\n",
      "Epoch 1672/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2732 - val_accuracy: 0.8940 - val_loss: 2.1502 - learning_rate: 1.6423e-04\n",
      "Epoch 1673/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2677 - val_accuracy: 0.8940 - val_loss: 2.1506 - learning_rate: 1.6423e-04\n",
      "Epoch 1674/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2722 - val_accuracy: 0.8940 - val_loss: 2.1521 - learning_rate: 1.6423e-04\n",
      "Epoch 1675/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2818 - val_accuracy: 0.8940 - val_loss: 2.1512 - learning_rate: 1.6423e-04\n",
      "Epoch 1676/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2798 - val_accuracy: 0.8940 - val_loss: 2.1514 - learning_rate: 1.6423e-04\n",
      "Epoch 1677/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2646 - val_accuracy: 0.8940 - val_loss: 2.1519 - learning_rate: 1.6423e-04\n",
      "Epoch 1678/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2783 - val_accuracy: 0.8940 - val_loss: 2.1523 - learning_rate: 1.6423e-04\n",
      "Epoch 1679/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2853 - val_accuracy: 0.8940 - val_loss: 2.1535 - learning_rate: 1.6423e-04\n",
      "Epoch 1680/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.1536 - learning_rate: 1.6423e-04\n",
      "Epoch 1681/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2815 - val_accuracy: 0.8940 - val_loss: 2.1524 - learning_rate: 1.6423e-04\n",
      "Epoch 1682/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2747 - val_accuracy: 0.8933 - val_loss: 2.1536 - learning_rate: 1.6423e-04\n",
      "Epoch 1683/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.1545 - learning_rate: 1.6423e-04\n",
      "Epoch 1684/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2683 - val_accuracy: 0.8940 - val_loss: 2.1543 - learning_rate: 1.6423e-04\n",
      "Epoch 1685/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2693 - val_accuracy: 0.8933 - val_loss: 2.1523 - learning_rate: 1.6423e-04\n",
      "Epoch 1686/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2676 - val_accuracy: 0.8940 - val_loss: 2.1542 - learning_rate: 1.6423e-04\n",
      "Epoch 1687/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2761 - val_accuracy: 0.8940 - val_loss: 2.1543 - learning_rate: 1.6423e-04\n",
      "Epoch 1688/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.1551 - learning_rate: 1.6423e-04\n",
      "Epoch 1689/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2768 - val_accuracy: 0.8927 - val_loss: 2.1544 - learning_rate: 1.6423e-04\n",
      "Epoch 1690/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2887 - val_accuracy: 0.8933 - val_loss: 2.1533 - learning_rate: 1.6423e-04\n",
      "Epoch 1691/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2795 - val_accuracy: 0.8940 - val_loss: 2.1552 - learning_rate: 1.6423e-04\n",
      "Epoch 1692/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.1553 - learning_rate: 1.6423e-04\n",
      "Epoch 1693/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2663 - val_accuracy: 0.8940 - val_loss: 2.1550 - learning_rate: 1.6423e-04\n",
      "Epoch 1694/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2794 - val_accuracy: 0.8940 - val_loss: 2.1547 - learning_rate: 1.6423e-04\n",
      "Epoch 1695/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2660 - val_accuracy: 0.8940 - val_loss: 2.1560 - learning_rate: 1.6423e-04\n",
      "Epoch 1696/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.1548 - learning_rate: 1.6423e-04\n",
      "Epoch 1697/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2690 - val_accuracy: 0.8940 - val_loss: 2.1560 - learning_rate: 1.6423e-04\n",
      "Epoch 1698/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.1555 - learning_rate: 1.6423e-04\n",
      "Epoch 1699/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.1567 - learning_rate: 1.6423e-04\n",
      "Epoch 1700/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9250 - loss: 0.2576\n",
      "Epoch 1700: ReduceLROnPlateau reducing learning rate to 0.00014780883793719113.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.1565 - learning_rate: 1.6423e-04\n",
      "Epoch 1701/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.1570 - learning_rate: 1.4781e-04\n",
      "Epoch 1702/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2704 - val_accuracy: 0.8940 - val_loss: 2.1554 - learning_rate: 1.4781e-04\n",
      "Epoch 1703/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9063 - loss: 0.2834 - val_accuracy: 0.8940 - val_loss: 2.1574 - learning_rate: 1.4781e-04\n",
      "Epoch 1704/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9065 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.1575 - learning_rate: 1.4781e-04\n",
      "Epoch 1705/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9204 - loss: 0.2605 - val_accuracy: 0.8947 - val_loss: 2.1571 - learning_rate: 1.4781e-04\n",
      "Epoch 1706/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2756 - val_accuracy: 0.8940 - val_loss: 2.1560 - learning_rate: 1.4781e-04\n",
      "Epoch 1707/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2689 - val_accuracy: 0.8953 - val_loss: 2.1567 - learning_rate: 1.4781e-04\n",
      "Epoch 1708/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.1570 - learning_rate: 1.4781e-04\n",
      "Epoch 1709/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.1579 - learning_rate: 1.4781e-04\n",
      "Epoch 1710/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.1573 - learning_rate: 1.4781e-04\n",
      "Epoch 1711/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2768 - val_accuracy: 0.8940 - val_loss: 2.1586 - learning_rate: 1.4781e-04\n",
      "Epoch 1712/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.1578 - learning_rate: 1.4781e-04\n",
      "Epoch 1713/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2712 - val_accuracy: 0.8940 - val_loss: 2.1598 - learning_rate: 1.4781e-04\n",
      "Epoch 1714/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.1590 - learning_rate: 1.4781e-04\n",
      "Epoch 1715/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.1586 - learning_rate: 1.4781e-04\n",
      "Epoch 1716/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.1593 - learning_rate: 1.4781e-04\n",
      "Epoch 1717/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2716 - val_accuracy: 0.8940 - val_loss: 2.1590 - learning_rate: 1.4781e-04\n",
      "Epoch 1718/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.1595 - learning_rate: 1.4781e-04\n",
      "Epoch 1719/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.1592 - learning_rate: 1.4781e-04\n",
      "Epoch 1720/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.1593 - learning_rate: 1.4781e-04\n",
      "Epoch 1721/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.1606 - learning_rate: 1.4781e-04\n",
      "Epoch 1722/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.1602 - learning_rate: 1.4781e-04\n",
      "Epoch 1723/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.1603 - learning_rate: 1.4781e-04\n",
      "Epoch 1724/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2761 - val_accuracy: 0.8953 - val_loss: 2.1611 - learning_rate: 1.4781e-04\n",
      "Epoch 1725/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.2913 - val_accuracy: 0.8947 - val_loss: 2.1603 - learning_rate: 1.4781e-04\n",
      "Epoch 1726/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.1616 - learning_rate: 1.4781e-04\n",
      "Epoch 1727/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.1598 - learning_rate: 1.4781e-04\n",
      "Epoch 1728/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2624 - val_accuracy: 0.8947 - val_loss: 2.1609 - learning_rate: 1.4781e-04\n",
      "Epoch 1729/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2549 - val_accuracy: 0.8947 - val_loss: 2.1621 - learning_rate: 1.4781e-04\n",
      "Epoch 1730/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.1613 - learning_rate: 1.4781e-04\n",
      "Epoch 1731/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2841 - val_accuracy: 0.8947 - val_loss: 2.1608 - learning_rate: 1.4781e-04\n",
      "Epoch 1732/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2685 - val_accuracy: 0.8953 - val_loss: 2.1630 - learning_rate: 1.4781e-04\n",
      "Epoch 1733/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.1621 - learning_rate: 1.4781e-04\n",
      "Epoch 1734/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2711 - val_accuracy: 0.8940 - val_loss: 2.1617 - learning_rate: 1.4781e-04\n",
      "Epoch 1735/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.1633 - learning_rate: 1.4781e-04\n",
      "Epoch 1736/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.1625 - learning_rate: 1.4781e-04\n",
      "Epoch 1737/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.1625 - learning_rate: 1.4781e-04\n",
      "Epoch 1738/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2812 - val_accuracy: 0.8953 - val_loss: 2.1616 - learning_rate: 1.4781e-04\n",
      "Epoch 1739/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9127 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.1619 - learning_rate: 1.4781e-04\n",
      "Epoch 1740/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9233 - loss: 0.2486 \n",
      "Epoch 1740: ReduceLROnPlateau reducing learning rate to 0.00013302795414347202.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.1621 - learning_rate: 1.4781e-04\n",
      "Epoch 1741/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2538 - val_accuracy: 0.8940 - val_loss: 2.1624 - learning_rate: 1.3303e-04\n",
      "Epoch 1742/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.1610 - learning_rate: 1.3303e-04\n",
      "Epoch 1743/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.1616 - learning_rate: 1.3303e-04\n",
      "Epoch 1744/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2875 - val_accuracy: 0.8940 - val_loss: 2.1615 - learning_rate: 1.3303e-04\n",
      "Epoch 1745/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2820 - val_accuracy: 0.8947 - val_loss: 2.1625 - learning_rate: 1.3303e-04\n",
      "Epoch 1746/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.1633 - learning_rate: 1.3303e-04\n",
      "Epoch 1747/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.1629 - learning_rate: 1.3303e-04\n",
      "Epoch 1748/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2769 - val_accuracy: 0.8940 - val_loss: 2.1631 - learning_rate: 1.3303e-04\n",
      "Epoch 1749/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2704 - val_accuracy: 0.8940 - val_loss: 2.1632 - learning_rate: 1.3303e-04\n",
      "Epoch 1750/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.1647 - learning_rate: 1.3303e-04\n",
      "Epoch 1751/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2767 - val_accuracy: 0.8940 - val_loss: 2.1654 - learning_rate: 1.3303e-04\n",
      "Epoch 1752/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9066 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.1643 - learning_rate: 1.3303e-04\n",
      "Epoch 1753/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2812 - val_accuracy: 0.8947 - val_loss: 2.1656 - learning_rate: 1.3303e-04\n",
      "Epoch 1754/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.1649 - learning_rate: 1.3303e-04\n",
      "Epoch 1755/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.1658 - learning_rate: 1.3303e-04\n",
      "Epoch 1756/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2772 - val_accuracy: 0.8940 - val_loss: 2.1663 - learning_rate: 1.3303e-04\n",
      "Epoch 1757/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.1658 - learning_rate: 1.3303e-04\n",
      "Epoch 1758/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.1654 - learning_rate: 1.3303e-04\n",
      "Epoch 1759/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2590 - val_accuracy: 0.8953 - val_loss: 2.1657 - learning_rate: 1.3303e-04\n",
      "Epoch 1760/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2832 - val_accuracy: 0.8947 - val_loss: 2.1659 - learning_rate: 1.3303e-04\n",
      "Epoch 1761/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2803 - val_accuracy: 0.8940 - val_loss: 2.1656 - learning_rate: 1.3303e-04\n",
      "Epoch 1762/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.1658 - learning_rate: 1.3303e-04\n",
      "Epoch 1763/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2815 - val_accuracy: 0.8940 - val_loss: 2.1662 - learning_rate: 1.3303e-04\n",
      "Epoch 1764/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2819 - val_accuracy: 0.8940 - val_loss: 2.1663 - learning_rate: 1.3303e-04\n",
      "Epoch 1765/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2651 - val_accuracy: 0.8940 - val_loss: 2.1664 - learning_rate: 1.3303e-04\n",
      "Epoch 1766/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2761 - val_accuracy: 0.8940 - val_loss: 2.1665 - learning_rate: 1.3303e-04\n",
      "Epoch 1767/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.1666 - learning_rate: 1.3303e-04\n",
      "Epoch 1768/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2773 - val_accuracy: 0.8953 - val_loss: 2.1666 - learning_rate: 1.3303e-04\n",
      "Epoch 1769/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.1657 - learning_rate: 1.3303e-04\n",
      "Epoch 1770/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2566 - val_accuracy: 0.8947 - val_loss: 2.1660 - learning_rate: 1.3303e-04\n",
      "Epoch 1771/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.1659 - learning_rate: 1.3303e-04\n",
      "Epoch 1772/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.1662 - learning_rate: 1.3303e-04\n",
      "Epoch 1773/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9096 - loss: 0.2806 - val_accuracy: 0.8940 - val_loss: 2.1662 - learning_rate: 1.3303e-04\n",
      "Epoch 1774/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.1668 - learning_rate: 1.3303e-04\n",
      "Epoch 1775/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.2843 - val_accuracy: 0.8947 - val_loss: 2.1665 - learning_rate: 1.3303e-04\n",
      "Epoch 1776/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.1667 - learning_rate: 1.3303e-04\n",
      "Epoch 1777/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9162 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.1678 - learning_rate: 1.3303e-04\n",
      "Epoch 1778/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2733 - val_accuracy: 0.8940 - val_loss: 2.1664 - learning_rate: 1.3303e-04\n",
      "Epoch 1779/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2716 - val_accuracy: 0.8940 - val_loss: 2.1665 - learning_rate: 1.3303e-04\n",
      "Epoch 1780/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8717 - loss: 0.3116 8\n",
      "Epoch 1780: ReduceLROnPlateau reducing learning rate to 0.00011972515349043534.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9026 - loss: 0.2894 - val_accuracy: 0.8947 - val_loss: 2.1664 - learning_rate: 1.3303e-04\n",
      "Epoch 1781/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.1672 - learning_rate: 1.1973e-04\n",
      "Epoch 1782/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2637 - val_accuracy: 0.8947 - val_loss: 2.1674 - learning_rate: 1.1973e-04\n",
      "Epoch 1783/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2730 - val_accuracy: 0.8940 - val_loss: 2.1664 - learning_rate: 1.1973e-04\n",
      "Epoch 1784/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2747 - val_accuracy: 0.8940 - val_loss: 2.1666 - learning_rate: 1.1973e-04\n",
      "Epoch 1785/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.1669 - learning_rate: 1.1973e-04\n",
      "Epoch 1786/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.1667 - learning_rate: 1.1973e-04\n",
      "Epoch 1787/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2584 - val_accuracy: 0.8947 - val_loss: 2.1674 - learning_rate: 1.1973e-04\n",
      "Epoch 1788/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2656 - val_accuracy: 0.8947 - val_loss: 2.1677 - learning_rate: 1.1973e-04\n",
      "Epoch 1789/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2727 - val_accuracy: 0.8953 - val_loss: 2.1682 - learning_rate: 1.1973e-04\n",
      "Epoch 1790/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2672 - val_accuracy: 0.8940 - val_loss: 2.1682 - learning_rate: 1.1973e-04\n",
      "Epoch 1791/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.1684 - learning_rate: 1.1973e-04\n",
      "Epoch 1792/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.1691 - learning_rate: 1.1973e-04\n",
      "Epoch 1793/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9115 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.1683 - learning_rate: 1.1973e-04\n",
      "Epoch 1794/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2750 - val_accuracy: 0.8940 - val_loss: 2.1690 - learning_rate: 1.1973e-04\n",
      "Epoch 1795/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2756 - val_accuracy: 0.8940 - val_loss: 2.1698 - learning_rate: 1.1973e-04\n",
      "Epoch 1796/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2827 - val_accuracy: 0.8947 - val_loss: 2.1687 - learning_rate: 1.1973e-04\n",
      "Epoch 1797/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.1691 - learning_rate: 1.1973e-04\n",
      "Epoch 1798/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9173 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.1694 - learning_rate: 1.1973e-04\n",
      "Epoch 1799/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.1693 - learning_rate: 1.1973e-04\n",
      "Epoch 1800/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2616 - val_accuracy: 0.8940 - val_loss: 2.1692 - learning_rate: 1.1973e-04\n",
      "Epoch 1801/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.1691 - learning_rate: 1.1973e-04\n",
      "Epoch 1802/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.1687 - learning_rate: 1.1973e-04\n",
      "Epoch 1803/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.1689 - learning_rate: 1.1973e-04\n",
      "Epoch 1804/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2853 - val_accuracy: 0.8947 - val_loss: 2.1690 - learning_rate: 1.1973e-04\n",
      "Epoch 1805/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2786 - val_accuracy: 0.8940 - val_loss: 2.1701 - learning_rate: 1.1973e-04\n",
      "Epoch 1806/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2743 - val_accuracy: 0.8940 - val_loss: 2.1703 - learning_rate: 1.1973e-04\n",
      "Epoch 1807/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.1697 - learning_rate: 1.1973e-04\n",
      "Epoch 1808/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2764 - val_accuracy: 0.8940 - val_loss: 2.1701 - learning_rate: 1.1973e-04\n",
      "Epoch 1809/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2739 - val_accuracy: 0.8940 - val_loss: 2.1707 - learning_rate: 1.1973e-04\n",
      "Epoch 1810/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.1711 - learning_rate: 1.1973e-04\n",
      "Epoch 1811/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.1705 - learning_rate: 1.1973e-04\n",
      "Epoch 1812/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2651 - val_accuracy: 0.8947 - val_loss: 2.1713 - learning_rate: 1.1973e-04\n",
      "Epoch 1813/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9138 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.1713 - learning_rate: 1.1973e-04\n",
      "Epoch 1814/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2746 - val_accuracy: 0.8940 - val_loss: 2.1710 - learning_rate: 1.1973e-04\n",
      "Epoch 1815/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2673 - val_accuracy: 0.8940 - val_loss: 2.1710 - learning_rate: 1.1973e-04\n",
      "Epoch 1816/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.1716 - learning_rate: 1.1973e-04\n",
      "Epoch 1817/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2775 - val_accuracy: 0.8940 - val_loss: 2.1714 - learning_rate: 1.1973e-04\n",
      "Epoch 1818/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.1723 - learning_rate: 1.1973e-04\n",
      "Epoch 1819/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2732 - val_accuracy: 0.8940 - val_loss: 2.1724 - learning_rate: 1.1973e-04\n",
      "Epoch 1820/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9058 - loss: 0.2831 \n",
      "Epoch 1820: ReduceLROnPlateau reducing learning rate to 0.00010775263945106417.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2785 - val_accuracy: 0.8940 - val_loss: 2.1730 - learning_rate: 1.1973e-04\n",
      "Epoch 1821/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2611 - val_accuracy: 0.8947 - val_loss: 2.1724 - learning_rate: 1.0775e-04\n",
      "Epoch 1822/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.1724 - learning_rate: 1.0775e-04\n",
      "Epoch 1823/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2876 - val_accuracy: 0.8947 - val_loss: 2.1728 - learning_rate: 1.0775e-04\n",
      "Epoch 1824/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.1732 - learning_rate: 1.0775e-04\n",
      "Epoch 1825/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.1736 - learning_rate: 1.0775e-04\n",
      "Epoch 1826/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2709 - val_accuracy: 0.8940 - val_loss: 2.1740 - learning_rate: 1.0775e-04\n",
      "Epoch 1827/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2717 - val_accuracy: 0.8953 - val_loss: 2.1734 - learning_rate: 1.0775e-04\n",
      "Epoch 1828/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.1747 - learning_rate: 1.0775e-04\n",
      "Epoch 1829/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9098 - loss: 0.2763 - val_accuracy: 0.8940 - val_loss: 2.1738 - learning_rate: 1.0775e-04\n",
      "Epoch 1830/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2657 - val_accuracy: 0.8940 - val_loss: 2.1747 - learning_rate: 1.0775e-04\n",
      "Epoch 1831/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2822 - val_accuracy: 0.8947 - val_loss: 2.1739 - learning_rate: 1.0775e-04\n",
      "Epoch 1832/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.1750 - learning_rate: 1.0775e-04\n",
      "Epoch 1833/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.1751 - learning_rate: 1.0775e-04\n",
      "Epoch 1834/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2731 - val_accuracy: 0.8953 - val_loss: 2.1759 - learning_rate: 1.0775e-04\n",
      "Epoch 1835/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2714 - val_accuracy: 0.8953 - val_loss: 2.1747 - learning_rate: 1.0775e-04\n",
      "Epoch 1836/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.1751 - learning_rate: 1.0775e-04\n",
      "Epoch 1837/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.1748 - learning_rate: 1.0775e-04\n",
      "Epoch 1838/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2697 - val_accuracy: 0.8940 - val_loss: 2.1750 - learning_rate: 1.0775e-04\n",
      "Epoch 1839/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.1759 - learning_rate: 1.0775e-04\n",
      "Epoch 1840/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.1757 - learning_rate: 1.0775e-04\n",
      "Epoch 1841/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.1747 - learning_rate: 1.0775e-04\n",
      "Epoch 1842/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.1748 - learning_rate: 1.0775e-04\n",
      "Epoch 1843/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.1753 - learning_rate: 1.0775e-04\n",
      "Epoch 1844/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2694 - val_accuracy: 0.8940 - val_loss: 2.1751 - learning_rate: 1.0775e-04\n",
      "Epoch 1845/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2752 - val_accuracy: 0.8940 - val_loss: 2.1757 - learning_rate: 1.0775e-04\n",
      "Epoch 1846/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.1751 - learning_rate: 1.0775e-04\n",
      "Epoch 1847/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.1755 - learning_rate: 1.0775e-04\n",
      "Epoch 1848/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.1755 - learning_rate: 1.0775e-04\n",
      "Epoch 1849/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.1766 - learning_rate: 1.0775e-04\n",
      "Epoch 1850/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9171 - loss: 0.2640 - val_accuracy: 0.8940 - val_loss: 2.1763 - learning_rate: 1.0775e-04\n",
      "Epoch 1851/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.1762 - learning_rate: 1.0775e-04\n",
      "Epoch 1852/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.1769 - learning_rate: 1.0775e-04\n",
      "Epoch 1853/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.1769 - learning_rate: 1.0775e-04\n",
      "Epoch 1854/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2862 - val_accuracy: 0.8947 - val_loss: 2.1776 - learning_rate: 1.0775e-04\n",
      "Epoch 1855/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9155 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.1777 - learning_rate: 1.0775e-04\n",
      "Epoch 1856/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.1771 - learning_rate: 1.0775e-04\n",
      "Epoch 1857/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.1777 - learning_rate: 1.0775e-04\n",
      "Epoch 1858/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2636 - val_accuracy: 0.8940 - val_loss: 2.1787 - learning_rate: 1.0775e-04\n",
      "Epoch 1859/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2829 - val_accuracy: 0.8947 - val_loss: 2.1780 - learning_rate: 1.0775e-04\n",
      "Epoch 1860/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2651\n",
      "Epoch 1860: ReduceLROnPlateau reducing learning rate to 9.697737550595775e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2710 - val_accuracy: 0.8940 - val_loss: 2.1788 - learning_rate: 1.0775e-04\n",
      "Epoch 1861/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9137 - loss: 0.2751 - val_accuracy: 0.8940 - val_loss: 2.1788 - learning_rate: 9.6977e-05\n",
      "Epoch 1862/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2786 - val_accuracy: 0.8940 - val_loss: 2.1791 - learning_rate: 9.6977e-05\n",
      "Epoch 1863/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2572 - val_accuracy: 0.8947 - val_loss: 2.1796 - learning_rate: 9.6977e-05\n",
      "Epoch 1864/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.1789 - learning_rate: 9.6977e-05\n",
      "Epoch 1865/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2863 - val_accuracy: 0.8947 - val_loss: 2.1784 - learning_rate: 9.6977e-05\n",
      "Epoch 1866/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9143 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.1791 - learning_rate: 9.6977e-05\n",
      "Epoch 1867/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2732 - val_accuracy: 0.8953 - val_loss: 2.1798 - learning_rate: 9.6977e-05\n",
      "Epoch 1868/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2848 - val_accuracy: 0.8947 - val_loss: 2.1795 - learning_rate: 9.6977e-05\n",
      "Epoch 1869/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2799 - val_accuracy: 0.8940 - val_loss: 2.1798 - learning_rate: 9.6977e-05\n",
      "Epoch 1870/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.1785 - learning_rate: 9.6977e-05\n",
      "Epoch 1871/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2880 - val_accuracy: 0.8947 - val_loss: 2.1788 - learning_rate: 9.6977e-05\n",
      "Epoch 1872/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2762 - val_accuracy: 0.8940 - val_loss: 2.1797 - learning_rate: 9.6977e-05\n",
      "Epoch 1873/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9174 - loss: 0.2580 - val_accuracy: 0.8947 - val_loss: 2.1793 - learning_rate: 9.6977e-05\n",
      "Epoch 1874/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2784 - val_accuracy: 0.8940 - val_loss: 2.1796 - learning_rate: 9.6977e-05\n",
      "Epoch 1875/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2736 - val_accuracy: 0.8940 - val_loss: 2.1792 - learning_rate: 9.6977e-05\n",
      "Epoch 1876/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2654 - val_accuracy: 0.8940 - val_loss: 2.1792 - learning_rate: 9.6977e-05\n",
      "Epoch 1877/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.1800 - learning_rate: 9.6977e-05\n",
      "Epoch 1878/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.1799 - learning_rate: 9.6977e-05\n",
      "Epoch 1879/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.1793 - learning_rate: 9.6977e-05\n",
      "Epoch 1880/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2732 - val_accuracy: 0.8953 - val_loss: 2.1803 - learning_rate: 9.6977e-05\n",
      "Epoch 1881/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2852 - val_accuracy: 0.8940 - val_loss: 2.1795 - learning_rate: 9.6977e-05\n",
      "Epoch 1882/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.1802 - learning_rate: 9.6977e-05\n",
      "Epoch 1883/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.1796 - learning_rate: 9.6977e-05\n",
      "Epoch 1884/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.1806 - learning_rate: 9.6977e-05\n",
      "Epoch 1885/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.1805 - learning_rate: 9.6977e-05\n",
      "Epoch 1886/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2755 - val_accuracy: 0.8940 - val_loss: 2.1804 - learning_rate: 9.6977e-05\n",
      "Epoch 1887/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.1809 - learning_rate: 9.6977e-05\n",
      "Epoch 1888/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.1814 - learning_rate: 9.6977e-05\n",
      "Epoch 1889/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9090 - loss: 0.2851 - val_accuracy: 0.8940 - val_loss: 2.1817 - learning_rate: 9.6977e-05\n",
      "Epoch 1890/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2708 - val_accuracy: 0.8940 - val_loss: 2.1815 - learning_rate: 9.6977e-05\n",
      "Epoch 1891/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9077 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.1823 - learning_rate: 9.6977e-05\n",
      "Epoch 1892/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.1828 - learning_rate: 9.6977e-05\n",
      "Epoch 1893/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2731 - val_accuracy: 0.8940 - val_loss: 2.1815 - learning_rate: 9.6977e-05\n",
      "Epoch 1894/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2701 - val_accuracy: 0.8940 - val_loss: 2.1821 - learning_rate: 9.6977e-05\n",
      "Epoch 1895/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2778 - val_accuracy: 0.8940 - val_loss: 2.1815 - learning_rate: 9.6977e-05\n",
      "Epoch 1896/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.1817 - learning_rate: 9.6977e-05\n",
      "Epoch 1897/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.1817 - learning_rate: 9.6977e-05\n",
      "Epoch 1898/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.1823 - learning_rate: 9.6977e-05\n",
      "Epoch 1899/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.1819 - learning_rate: 9.6977e-05\n",
      "Epoch 1900/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2976 \n",
      "Epoch 1900: ReduceLROnPlateau reducing learning rate to 8.727963795536197e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.1822 - learning_rate: 9.6977e-05\n",
      "Epoch 1901/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.1819 - learning_rate: 8.7280e-05\n",
      "Epoch 1902/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.1828 - learning_rate: 8.7280e-05\n",
      "Epoch 1903/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2879 - val_accuracy: 0.8947 - val_loss: 2.1829 - learning_rate: 8.7280e-05\n",
      "Epoch 1904/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.1829 - learning_rate: 8.7280e-05\n",
      "Epoch 1905/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.1832 - learning_rate: 8.7280e-05\n",
      "Epoch 1906/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.1831 - learning_rate: 8.7280e-05\n",
      "Epoch 1907/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.1835 - learning_rate: 8.7280e-05\n",
      "Epoch 1908/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.1828 - learning_rate: 8.7280e-05\n",
      "Epoch 1909/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.1832 - learning_rate: 8.7280e-05\n",
      "Epoch 1910/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2662 - val_accuracy: 0.8940 - val_loss: 2.1839 - learning_rate: 8.7280e-05\n",
      "Epoch 1911/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2774 - val_accuracy: 0.8940 - val_loss: 2.1828 - learning_rate: 8.7280e-05\n",
      "Epoch 1912/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2759 - val_accuracy: 0.8940 - val_loss: 2.1843 - learning_rate: 8.7280e-05\n",
      "Epoch 1913/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.1836 - learning_rate: 8.7280e-05\n",
      "Epoch 1914/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2695 - val_accuracy: 0.8940 - val_loss: 2.1836 - learning_rate: 8.7280e-05\n",
      "Epoch 1915/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2646 - val_accuracy: 0.8940 - val_loss: 2.1842 - learning_rate: 8.7280e-05\n",
      "Epoch 1916/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2736 - val_accuracy: 0.8940 - val_loss: 2.1840 - learning_rate: 8.7280e-05\n",
      "Epoch 1917/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2841 - val_accuracy: 0.8940 - val_loss: 2.1837 - learning_rate: 8.7280e-05\n",
      "Epoch 1918/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2714 - val_accuracy: 0.8940 - val_loss: 2.1842 - learning_rate: 8.7280e-05\n",
      "Epoch 1919/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9120 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.1838 - learning_rate: 8.7280e-05\n",
      "Epoch 1920/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2836 - val_accuracy: 0.8947 - val_loss: 2.1841 - learning_rate: 8.7280e-05\n",
      "Epoch 1921/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.1836 - learning_rate: 8.7280e-05\n",
      "Epoch 1922/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.1845 - learning_rate: 8.7280e-05\n",
      "Epoch 1923/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.1847 - learning_rate: 8.7280e-05\n",
      "Epoch 1924/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9065 - loss: 0.2864 - val_accuracy: 0.8947 - val_loss: 2.1846 - learning_rate: 8.7280e-05\n",
      "Epoch 1925/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.1849 - learning_rate: 8.7280e-05\n",
      "Epoch 1926/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.1851 - learning_rate: 8.7280e-05\n",
      "Epoch 1927/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.1848 - learning_rate: 8.7280e-05\n",
      "Epoch 1928/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.1858 - learning_rate: 8.7280e-05\n",
      "Epoch 1929/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2830 - val_accuracy: 0.8947 - val_loss: 2.1855 - learning_rate: 8.7280e-05\n",
      "Epoch 1930/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2667 - val_accuracy: 0.8940 - val_loss: 2.1859 - learning_rate: 8.7280e-05\n",
      "Epoch 1931/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9040 - loss: 0.2902 - val_accuracy: 0.8940 - val_loss: 2.1859 - learning_rate: 8.7280e-05\n",
      "Epoch 1932/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2673 - val_accuracy: 0.8940 - val_loss: 2.1865 - learning_rate: 8.7280e-05\n",
      "Epoch 1933/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2626 - val_accuracy: 0.8940 - val_loss: 2.1864 - learning_rate: 8.7280e-05\n",
      "Epoch 1934/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2848 - val_accuracy: 0.8947 - val_loss: 2.1862 - learning_rate: 8.7280e-05\n",
      "Epoch 1935/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.2562 - val_accuracy: 0.8940 - val_loss: 2.1867 - learning_rate: 8.7280e-05\n",
      "Epoch 1936/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2858 - val_accuracy: 0.8940 - val_loss: 2.1864 - learning_rate: 8.7280e-05\n",
      "Epoch 1937/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.1864 - learning_rate: 8.7280e-05\n",
      "Epoch 1938/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.1865 - learning_rate: 8.7280e-05\n",
      "Epoch 1939/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2702 - val_accuracy: 0.8940 - val_loss: 2.1866 - learning_rate: 8.7280e-05\n",
      "Epoch 1940/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2509\n",
      "Epoch 1940: ReduceLROnPlateau reducing learning rate to 7.85516735049896e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.1864 - learning_rate: 8.7280e-05\n",
      "Epoch 1941/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.1865 - learning_rate: 7.8552e-05\n",
      "Epoch 1942/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.1866 - learning_rate: 7.8552e-05\n",
      "Epoch 1943/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.1863 - learning_rate: 7.8552e-05\n",
      "Epoch 1944/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.1871 - learning_rate: 7.8552e-05\n",
      "Epoch 1945/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2745 - val_accuracy: 0.8940 - val_loss: 2.1870 - learning_rate: 7.8552e-05\n",
      "Epoch 1946/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2668 - val_accuracy: 0.8940 - val_loss: 2.1872 - learning_rate: 7.8552e-05\n",
      "Epoch 1947/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2825 - val_accuracy: 0.8947 - val_loss: 2.1868 - learning_rate: 7.8552e-05\n",
      "Epoch 1948/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9138 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.1869 - learning_rate: 7.8552e-05\n",
      "Epoch 1949/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.1873 - learning_rate: 7.8552e-05\n",
      "Epoch 1950/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.1876 - learning_rate: 7.8552e-05\n",
      "Epoch 1951/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.1873 - learning_rate: 7.8552e-05\n",
      "Epoch 1952/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.1869 - learning_rate: 7.8552e-05\n",
      "Epoch 1953/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.1874 - learning_rate: 7.8552e-05\n",
      "Epoch 1954/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.1874 - learning_rate: 7.8552e-05\n",
      "Epoch 1955/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.1877 - learning_rate: 7.8552e-05\n",
      "Epoch 1956/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.1878 - learning_rate: 7.8552e-05\n",
      "Epoch 1957/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2838 - val_accuracy: 0.8947 - val_loss: 2.1880 - learning_rate: 7.8552e-05\n",
      "Epoch 1958/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2882 - val_accuracy: 0.8947 - val_loss: 2.1884 - learning_rate: 7.8552e-05\n",
      "Epoch 1959/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2824 - val_accuracy: 0.8947 - val_loss: 2.1883 - learning_rate: 7.8552e-05\n",
      "Epoch 1960/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2683 - val_accuracy: 0.8947 - val_loss: 2.1886 - learning_rate: 7.8552e-05\n",
      "Epoch 1961/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.1889 - learning_rate: 7.8552e-05\n",
      "Epoch 1962/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2731 - val_accuracy: 0.8947 - val_loss: 2.1892 - learning_rate: 7.8552e-05\n",
      "Epoch 1963/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.1901 - learning_rate: 7.8552e-05\n",
      "Epoch 1964/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.1892 - learning_rate: 7.8552e-05\n",
      "Epoch 1965/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2826 - val_accuracy: 0.8947 - val_loss: 2.1892 - learning_rate: 7.8552e-05\n",
      "Epoch 1966/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.1889 - learning_rate: 7.8552e-05\n",
      "Epoch 1967/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.1893 - learning_rate: 7.8552e-05\n",
      "Epoch 1968/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.1897 - learning_rate: 7.8552e-05\n",
      "Epoch 1969/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.1903 - learning_rate: 7.8552e-05\n",
      "Epoch 1970/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.1900 - learning_rate: 7.8552e-05\n",
      "Epoch 1971/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.1899 - learning_rate: 7.8552e-05\n",
      "Epoch 1972/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.1896 - learning_rate: 7.8552e-05\n",
      "Epoch 1973/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.1898 - learning_rate: 7.8552e-05\n",
      "Epoch 1974/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.1904 - learning_rate: 7.8552e-05\n",
      "Epoch 1975/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.1902 - learning_rate: 7.8552e-05\n",
      "Epoch 1976/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.1910 - learning_rate: 7.8552e-05\n",
      "Epoch 1977/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2613 - val_accuracy: 0.8940 - val_loss: 2.1908 - learning_rate: 7.8552e-05\n",
      "Epoch 1978/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.1905 - learning_rate: 7.8552e-05\n",
      "Epoch 1979/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2878 - val_accuracy: 0.8947 - val_loss: 2.1911 - learning_rate: 7.8552e-05\n",
      "Epoch 1980/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2794 \n",
      "Epoch 1980: ReduceLROnPlateau reducing learning rate to 7.0696507464163e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.1910 - learning_rate: 7.8552e-05\n",
      "Epoch 1981/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.1907 - learning_rate: 7.0697e-05\n",
      "Epoch 1982/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.1904 - learning_rate: 7.0697e-05\n",
      "Epoch 1983/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.1908 - learning_rate: 7.0697e-05\n",
      "Epoch 1984/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.1917 - learning_rate: 7.0697e-05\n",
      "Epoch 1985/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9166 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.1904 - learning_rate: 7.0697e-05\n",
      "Epoch 1986/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9170 - loss: 0.2598 - val_accuracy: 0.8947 - val_loss: 2.1908 - learning_rate: 7.0697e-05\n",
      "Epoch 1987/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9194 - loss: 0.2598 - val_accuracy: 0.8940 - val_loss: 2.1915 - learning_rate: 7.0697e-05\n",
      "Epoch 1988/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.1915 - learning_rate: 7.0697e-05\n",
      "Epoch 1989/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.1919 - learning_rate: 7.0697e-05\n",
      "Epoch 1990/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.1918 - learning_rate: 7.0697e-05\n",
      "Epoch 1991/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.1919 - learning_rate: 7.0697e-05\n",
      "Epoch 1992/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.1919 - learning_rate: 7.0697e-05\n",
      "Epoch 1993/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9180 - loss: 0.2607 - val_accuracy: 0.8947 - val_loss: 2.1919 - learning_rate: 7.0697e-05\n",
      "Epoch 1994/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.1918 - learning_rate: 7.0697e-05\n",
      "Epoch 1995/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.1924 - learning_rate: 7.0697e-05\n",
      "Epoch 1996/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9101 - loss: 0.2839 - val_accuracy: 0.8947 - val_loss: 2.1918 - learning_rate: 7.0697e-05\n",
      "Epoch 1997/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.1929 - learning_rate: 7.0697e-05\n",
      "Epoch 1998/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.1926 - learning_rate: 7.0697e-05\n",
      "Epoch 1999/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.1921 - learning_rate: 7.0697e-05\n",
      "Epoch 2000/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.1928 - learning_rate: 7.0697e-05\n",
      "Epoch 2001/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9180 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.1927 - learning_rate: 7.0697e-05\n",
      "Epoch 2002/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2586 - val_accuracy: 0.8940 - val_loss: 2.1930 - learning_rate: 7.0697e-05\n",
      "Epoch 2003/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2735 - val_accuracy: 0.8940 - val_loss: 2.1929 - learning_rate: 7.0697e-05\n",
      "Epoch 2004/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.1932 - learning_rate: 7.0697e-05\n",
      "Epoch 2005/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.1932 - learning_rate: 7.0697e-05\n",
      "Epoch 2006/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2630 - val_accuracy: 0.8940 - val_loss: 2.1934 - learning_rate: 7.0697e-05\n",
      "Epoch 2007/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.1937 - learning_rate: 7.0697e-05\n",
      "Epoch 2008/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.1934 - learning_rate: 7.0697e-05\n",
      "Epoch 2009/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.1932 - learning_rate: 7.0697e-05\n",
      "Epoch 2010/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.1934 - learning_rate: 7.0697e-05\n",
      "Epoch 2011/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.1932 - learning_rate: 7.0697e-05\n",
      "Epoch 2012/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2820 - val_accuracy: 0.8947 - val_loss: 2.1937 - learning_rate: 7.0697e-05\n",
      "Epoch 2013/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9138 - loss: 0.2731 - val_accuracy: 0.8940 - val_loss: 2.1934 - learning_rate: 7.0697e-05\n",
      "Epoch 2014/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.1933 - learning_rate: 7.0697e-05\n",
      "Epoch 2015/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.1936 - learning_rate: 7.0697e-05\n",
      "Epoch 2016/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.1937 - learning_rate: 7.0697e-05\n",
      "Epoch 2017/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.1938 - learning_rate: 7.0697e-05\n",
      "Epoch 2018/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2805 - val_accuracy: 0.8947 - val_loss: 2.1938 - learning_rate: 7.0697e-05\n",
      "Epoch 2019/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.1934 - learning_rate: 7.0697e-05\n",
      "Epoch 2020/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.3187 \n",
      "Epoch 2020: ReduceLROnPlateau reducing learning rate to 6.36268567177467e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.1935 - learning_rate: 7.0697e-05\n",
      "Epoch 2021/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2705 - val_accuracy: 0.8940 - val_loss: 2.1935 - learning_rate: 6.3627e-05\n",
      "Epoch 2022/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2608 - val_accuracy: 0.8947 - val_loss: 2.1940 - learning_rate: 6.3627e-05\n",
      "Epoch 2023/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2739 - val_accuracy: 0.8940 - val_loss: 2.1940 - learning_rate: 6.3627e-05\n",
      "Epoch 2024/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.1934 - learning_rate: 6.3627e-05\n",
      "Epoch 2025/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.1939 - learning_rate: 6.3627e-05\n",
      "Epoch 2026/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.1941 - learning_rate: 6.3627e-05\n",
      "Epoch 2027/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.1941 - learning_rate: 6.3627e-05\n",
      "Epoch 2028/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2645 - val_accuracy: 0.8947 - val_loss: 2.1945 - learning_rate: 6.3627e-05\n",
      "Epoch 2029/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.1940 - learning_rate: 6.3627e-05\n",
      "Epoch 2030/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.1941 - learning_rate: 6.3627e-05\n",
      "Epoch 2031/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2742 - val_accuracy: 0.8940 - val_loss: 2.1949 - learning_rate: 6.3627e-05\n",
      "Epoch 2032/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.1947 - learning_rate: 6.3627e-05\n",
      "Epoch 2033/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.1946 - learning_rate: 6.3627e-05\n",
      "Epoch 2034/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.1943 - learning_rate: 6.3627e-05\n",
      "Epoch 2035/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.1946 - learning_rate: 6.3627e-05\n",
      "Epoch 2036/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.1948 - learning_rate: 6.3627e-05\n",
      "Epoch 2037/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.1947 - learning_rate: 6.3627e-05\n",
      "Epoch 2038/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.1953 - learning_rate: 6.3627e-05\n",
      "Epoch 2039/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2678 - val_accuracy: 0.8940 - val_loss: 2.1950 - learning_rate: 6.3627e-05\n",
      "Epoch 2040/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.1949 - learning_rate: 6.3627e-05\n",
      "Epoch 2041/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.1951 - learning_rate: 6.3627e-05\n",
      "Epoch 2042/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2626 - val_accuracy: 0.8940 - val_loss: 2.1952 - learning_rate: 6.3627e-05\n",
      "Epoch 2043/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.1950 - learning_rate: 6.3627e-05\n",
      "Epoch 2044/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.1957 - learning_rate: 6.3627e-05\n",
      "Epoch 2045/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.1957 - learning_rate: 6.3627e-05\n",
      "Epoch 2046/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.1956 - learning_rate: 6.3627e-05\n",
      "Epoch 2047/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2661 - val_accuracy: 0.8947 - val_loss: 2.1956 - learning_rate: 6.3627e-05\n",
      "Epoch 2048/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9083 - loss: 0.2851 - val_accuracy: 0.8947 - val_loss: 2.1956 - learning_rate: 6.3627e-05\n",
      "Epoch 2049/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.2829 - val_accuracy: 0.8947 - val_loss: 2.1955 - learning_rate: 6.3627e-05\n",
      "Epoch 2050/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.1956 - learning_rate: 6.3627e-05\n",
      "Epoch 2051/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.1957 - learning_rate: 6.3627e-05\n",
      "Epoch 2052/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9039 - loss: 0.2974 - val_accuracy: 0.8947 - val_loss: 2.1954 - learning_rate: 6.3627e-05\n",
      "Epoch 2053/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.1959 - learning_rate: 6.3627e-05\n",
      "Epoch 2054/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2748 - val_accuracy: 0.8940 - val_loss: 2.1963 - learning_rate: 6.3627e-05\n",
      "Epoch 2055/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2849 - val_accuracy: 0.8940 - val_loss: 2.1964 - learning_rate: 6.3627e-05\n",
      "Epoch 2056/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.1967 - learning_rate: 6.3627e-05\n",
      "Epoch 2057/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.1968 - learning_rate: 6.3627e-05\n",
      "Epoch 2058/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2701 - val_accuracy: 0.8940 - val_loss: 2.1972 - learning_rate: 6.3627e-05\n",
      "Epoch 2059/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.1972 - learning_rate: 6.3627e-05\n",
      "Epoch 2060/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9275 - loss: 0.2367 \n",
      "Epoch 2060: ReduceLROnPlateau reducing learning rate to 5.726417366531678e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.1970 - learning_rate: 6.3627e-05\n",
      "Epoch 2061/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.1973 - learning_rate: 5.7264e-05\n",
      "Epoch 2062/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.1974 - learning_rate: 5.7264e-05\n",
      "Epoch 2063/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.1972 - learning_rate: 5.7264e-05\n",
      "Epoch 2064/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2812 - val_accuracy: 0.8947 - val_loss: 2.1977 - learning_rate: 5.7264e-05\n",
      "Epoch 2065/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2774 - val_accuracy: 0.8940 - val_loss: 2.1984 - learning_rate: 5.7264e-05\n",
      "Epoch 2066/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2663 - val_accuracy: 0.8940 - val_loss: 2.1981 - learning_rate: 5.7264e-05\n",
      "Epoch 2067/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2747 - val_accuracy: 0.8940 - val_loss: 2.1979 - learning_rate: 5.7264e-05\n",
      "Epoch 2068/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2740 - val_accuracy: 0.8940 - val_loss: 2.1980 - learning_rate: 5.7264e-05\n",
      "Epoch 2069/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.1973 - learning_rate: 5.7264e-05\n",
      "Epoch 2070/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.1974 - learning_rate: 5.7264e-05\n",
      "Epoch 2071/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9073 - loss: 0.2822 - val_accuracy: 0.8947 - val_loss: 2.1976 - learning_rate: 5.7264e-05\n",
      "Epoch 2072/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.1976 - learning_rate: 5.7264e-05\n",
      "Epoch 2073/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.1983 - learning_rate: 5.7264e-05\n",
      "Epoch 2074/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9065 - loss: 0.2917 - val_accuracy: 0.8940 - val_loss: 2.1982 - learning_rate: 5.7264e-05\n",
      "Epoch 2075/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.1977 - learning_rate: 5.7264e-05\n",
      "Epoch 2076/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.1980 - learning_rate: 5.7264e-05\n",
      "Epoch 2077/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.1983 - learning_rate: 5.7264e-05\n",
      "Epoch 2078/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2821 - val_accuracy: 0.8947 - val_loss: 2.1982 - learning_rate: 5.7264e-05\n",
      "Epoch 2079/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.1977 - learning_rate: 5.7264e-05\n",
      "Epoch 2080/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2830 - val_accuracy: 0.8947 - val_loss: 2.1978 - learning_rate: 5.7264e-05\n",
      "Epoch 2081/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9060 - loss: 0.2897 - val_accuracy: 0.8947 - val_loss: 2.1983 - learning_rate: 5.7264e-05\n",
      "Epoch 2082/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.1986 - learning_rate: 5.7264e-05\n",
      "Epoch 2083/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2766 - val_accuracy: 0.8940 - val_loss: 2.1985 - learning_rate: 5.7264e-05\n",
      "Epoch 2084/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2775 - val_accuracy: 0.8940 - val_loss: 2.1990 - learning_rate: 5.7264e-05\n",
      "Epoch 2085/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.1984 - learning_rate: 5.7264e-05\n",
      "Epoch 2086/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2689 - val_accuracy: 0.8940 - val_loss: 2.1989 - learning_rate: 5.7264e-05\n",
      "Epoch 2087/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.1989 - learning_rate: 5.7264e-05\n",
      "Epoch 2088/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2713 - val_accuracy: 0.8940 - val_loss: 2.1993 - learning_rate: 5.7264e-05\n",
      "Epoch 2089/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.1996 - learning_rate: 5.7264e-05\n",
      "Epoch 2090/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.1995 - learning_rate: 5.7264e-05\n",
      "Epoch 2091/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.1994 - learning_rate: 5.7264e-05\n",
      "Epoch 2092/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.1995 - learning_rate: 5.7264e-05\n",
      "Epoch 2093/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2569 - val_accuracy: 0.8947 - val_loss: 2.1994 - learning_rate: 5.7264e-05\n",
      "Epoch 2094/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9050 - loss: 0.2900 - val_accuracy: 0.8947 - val_loss: 2.1991 - learning_rate: 5.7264e-05\n",
      "Epoch 2095/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.1993 - learning_rate: 5.7264e-05\n",
      "Epoch 2096/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.1990 - learning_rate: 5.7264e-05\n",
      "Epoch 2097/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.1994 - learning_rate: 5.7264e-05\n",
      "Epoch 2098/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.1994 - learning_rate: 5.7264e-05\n",
      "Epoch 2099/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.1995 - learning_rate: 5.7264e-05\n",
      "Epoch 2100/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9283 - loss: 0.2630 \n",
      "Epoch 2100: ReduceLROnPlateau reducing learning rate to 5.1537755643948914e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9157 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.1995 - learning_rate: 5.7264e-05\n",
      "Epoch 2101/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2777 - val_accuracy: 0.8940 - val_loss: 2.1998 - learning_rate: 5.1538e-05\n",
      "Epoch 2102/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2618 - val_accuracy: 0.8947 - val_loss: 2.1999 - learning_rate: 5.1538e-05\n",
      "Epoch 2103/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2737 - val_accuracy: 0.8940 - val_loss: 2.1997 - learning_rate: 5.1538e-05\n",
      "Epoch 2104/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2754 - val_accuracy: 0.8940 - val_loss: 2.2001 - learning_rate: 5.1538e-05\n",
      "Epoch 2105/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.1998 - learning_rate: 5.1538e-05\n",
      "Epoch 2106/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.1998 - learning_rate: 5.1538e-05\n",
      "Epoch 2107/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2002 - learning_rate: 5.1538e-05\n",
      "Epoch 2108/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2644 - val_accuracy: 0.8940 - val_loss: 2.2003 - learning_rate: 5.1538e-05\n",
      "Epoch 2109/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9149 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2000 - learning_rate: 5.1538e-05\n",
      "Epoch 2110/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2001 - learning_rate: 5.1538e-05\n",
      "Epoch 2111/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2004 - learning_rate: 5.1538e-05\n",
      "Epoch 2112/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.2003 - learning_rate: 5.1538e-05\n",
      "Epoch 2113/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2005 - learning_rate: 5.1538e-05\n",
      "Epoch 2114/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2867 - val_accuracy: 0.8940 - val_loss: 2.2007 - learning_rate: 5.1538e-05\n",
      "Epoch 2115/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2744 - val_accuracy: 0.8940 - val_loss: 2.2009 - learning_rate: 5.1538e-05\n",
      "Epoch 2116/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2617 - val_accuracy: 0.8947 - val_loss: 2.2007 - learning_rate: 5.1538e-05\n",
      "Epoch 2117/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2011 - learning_rate: 5.1538e-05\n",
      "Epoch 2118/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2011 - learning_rate: 5.1538e-05\n",
      "Epoch 2119/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.2012 - learning_rate: 5.1538e-05\n",
      "Epoch 2120/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9188 - loss: 0.2597 - val_accuracy: 0.8947 - val_loss: 2.2012 - learning_rate: 5.1538e-05\n",
      "Epoch 2121/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2008 - learning_rate: 5.1538e-05\n",
      "Epoch 2122/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2010 - learning_rate: 5.1538e-05\n",
      "Epoch 2123/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.2864 - val_accuracy: 0.8947 - val_loss: 2.2010 - learning_rate: 5.1538e-05\n",
      "Epoch 2124/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2011 - learning_rate: 5.1538e-05\n",
      "Epoch 2125/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2009 - learning_rate: 5.1538e-05\n",
      "Epoch 2126/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2008 - learning_rate: 5.1538e-05\n",
      "Epoch 2127/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2014 - learning_rate: 5.1538e-05\n",
      "Epoch 2128/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2014 - learning_rate: 5.1538e-05\n",
      "Epoch 2129/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2014 - learning_rate: 5.1538e-05\n",
      "Epoch 2130/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2014 - learning_rate: 5.1538e-05\n",
      "Epoch 2131/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2015 - learning_rate: 5.1538e-05\n",
      "Epoch 2132/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2013 - learning_rate: 5.1538e-05\n",
      "Epoch 2133/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2015 - learning_rate: 5.1538e-05\n",
      "Epoch 2134/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2018 - learning_rate: 5.1538e-05\n",
      "Epoch 2135/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2018 - learning_rate: 5.1538e-05\n",
      "Epoch 2136/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2721 - val_accuracy: 0.8940 - val_loss: 2.2019 - learning_rate: 5.1538e-05\n",
      "Epoch 2137/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9158 - loss: 0.2639 - val_accuracy: 0.8940 - val_loss: 2.2019 - learning_rate: 5.1538e-05\n",
      "Epoch 2138/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2020 - learning_rate: 5.1538e-05\n",
      "Epoch 2139/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2517 - val_accuracy: 0.8947 - val_loss: 2.2019 - learning_rate: 5.1538e-05\n",
      "Epoch 2140/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9030 - loss: 0.2914 0\n",
      "Epoch 2140: ReduceLROnPlateau reducing learning rate to 4.638397876988165e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2020 - learning_rate: 5.1538e-05\n",
      "Epoch 2141/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2020 - learning_rate: 4.6384e-05\n",
      "Epoch 2142/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2020 - learning_rate: 4.6384e-05\n",
      "Epoch 2143/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2019 - learning_rate: 4.6384e-05\n",
      "Epoch 2144/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2024 - learning_rate: 4.6384e-05\n",
      "Epoch 2145/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2853 - val_accuracy: 0.8947 - val_loss: 2.2022 - learning_rate: 4.6384e-05\n",
      "Epoch 2146/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2021 - learning_rate: 4.6384e-05\n",
      "Epoch 2147/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2022 - learning_rate: 4.6384e-05\n",
      "Epoch 2148/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2020 - learning_rate: 4.6384e-05\n",
      "Epoch 2149/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2025 - learning_rate: 4.6384e-05\n",
      "Epoch 2150/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2027 - learning_rate: 4.6384e-05\n",
      "Epoch 2151/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2027 - learning_rate: 4.6384e-05\n",
      "Epoch 2152/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2022 - learning_rate: 4.6384e-05\n",
      "Epoch 2153/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2027 - learning_rate: 4.6384e-05\n",
      "Epoch 2154/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2030 - learning_rate: 4.6384e-05\n",
      "Epoch 2155/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2025 - learning_rate: 4.6384e-05\n",
      "Epoch 2156/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2027 - learning_rate: 4.6384e-05\n",
      "Epoch 2157/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2552 - val_accuracy: 0.8947 - val_loss: 2.2028 - learning_rate: 4.6384e-05\n",
      "Epoch 2158/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2028 - learning_rate: 4.6384e-05\n",
      "Epoch 2159/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9063 - loss: 0.2939 - val_accuracy: 0.8947 - val_loss: 2.2028 - learning_rate: 4.6384e-05\n",
      "Epoch 2160/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2023 - learning_rate: 4.6384e-05\n",
      "Epoch 2161/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2023 - learning_rate: 4.6384e-05\n",
      "Epoch 2162/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2028 - learning_rate: 4.6384e-05\n",
      "Epoch 2163/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2028 - learning_rate: 4.6384e-05\n",
      "Epoch 2164/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2028 - learning_rate: 4.6384e-05\n",
      "Epoch 2165/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2736 - val_accuracy: 0.8953 - val_loss: 2.2033 - learning_rate: 4.6384e-05\n",
      "Epoch 2166/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2032 - learning_rate: 4.6384e-05\n",
      "Epoch 2167/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.2883 - val_accuracy: 0.8947 - val_loss: 2.2036 - learning_rate: 4.6384e-05\n",
      "Epoch 2168/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2030 - learning_rate: 4.6384e-05\n",
      "Epoch 2169/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2035 - learning_rate: 4.6384e-05\n",
      "Epoch 2170/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2035 - learning_rate: 4.6384e-05\n",
      "Epoch 2171/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.2036 - learning_rate: 4.6384e-05\n",
      "Epoch 2172/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2038 - learning_rate: 4.6384e-05\n",
      "Epoch 2173/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2831 - val_accuracy: 0.8947 - val_loss: 2.2038 - learning_rate: 4.6384e-05\n",
      "Epoch 2174/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2574 - val_accuracy: 0.8940 - val_loss: 2.2038 - learning_rate: 4.6384e-05\n",
      "Epoch 2175/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2747 - val_accuracy: 0.8940 - val_loss: 2.2038 - learning_rate: 4.6384e-05\n",
      "Epoch 2176/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2038 - learning_rate: 4.6384e-05\n",
      "Epoch 2177/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2040 - learning_rate: 4.6384e-05\n",
      "Epoch 2178/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2719 - val_accuracy: 0.8940 - val_loss: 2.2043 - learning_rate: 4.6384e-05\n",
      "Epoch 2179/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2040 - learning_rate: 4.6384e-05\n",
      "Epoch 2180/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2483 \n",
      "Epoch 2180: ReduceLROnPlateau reducing learning rate to 4.174558089289349e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2039 - learning_rate: 4.6384e-05\n",
      "Epoch 2181/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9098 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2041 - learning_rate: 4.1746e-05\n",
      "Epoch 2182/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2693 - val_accuracy: 0.8940 - val_loss: 2.2037 - learning_rate: 4.1746e-05\n",
      "Epoch 2183/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2042 - learning_rate: 4.1746e-05\n",
      "Epoch 2184/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2040 - learning_rate: 4.1746e-05\n",
      "Epoch 2185/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9131 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2040 - learning_rate: 4.1746e-05\n",
      "Epoch 2186/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2787 - val_accuracy: 0.8940 - val_loss: 2.2042 - learning_rate: 4.1746e-05\n",
      "Epoch 2187/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2038 - learning_rate: 4.1746e-05\n",
      "Epoch 2188/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2811 - val_accuracy: 0.8947 - val_loss: 2.2037 - learning_rate: 4.1746e-05\n",
      "Epoch 2189/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9223 - loss: 0.2534 - val_accuracy: 0.8947 - val_loss: 2.2040 - learning_rate: 4.1746e-05\n",
      "Epoch 2190/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2039 - learning_rate: 4.1746e-05\n",
      "Epoch 2191/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2043 - learning_rate: 4.1746e-05\n",
      "Epoch 2192/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2043 - learning_rate: 4.1746e-05\n",
      "Epoch 2193/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2043 - learning_rate: 4.1746e-05\n",
      "Epoch 2194/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2044 - learning_rate: 4.1746e-05\n",
      "Epoch 2195/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2047 - learning_rate: 4.1746e-05\n",
      "Epoch 2196/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2044 - learning_rate: 4.1746e-05\n",
      "Epoch 2197/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2049 - learning_rate: 4.1746e-05\n",
      "Epoch 2198/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2045 - learning_rate: 4.1746e-05\n",
      "Epoch 2199/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9181 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2044 - learning_rate: 4.1746e-05\n",
      "Epoch 2200/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2684 - val_accuracy: 0.8940 - val_loss: 2.2047 - learning_rate: 4.1746e-05\n",
      "Epoch 2201/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2050 - learning_rate: 4.1746e-05\n",
      "Epoch 2202/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9176 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2046 - learning_rate: 4.1746e-05\n",
      "Epoch 2203/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2052 - learning_rate: 4.1746e-05\n",
      "Epoch 2204/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2050 - learning_rate: 4.1746e-05\n",
      "Epoch 2205/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2051 - learning_rate: 4.1746e-05\n",
      "Epoch 2206/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9086 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2054 - learning_rate: 4.1746e-05\n",
      "Epoch 2207/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9106 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2058 - learning_rate: 4.1746e-05\n",
      "Epoch 2208/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2054 - learning_rate: 4.1746e-05\n",
      "Epoch 2209/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2056 - learning_rate: 4.1746e-05\n",
      "Epoch 2210/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2713 - val_accuracy: 0.8940 - val_loss: 2.2057 - learning_rate: 4.1746e-05\n",
      "Epoch 2211/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2735 - val_accuracy: 0.8940 - val_loss: 2.2058 - learning_rate: 4.1746e-05\n",
      "Epoch 2212/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2058 - learning_rate: 4.1746e-05\n",
      "Epoch 2213/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2053 - learning_rate: 4.1746e-05\n",
      "Epoch 2214/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2053 - learning_rate: 4.1746e-05\n",
      "Epoch 2215/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2055 - learning_rate: 4.1746e-05\n",
      "Epoch 2216/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2057 - learning_rate: 4.1746e-05\n",
      "Epoch 2217/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2058 - learning_rate: 4.1746e-05\n",
      "Epoch 2218/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2834 - val_accuracy: 0.8947 - val_loss: 2.2056 - learning_rate: 4.1746e-05\n",
      "Epoch 2219/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2057 - learning_rate: 4.1746e-05\n",
      "Epoch 2220/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2860 \n",
      "Epoch 2220: ReduceLROnPlateau reducing learning rate to 3.7571023131022234e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2059 - learning_rate: 4.1746e-05\n",
      "Epoch 2221/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2064 - learning_rate: 3.7571e-05\n",
      "Epoch 2222/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.2058 - learning_rate: 3.7571e-05\n",
      "Epoch 2223/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2061 - learning_rate: 3.7571e-05\n",
      "Epoch 2224/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9087 - loss: 0.2808 - val_accuracy: 0.8940 - val_loss: 2.2062 - learning_rate: 3.7571e-05\n",
      "Epoch 2225/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2067 - learning_rate: 3.7571e-05\n",
      "Epoch 2226/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2066 - learning_rate: 3.7571e-05\n",
      "Epoch 2227/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2067 - learning_rate: 3.7571e-05\n",
      "Epoch 2228/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2069 - learning_rate: 3.7571e-05\n",
      "Epoch 2229/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2070 - learning_rate: 3.7571e-05\n",
      "Epoch 2230/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2068 - learning_rate: 3.7571e-05\n",
      "Epoch 2231/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2068 - learning_rate: 3.7571e-05\n",
      "Epoch 2232/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2864 - val_accuracy: 0.8947 - val_loss: 2.2072 - learning_rate: 3.7571e-05\n",
      "Epoch 2233/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2069 - learning_rate: 3.7571e-05\n",
      "Epoch 2234/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2070 - learning_rate: 3.7571e-05\n",
      "Epoch 2235/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2073 - learning_rate: 3.7571e-05\n",
      "Epoch 2236/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2620 - val_accuracy: 0.8947 - val_loss: 2.2070 - learning_rate: 3.7571e-05\n",
      "Epoch 2237/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2072 - learning_rate: 3.7571e-05\n",
      "Epoch 2238/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9066 - loss: 0.2895 - val_accuracy: 0.8947 - val_loss: 2.2067 - learning_rate: 3.7571e-05\n",
      "Epoch 2239/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2888 - val_accuracy: 0.8947 - val_loss: 2.2071 - learning_rate: 3.7571e-05\n",
      "Epoch 2240/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2068 - learning_rate: 3.7571e-05\n",
      "Epoch 2241/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2072 - learning_rate: 3.7571e-05\n",
      "Epoch 2242/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2243/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2074 - learning_rate: 3.7571e-05\n",
      "Epoch 2244/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2245/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2798 - val_accuracy: 0.8940 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2246/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9075 - loss: 0.2866 - val_accuracy: 0.8940 - val_loss: 2.2079 - learning_rate: 3.7571e-05\n",
      "Epoch 2247/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9102 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2079 - learning_rate: 3.7571e-05\n",
      "Epoch 2248/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2076 - learning_rate: 3.7571e-05\n",
      "Epoch 2249/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2250/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2076 - learning_rate: 3.7571e-05\n",
      "Epoch 2251/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2860 - val_accuracy: 0.8947 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2252/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2078 - learning_rate: 3.7571e-05\n",
      "Epoch 2253/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9177 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2254/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2255/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2074 - learning_rate: 3.7571e-05\n",
      "Epoch 2256/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9196 - loss: 0.2563 - val_accuracy: 0.8947 - val_loss: 2.2075 - learning_rate: 3.7571e-05\n",
      "Epoch 2257/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2077 - learning_rate: 3.7571e-05\n",
      "Epoch 2258/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2620 - val_accuracy: 0.8947 - val_loss: 2.2079 - learning_rate: 3.7571e-05\n",
      "Epoch 2259/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2078 - learning_rate: 3.7571e-05\n",
      "Epoch 2260/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9225 - loss: 0.2622 \n",
      "Epoch 2260: ReduceLROnPlateau reducing learning rate to 3.381392016308382e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2078 - learning_rate: 3.7571e-05\n",
      "Epoch 2261/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2080 - learning_rate: 3.3814e-05\n",
      "Epoch 2262/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2079 - learning_rate: 3.3814e-05\n",
      "Epoch 2263/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2902 - val_accuracy: 0.8947 - val_loss: 2.2080 - learning_rate: 3.3814e-05\n",
      "Epoch 2264/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9087 - loss: 0.2857 - val_accuracy: 0.8947 - val_loss: 2.2081 - learning_rate: 3.3814e-05\n",
      "Epoch 2265/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2082 - learning_rate: 3.3814e-05\n",
      "Epoch 2266/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9087 - loss: 0.2834 - val_accuracy: 0.8947 - val_loss: 2.2083 - learning_rate: 3.3814e-05\n",
      "Epoch 2267/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2086 - learning_rate: 3.3814e-05\n",
      "Epoch 2268/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2085 - learning_rate: 3.3814e-05\n",
      "Epoch 2269/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2084 - learning_rate: 3.3814e-05\n",
      "Epoch 2270/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2085 - learning_rate: 3.3814e-05\n",
      "Epoch 2271/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2083 - learning_rate: 3.3814e-05\n",
      "Epoch 2272/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2085 - learning_rate: 3.3814e-05\n",
      "Epoch 2273/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2086 - learning_rate: 3.3814e-05\n",
      "Epoch 2274/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2086 - learning_rate: 3.3814e-05\n",
      "Epoch 2275/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.2085 - learning_rate: 3.3814e-05\n",
      "Epoch 2276/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2085 - learning_rate: 3.3814e-05\n",
      "Epoch 2277/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2084 - learning_rate: 3.3814e-05\n",
      "Epoch 2278/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2087 - learning_rate: 3.3814e-05\n",
      "Epoch 2279/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2845 - val_accuracy: 0.8947 - val_loss: 2.2087 - learning_rate: 3.3814e-05\n",
      "Epoch 2280/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2088 - learning_rate: 3.3814e-05\n",
      "Epoch 2281/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2087 - learning_rate: 3.3814e-05\n",
      "Epoch 2282/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2086 - learning_rate: 3.3814e-05\n",
      "Epoch 2283/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.2088 - learning_rate: 3.3814e-05\n",
      "Epoch 2284/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9119 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2087 - learning_rate: 3.3814e-05\n",
      "Epoch 2285/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2088 - learning_rate: 3.3814e-05\n",
      "Epoch 2286/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2092 - learning_rate: 3.3814e-05\n",
      "Epoch 2287/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2818 - val_accuracy: 0.8940 - val_loss: 2.2096 - learning_rate: 3.3814e-05\n",
      "Epoch 2288/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2700 - val_accuracy: 0.8940 - val_loss: 2.2093 - learning_rate: 3.3814e-05\n",
      "Epoch 2289/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9066 - loss: 0.2898 - val_accuracy: 0.8940 - val_loss: 2.2093 - learning_rate: 3.3814e-05\n",
      "Epoch 2290/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2768 - val_accuracy: 0.8940 - val_loss: 2.2092 - learning_rate: 3.3814e-05\n",
      "Epoch 2291/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9106 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2089 - learning_rate: 3.3814e-05\n",
      "Epoch 2292/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2089 - learning_rate: 3.3814e-05\n",
      "Epoch 2293/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2089 - learning_rate: 3.3814e-05\n",
      "Epoch 2294/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2090 - learning_rate: 3.3814e-05\n",
      "Epoch 2295/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2849 - val_accuracy: 0.8947 - val_loss: 2.2088 - learning_rate: 3.3814e-05\n",
      "Epoch 2296/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2824 - val_accuracy: 0.8940 - val_loss: 2.2092 - learning_rate: 3.3814e-05\n",
      "Epoch 2297/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2094 - learning_rate: 3.3814e-05\n",
      "Epoch 2298/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2094 - learning_rate: 3.3814e-05\n",
      "Epoch 2299/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2093 - learning_rate: 3.3814e-05\n",
      "Epoch 2300/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2742 \n",
      "Epoch 2300: ReduceLROnPlateau reducing learning rate to 3.043252945644781e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2094 - learning_rate: 3.3814e-05\n",
      "Epoch 2301/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2094 - learning_rate: 3.0433e-05\n",
      "Epoch 2302/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2092 - learning_rate: 3.0433e-05\n",
      "Epoch 2303/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2093 - learning_rate: 3.0433e-05\n",
      "Epoch 2304/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.2093 - learning_rate: 3.0433e-05\n",
      "Epoch 2305/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2096 - learning_rate: 3.0433e-05\n",
      "Epoch 2306/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2649 - val_accuracy: 0.8947 - val_loss: 2.2096 - learning_rate: 3.0433e-05\n",
      "Epoch 2307/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2097 - learning_rate: 3.0433e-05\n",
      "Epoch 2308/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2097 - learning_rate: 3.0433e-05\n",
      "Epoch 2309/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2096 - learning_rate: 3.0433e-05\n",
      "Epoch 2310/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2098 - learning_rate: 3.0433e-05\n",
      "Epoch 2311/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2099 - learning_rate: 3.0433e-05\n",
      "Epoch 2312/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2099 - learning_rate: 3.0433e-05\n",
      "Epoch 2313/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2102 - learning_rate: 3.0433e-05\n",
      "Epoch 2314/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2102 - learning_rate: 3.0433e-05\n",
      "Epoch 2315/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2102 - learning_rate: 3.0433e-05\n",
      "Epoch 2316/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2102 - learning_rate: 3.0433e-05\n",
      "Epoch 2317/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9184 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2102 - learning_rate: 3.0433e-05\n",
      "Epoch 2318/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2105 - learning_rate: 3.0433e-05\n",
      "Epoch 2319/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2107 - learning_rate: 3.0433e-05\n",
      "Epoch 2320/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2110 - learning_rate: 3.0433e-05\n",
      "Epoch 2321/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2107 - learning_rate: 3.0433e-05\n",
      "Epoch 2322/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2106 - learning_rate: 3.0433e-05\n",
      "Epoch 2323/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2106 - learning_rate: 3.0433e-05\n",
      "Epoch 2324/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9037 - loss: 0.2928 - val_accuracy: 0.8947 - val_loss: 2.2109 - learning_rate: 3.0433e-05\n",
      "Epoch 2325/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2107 - learning_rate: 3.0433e-05\n",
      "Epoch 2326/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2110 - learning_rate: 3.0433e-05\n",
      "Epoch 2327/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2108 - learning_rate: 3.0433e-05\n",
      "Epoch 2328/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2661 - val_accuracy: 0.8947 - val_loss: 2.2105 - learning_rate: 3.0433e-05\n",
      "Epoch 2329/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2108 - learning_rate: 3.0433e-05\n",
      "Epoch 2330/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2110 - learning_rate: 3.0433e-05\n",
      "Epoch 2331/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2831 - val_accuracy: 0.8947 - val_loss: 2.2108 - learning_rate: 3.0433e-05\n",
      "Epoch 2332/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2107 - learning_rate: 3.0433e-05\n",
      "Epoch 2333/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2110 - learning_rate: 3.0433e-05\n",
      "Epoch 2334/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2109 - learning_rate: 3.0433e-05\n",
      "Epoch 2335/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2109 - learning_rate: 3.0433e-05\n",
      "Epoch 2336/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2111 - learning_rate: 3.0433e-05\n",
      "Epoch 2337/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2651 - val_accuracy: 0.8947 - val_loss: 2.2112 - learning_rate: 3.0433e-05\n",
      "Epoch 2338/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2111 - learning_rate: 3.0433e-05\n",
      "Epoch 2339/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2112 - learning_rate: 3.0433e-05\n",
      "Epoch 2340/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2942\n",
      "Epoch 2340: ReduceLROnPlateau reducing learning rate to 2.738927651080303e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2114 - learning_rate: 3.0433e-05\n",
      "Epoch 2341/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2114 - learning_rate: 2.7389e-05\n",
      "Epoch 2342/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2116 - learning_rate: 2.7389e-05\n",
      "Epoch 2343/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2114 - learning_rate: 2.7389e-05\n",
      "Epoch 2344/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.2115 - learning_rate: 2.7389e-05\n",
      "Epoch 2345/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2118 - learning_rate: 2.7389e-05\n",
      "Epoch 2346/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2119 - learning_rate: 2.7389e-05\n",
      "Epoch 2347/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2116 - learning_rate: 2.7389e-05\n",
      "Epoch 2348/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2117 - learning_rate: 2.7389e-05\n",
      "Epoch 2349/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2116 - learning_rate: 2.7389e-05\n",
      "Epoch 2350/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9215 - loss: 0.2521 - val_accuracy: 0.8947 - val_loss: 2.2118 - learning_rate: 2.7389e-05\n",
      "Epoch 2351/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2118 - learning_rate: 2.7389e-05\n",
      "Epoch 2352/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2118 - learning_rate: 2.7389e-05\n",
      "Epoch 2353/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2117 - learning_rate: 2.7389e-05\n",
      "Epoch 2354/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.2118 - learning_rate: 2.7389e-05\n",
      "Epoch 2355/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2117 - learning_rate: 2.7389e-05\n",
      "Epoch 2356/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.2121 - learning_rate: 2.7389e-05\n",
      "Epoch 2357/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2683 - val_accuracy: 0.8947 - val_loss: 2.2119 - learning_rate: 2.7389e-05\n",
      "Epoch 2358/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2122 - learning_rate: 2.7389e-05\n",
      "Epoch 2359/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2840 - val_accuracy: 0.8947 - val_loss: 2.2117 - learning_rate: 2.7389e-05\n",
      "Epoch 2360/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2117 - learning_rate: 2.7389e-05\n",
      "Epoch 2361/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2115 - learning_rate: 2.7389e-05\n",
      "Epoch 2362/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2118 - learning_rate: 2.7389e-05\n",
      "Epoch 2363/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9053 - loss: 0.2884 - val_accuracy: 0.8947 - val_loss: 2.2118 - learning_rate: 2.7389e-05\n",
      "Epoch 2364/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2115 - learning_rate: 2.7389e-05\n",
      "Epoch 2365/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9187 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2117 - learning_rate: 2.7389e-05\n",
      "Epoch 2366/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2117 - learning_rate: 2.7389e-05\n",
      "Epoch 2367/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2624 - val_accuracy: 0.8947 - val_loss: 2.2119 - learning_rate: 2.7389e-05\n",
      "Epoch 2368/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2119 - learning_rate: 2.7389e-05\n",
      "Epoch 2369/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2119 - learning_rate: 2.7389e-05\n",
      "Epoch 2370/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2524 - val_accuracy: 0.8947 - val_loss: 2.2120 - learning_rate: 2.7389e-05\n",
      "Epoch 2371/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2121 - learning_rate: 2.7389e-05\n",
      "Epoch 2372/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2122 - learning_rate: 2.7389e-05\n",
      "Epoch 2373/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2550 - val_accuracy: 0.8947 - val_loss: 2.2119 - learning_rate: 2.7389e-05\n",
      "Epoch 2374/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2821 - val_accuracy: 0.8947 - val_loss: 2.2125 - learning_rate: 2.7389e-05\n",
      "Epoch 2375/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2124 - learning_rate: 2.7389e-05\n",
      "Epoch 2376/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2123 - learning_rate: 2.7389e-05\n",
      "Epoch 2377/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2124 - learning_rate: 2.7389e-05\n",
      "Epoch 2378/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2123 - learning_rate: 2.7389e-05\n",
      "Epoch 2379/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2126 - learning_rate: 2.7389e-05\n",
      "Epoch 2380/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.2864 \n",
      "Epoch 2380: ReduceLROnPlateau reducing learning rate to 2.4650348859722725e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2123 - learning_rate: 2.7389e-05\n",
      "Epoch 2381/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2124 - learning_rate: 2.4650e-05\n",
      "Epoch 2382/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9100 - loss: 0.2858 - val_accuracy: 0.8947 - val_loss: 2.2125 - learning_rate: 2.4650e-05\n",
      "Epoch 2383/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2129 - learning_rate: 2.4650e-05\n",
      "Epoch 2384/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2127 - learning_rate: 2.4650e-05\n",
      "Epoch 2385/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2588 - val_accuracy: 0.8947 - val_loss: 2.2126 - learning_rate: 2.4650e-05\n",
      "Epoch 2386/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.2127 - learning_rate: 2.4650e-05\n",
      "Epoch 2387/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2126 - learning_rate: 2.4650e-05\n",
      "Epoch 2388/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2128 - learning_rate: 2.4650e-05\n",
      "Epoch 2389/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9127 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2127 - learning_rate: 2.4650e-05\n",
      "Epoch 2390/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2812 - val_accuracy: 0.8947 - val_loss: 2.2127 - learning_rate: 2.4650e-05\n",
      "Epoch 2391/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2127 - learning_rate: 2.4650e-05\n",
      "Epoch 2392/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2127 - learning_rate: 2.4650e-05\n",
      "Epoch 2393/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2132 - learning_rate: 2.4650e-05\n",
      "Epoch 2394/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2131 - learning_rate: 2.4650e-05\n",
      "Epoch 2395/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2132 - learning_rate: 2.4650e-05\n",
      "Epoch 2396/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2891 - val_accuracy: 0.8947 - val_loss: 2.2132 - learning_rate: 2.4650e-05\n",
      "Epoch 2397/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.2133 - learning_rate: 2.4650e-05\n",
      "Epoch 2398/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2132 - learning_rate: 2.4650e-05\n",
      "Epoch 2399/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2133 - learning_rate: 2.4650e-05\n",
      "Epoch 2400/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2135 - learning_rate: 2.4650e-05\n",
      "Epoch 2401/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2135 - learning_rate: 2.4650e-05\n",
      "Epoch 2402/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2902 - val_accuracy: 0.8947 - val_loss: 2.2134 - learning_rate: 2.4650e-05\n",
      "Epoch 2403/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2711 - val_accuracy: 0.8940 - val_loss: 2.2136 - learning_rate: 2.4650e-05\n",
      "Epoch 2404/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2736 - val_accuracy: 0.8940 - val_loss: 2.2133 - learning_rate: 2.4650e-05\n",
      "Epoch 2405/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2659 - val_accuracy: 0.8940 - val_loss: 2.2136 - learning_rate: 2.4650e-05\n",
      "Epoch 2406/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2736 - val_accuracy: 0.8940 - val_loss: 2.2138 - learning_rate: 2.4650e-05\n",
      "Epoch 2407/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2765 - val_accuracy: 0.8940 - val_loss: 2.2137 - learning_rate: 2.4650e-05\n",
      "Epoch 2408/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2845 - val_accuracy: 0.8947 - val_loss: 2.2138 - learning_rate: 2.4650e-05\n",
      "Epoch 2409/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2680 - val_accuracy: 0.8940 - val_loss: 2.2138 - learning_rate: 2.4650e-05\n",
      "Epoch 2410/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2137 - learning_rate: 2.4650e-05\n",
      "Epoch 2411/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2137 - learning_rate: 2.4650e-05\n",
      "Epoch 2412/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2138 - learning_rate: 2.4650e-05\n",
      "Epoch 2413/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2138 - learning_rate: 2.4650e-05\n",
      "Epoch 2414/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2734 - val_accuracy: 0.8940 - val_loss: 2.2140 - learning_rate: 2.4650e-05\n",
      "Epoch 2415/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2138 - learning_rate: 2.4650e-05\n",
      "Epoch 2416/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2139 - learning_rate: 2.4650e-05\n",
      "Epoch 2417/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.2138 - learning_rate: 2.4650e-05\n",
      "Epoch 2418/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2141 - learning_rate: 2.4650e-05\n",
      "Epoch 2419/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2139 - learning_rate: 2.4650e-05\n",
      "Epoch 2420/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9200 - loss: 0.2655 \n",
      "Epoch 2420: ReduceLROnPlateau reducing learning rate to 2.218531462858664e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2738 - val_accuracy: 0.8940 - val_loss: 2.2139 - learning_rate: 2.4650e-05\n",
      "Epoch 2421/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2596 - val_accuracy: 0.8940 - val_loss: 2.2138 - learning_rate: 2.2185e-05\n",
      "Epoch 2422/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2708 - val_accuracy: 0.8940 - val_loss: 2.2140 - learning_rate: 2.2185e-05\n",
      "Epoch 2423/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2693 - val_accuracy: 0.8940 - val_loss: 2.2140 - learning_rate: 2.2185e-05\n",
      "Epoch 2424/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2626 - val_accuracy: 0.8940 - val_loss: 2.2140 - learning_rate: 2.2185e-05\n",
      "Epoch 2425/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2727 - val_accuracy: 0.8940 - val_loss: 2.2141 - learning_rate: 2.2185e-05\n",
      "Epoch 2426/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2676 - val_accuracy: 0.8940 - val_loss: 2.2141 - learning_rate: 2.2185e-05\n",
      "Epoch 2427/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2535 - val_accuracy: 0.8940 - val_loss: 2.2142 - learning_rate: 2.2185e-05\n",
      "Epoch 2428/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2141 - learning_rate: 2.2185e-05\n",
      "Epoch 2429/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2142 - learning_rate: 2.2185e-05\n",
      "Epoch 2430/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2142 - learning_rate: 2.2185e-05\n",
      "Epoch 2431/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2142 - learning_rate: 2.2185e-05\n",
      "Epoch 2432/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2141 - learning_rate: 2.2185e-05\n",
      "Epoch 2433/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2620 - val_accuracy: 0.8947 - val_loss: 2.2142 - learning_rate: 2.2185e-05\n",
      "Epoch 2434/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2143 - learning_rate: 2.2185e-05\n",
      "Epoch 2435/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2142 - learning_rate: 2.2185e-05\n",
      "Epoch 2436/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.2143 - learning_rate: 2.2185e-05\n",
      "Epoch 2437/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2143 - learning_rate: 2.2185e-05\n",
      "Epoch 2438/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2144 - learning_rate: 2.2185e-05\n",
      "Epoch 2439/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2146 - learning_rate: 2.2185e-05\n",
      "Epoch 2440/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2147 - learning_rate: 2.2185e-05\n",
      "Epoch 2441/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2145 - learning_rate: 2.2185e-05\n",
      "Epoch 2442/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2143 - learning_rate: 2.2185e-05\n",
      "Epoch 2443/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2145 - learning_rate: 2.2185e-05\n",
      "Epoch 2444/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2145 - learning_rate: 2.2185e-05\n",
      "Epoch 2445/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2145 - learning_rate: 2.2185e-05\n",
      "Epoch 2446/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2146 - learning_rate: 2.2185e-05\n",
      "Epoch 2447/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2147 - learning_rate: 2.2185e-05\n",
      "Epoch 2448/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2145 - learning_rate: 2.2185e-05\n",
      "Epoch 2449/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2146 - learning_rate: 2.2185e-05\n",
      "Epoch 2450/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2147 - learning_rate: 2.2185e-05\n",
      "Epoch 2451/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2148 - learning_rate: 2.2185e-05\n",
      "Epoch 2452/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9159 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2150 - learning_rate: 2.2185e-05\n",
      "Epoch 2453/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2150 - learning_rate: 2.2185e-05\n",
      "Epoch 2454/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2151 - learning_rate: 2.2185e-05\n",
      "Epoch 2455/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2869 - val_accuracy: 0.8947 - val_loss: 2.2151 - learning_rate: 2.2185e-05\n",
      "Epoch 2456/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2153 - learning_rate: 2.2185e-05\n",
      "Epoch 2457/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2804 - val_accuracy: 0.8940 - val_loss: 2.2154 - learning_rate: 2.2185e-05\n",
      "Epoch 2458/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2660 - val_accuracy: 0.8940 - val_loss: 2.2153 - learning_rate: 2.2185e-05\n",
      "Epoch 2459/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2152 - learning_rate: 2.2185e-05\n",
      "Epoch 2460/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9233 - loss: 0.2570 \n",
      "Epoch 2460: ReduceLROnPlateau reducing learning rate to 1.9966783656855114e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2153 - learning_rate: 2.2185e-05\n",
      "Epoch 2461/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2154 - learning_rate: 1.9967e-05\n",
      "Epoch 2462/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9111 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2154 - learning_rate: 1.9967e-05\n",
      "Epoch 2463/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2155 - learning_rate: 1.9967e-05\n",
      "Epoch 2464/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2155 - learning_rate: 1.9967e-05\n",
      "Epoch 2465/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2648 - val_accuracy: 0.8940 - val_loss: 2.2156 - learning_rate: 1.9967e-05\n",
      "Epoch 2466/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2467/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2468/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2469/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9107 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2470/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2471/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2472/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2837 - val_accuracy: 0.8947 - val_loss: 2.2156 - learning_rate: 1.9967e-05\n",
      "Epoch 2473/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2156 - learning_rate: 1.9967e-05\n",
      "Epoch 2474/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2155 - learning_rate: 1.9967e-05\n",
      "Epoch 2475/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2156 - learning_rate: 1.9967e-05\n",
      "Epoch 2476/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2477/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2597 - val_accuracy: 0.8947 - val_loss: 2.2156 - learning_rate: 1.9967e-05\n",
      "Epoch 2478/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2156 - learning_rate: 1.9967e-05\n",
      "Epoch 2479/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2480/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2481/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2482/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2483/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2593 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2484/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2485/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2486/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2487/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2488/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2489/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2158 - learning_rate: 1.9967e-05\n",
      "Epoch 2490/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2157 - learning_rate: 1.9967e-05\n",
      "Epoch 2491/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2159 - learning_rate: 1.9967e-05\n",
      "Epoch 2492/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2159 - learning_rate: 1.9967e-05\n",
      "Epoch 2493/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2161 - learning_rate: 1.9967e-05\n",
      "Epoch 2494/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2159 - learning_rate: 1.9967e-05\n",
      "Epoch 2495/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2160 - learning_rate: 1.9967e-05\n",
      "Epoch 2496/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2160 - learning_rate: 1.9967e-05\n",
      "Epoch 2497/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9093 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.2161 - learning_rate: 1.9967e-05\n",
      "Epoch 2498/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2161 - learning_rate: 1.9967e-05\n",
      "Epoch 2499/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2163 - learning_rate: 1.9967e-05\n",
      "Epoch 2500/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 775us/step - accuracy: 0.9183 - loss: 0.2646\n",
      "Epoch 2500: ReduceLROnPlateau reducing learning rate to 1.7970104636333417e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2162 - learning_rate: 1.9967e-05\n",
      "Epoch 2501/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2163 - learning_rate: 1.7970e-05\n",
      "Epoch 2502/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2161 - learning_rate: 1.7970e-05\n",
      "Epoch 2503/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2164 - learning_rate: 1.7970e-05\n",
      "Epoch 2504/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2164 - learning_rate: 1.7970e-05\n",
      "Epoch 2505/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2165 - learning_rate: 1.7970e-05\n",
      "Epoch 2506/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2165 - learning_rate: 1.7970e-05\n",
      "Epoch 2507/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2163 - learning_rate: 1.7970e-05\n",
      "Epoch 2508/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2164 - learning_rate: 1.7970e-05\n",
      "Epoch 2509/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2165 - learning_rate: 1.7970e-05\n",
      "Epoch 2510/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2166 - learning_rate: 1.7970e-05\n",
      "Epoch 2511/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2512/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2513/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2582 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2514/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2515/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2516/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2166 - learning_rate: 1.7970e-05\n",
      "Epoch 2517/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9120 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2169 - learning_rate: 1.7970e-05\n",
      "Epoch 2518/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2519/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9196 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 2.2169 - learning_rate: 1.7970e-05\n",
      "Epoch 2520/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2169 - learning_rate: 1.7970e-05\n",
      "Epoch 2521/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2522/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2613 - val_accuracy: 0.8947 - val_loss: 2.2169 - learning_rate: 1.7970e-05\n",
      "Epoch 2523/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2524/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2168 - learning_rate: 1.7970e-05\n",
      "Epoch 2525/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2168 - learning_rate: 1.7970e-05\n",
      "Epoch 2526/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9159 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2168 - learning_rate: 1.7970e-05\n",
      "Epoch 2527/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2168 - learning_rate: 1.7970e-05\n",
      "Epoch 2528/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2529/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2530/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9126 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2166 - learning_rate: 1.7970e-05\n",
      "Epoch 2531/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2168 - learning_rate: 1.7970e-05\n",
      "Epoch 2532/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2167 - learning_rate: 1.7970e-05\n",
      "Epoch 2533/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2169 - learning_rate: 1.7970e-05\n",
      "Epoch 2534/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2612 - val_accuracy: 0.8947 - val_loss: 2.2169 - learning_rate: 1.7970e-05\n",
      "Epoch 2535/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2170 - learning_rate: 1.7970e-05\n",
      "Epoch 2536/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2170 - learning_rate: 1.7970e-05\n",
      "Epoch 2537/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2825 - val_accuracy: 0.8947 - val_loss: 2.2168 - learning_rate: 1.7970e-05\n",
      "Epoch 2538/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2170 - learning_rate: 1.7970e-05\n",
      "Epoch 2539/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2171 - learning_rate: 1.7970e-05\n",
      "Epoch 2540/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9083 - loss: 0.3024 \n",
      "Epoch 2540: ReduceLROnPlateau reducing learning rate to 1.6173094991245307e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2172 - learning_rate: 1.7970e-05\n",
      "Epoch 2541/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2171 - learning_rate: 1.6173e-05\n",
      "Epoch 2542/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2172 - learning_rate: 1.6173e-05\n",
      "Epoch 2543/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2172 - learning_rate: 1.6173e-05\n",
      "Epoch 2544/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2172 - learning_rate: 1.6173e-05\n",
      "Epoch 2545/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2172 - learning_rate: 1.6173e-05\n",
      "Epoch 2546/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2855 - val_accuracy: 0.8947 - val_loss: 2.2173 - learning_rate: 1.6173e-05\n",
      "Epoch 2547/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2173 - learning_rate: 1.6173e-05\n",
      "Epoch 2548/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2175 - learning_rate: 1.6173e-05\n",
      "Epoch 2549/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2174 - learning_rate: 1.6173e-05\n",
      "Epoch 2550/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2175 - learning_rate: 1.6173e-05\n",
      "Epoch 2551/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2651 - val_accuracy: 0.8947 - val_loss: 2.2176 - learning_rate: 1.6173e-05\n",
      "Epoch 2552/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2176 - learning_rate: 1.6173e-05\n",
      "Epoch 2553/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2175 - learning_rate: 1.6173e-05\n",
      "Epoch 2554/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2175 - learning_rate: 1.6173e-05\n",
      "Epoch 2555/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2556/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2175 - learning_rate: 1.6173e-05\n",
      "Epoch 2557/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2176 - learning_rate: 1.6173e-05\n",
      "Epoch 2558/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2559/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2560/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2176 - learning_rate: 1.6173e-05\n",
      "Epoch 2561/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2176 - learning_rate: 1.6173e-05\n",
      "Epoch 2562/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2563/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2564/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2178 - learning_rate: 1.6173e-05\n",
      "Epoch 2565/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2178 - learning_rate: 1.6173e-05\n",
      "Epoch 2566/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2567/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2568/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2569/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9147 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2177 - learning_rate: 1.6173e-05\n",
      "Epoch 2570/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2178 - learning_rate: 1.6173e-05\n",
      "Epoch 2571/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2179 - learning_rate: 1.6173e-05\n",
      "Epoch 2572/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2844 - val_accuracy: 0.8947 - val_loss: 2.2179 - learning_rate: 1.6173e-05\n",
      "Epoch 2573/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2178 - learning_rate: 1.6173e-05\n",
      "Epoch 2574/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2180 - learning_rate: 1.6173e-05\n",
      "Epoch 2575/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2180 - learning_rate: 1.6173e-05\n",
      "Epoch 2576/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2182 - learning_rate: 1.6173e-05\n",
      "Epoch 2577/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.6173e-05\n",
      "Epoch 2578/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2182 - learning_rate: 1.6173e-05\n",
      "Epoch 2579/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2182 - learning_rate: 1.6173e-05\n",
      "Epoch 2580/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 988us/step - accuracy: 0.9154 - loss: 0.2788\n",
      "Epoch 2580: ReduceLROnPlateau reducing learning rate to 1.4555785492120777e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2182 - learning_rate: 1.6173e-05\n",
      "Epoch 2581/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.4556e-05\n",
      "Epoch 2582/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2184 - learning_rate: 1.4556e-05\n",
      "Epoch 2583/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.4556e-05\n",
      "Epoch 2584/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.4556e-05\n",
      "Epoch 2585/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.4556e-05\n",
      "Epoch 2586/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2184 - learning_rate: 1.4556e-05\n",
      "Epoch 2587/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.4556e-05\n",
      "Epoch 2588/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2566 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.4556e-05\n",
      "Epoch 2589/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2184 - learning_rate: 1.4556e-05\n",
      "Epoch 2590/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9154 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2184 - learning_rate: 1.4556e-05\n",
      "Epoch 2591/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2183 - learning_rate: 1.4556e-05\n",
      "Epoch 2592/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2185 - learning_rate: 1.4556e-05\n",
      "Epoch 2593/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2184 - learning_rate: 1.4556e-05\n",
      "Epoch 2594/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2185 - learning_rate: 1.4556e-05\n",
      "Epoch 2595/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2184 - learning_rate: 1.4556e-05\n",
      "Epoch 2596/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2185 - learning_rate: 1.4556e-05\n",
      "Epoch 2597/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2185 - learning_rate: 1.4556e-05\n",
      "Epoch 2598/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2185 - learning_rate: 1.4556e-05\n",
      "Epoch 2599/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9161 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2186 - learning_rate: 1.4556e-05\n",
      "Epoch 2600/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2186 - learning_rate: 1.4556e-05\n",
      "Epoch 2601/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2186 - learning_rate: 1.4556e-05\n",
      "Epoch 2602/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2649 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2603/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2601 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2604/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2605/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9070 - loss: 0.2901 - val_accuracy: 0.8947 - val_loss: 2.2188 - learning_rate: 1.4556e-05\n",
      "Epoch 2606/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2607/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9099 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2608/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2609/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2610/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2186 - learning_rate: 1.4556e-05\n",
      "Epoch 2611/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2612/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2613/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9108 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2186 - learning_rate: 1.4556e-05\n",
      "Epoch 2614/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2615/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2624 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2616/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2617/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2822 - val_accuracy: 0.8947 - val_loss: 2.2188 - learning_rate: 1.4556e-05\n",
      "Epoch 2618/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2619/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2188 - learning_rate: 1.4556e-05\n",
      "Epoch 2620/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.2803 \n",
      "Epoch 2620: ReduceLROnPlateau reducing learning rate to 1.3100206615490606e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2187 - learning_rate: 1.4556e-05\n",
      "Epoch 2621/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2188 - learning_rate: 1.3100e-05\n",
      "Epoch 2622/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9158 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2623/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2624/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2625/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2189 - learning_rate: 1.3100e-05\n",
      "Epoch 2626/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2189 - learning_rate: 1.3100e-05\n",
      "Epoch 2627/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9170 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2628/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9156 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2629/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9168 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2630/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2191 - learning_rate: 1.3100e-05\n",
      "Epoch 2631/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2844 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2632/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2633/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2617 - val_accuracy: 0.8947 - val_loss: 2.2191 - learning_rate: 1.3100e-05\n",
      "Epoch 2634/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2635/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2190 - learning_rate: 1.3100e-05\n",
      "Epoch 2636/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2191 - learning_rate: 1.3100e-05\n",
      "Epoch 2637/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2191 - learning_rate: 1.3100e-05\n",
      "Epoch 2638/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2191 - learning_rate: 1.3100e-05\n",
      "Epoch 2639/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2192 - learning_rate: 1.3100e-05\n",
      "Epoch 2640/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2191 - learning_rate: 1.3100e-05\n",
      "Epoch 2641/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9047 - loss: 0.2851 - val_accuracy: 0.8947 - val_loss: 2.2192 - learning_rate: 1.3100e-05\n",
      "Epoch 2642/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2191 - learning_rate: 1.3100e-05\n",
      "Epoch 2643/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2192 - learning_rate: 1.3100e-05\n",
      "Epoch 2644/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2192 - learning_rate: 1.3100e-05\n",
      "Epoch 2645/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2193 - learning_rate: 1.3100e-05\n",
      "Epoch 2646/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2622 - val_accuracy: 0.8947 - val_loss: 2.2193 - learning_rate: 1.3100e-05\n",
      "Epoch 2647/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2193 - learning_rate: 1.3100e-05\n",
      "Epoch 2648/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2193 - learning_rate: 1.3100e-05\n",
      "Epoch 2649/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2194 - learning_rate: 1.3100e-05\n",
      "Epoch 2650/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2192 - learning_rate: 1.3100e-05\n",
      "Epoch 2651/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2193 - learning_rate: 1.3100e-05\n",
      "Epoch 2652/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2194 - learning_rate: 1.3100e-05\n",
      "Epoch 2653/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2194 - learning_rate: 1.3100e-05\n",
      "Epoch 2654/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2195 - learning_rate: 1.3100e-05\n",
      "Epoch 2655/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2196 - learning_rate: 1.3100e-05\n",
      "Epoch 2656/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2819 - val_accuracy: 0.8947 - val_loss: 2.2195 - learning_rate: 1.3100e-05\n",
      "Epoch 2657/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9089 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2195 - learning_rate: 1.3100e-05\n",
      "Epoch 2658/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2195 - learning_rate: 1.3100e-05\n",
      "Epoch 2659/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2195 - learning_rate: 1.3100e-05\n",
      "Epoch 2660/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8975 - loss: 0.2795\n",
      "Epoch 2660: ReduceLROnPlateau reducing learning rate to 1.1790186363214161e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2637 - val_accuracy: 0.8947 - val_loss: 2.2196 - learning_rate: 1.3100e-05\n",
      "Epoch 2661/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.2197 - learning_rate: 1.1790e-05\n",
      "Epoch 2662/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2197 - learning_rate: 1.1790e-05\n",
      "Epoch 2663/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2196 - learning_rate: 1.1790e-05\n",
      "Epoch 2664/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2198 - learning_rate: 1.1790e-05\n",
      "Epoch 2665/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.2198 - learning_rate: 1.1790e-05\n",
      "Epoch 2666/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2199 - learning_rate: 1.1790e-05\n",
      "Epoch 2667/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2197 - learning_rate: 1.1790e-05\n",
      "Epoch 2668/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2198 - learning_rate: 1.1790e-05\n",
      "Epoch 2669/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2199 - learning_rate: 1.1790e-05\n",
      "Epoch 2670/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2197 - learning_rate: 1.1790e-05\n",
      "Epoch 2671/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2197 - learning_rate: 1.1790e-05\n",
      "Epoch 2672/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2197 - learning_rate: 1.1790e-05\n",
      "Epoch 2673/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2197 - learning_rate: 1.1790e-05\n",
      "Epoch 2674/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2199 - learning_rate: 1.1790e-05\n",
      "Epoch 2675/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2831 - val_accuracy: 0.8947 - val_loss: 2.2199 - learning_rate: 1.1790e-05\n",
      "Epoch 2676/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2199 - learning_rate: 1.1790e-05\n",
      "Epoch 2677/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.2199 - learning_rate: 1.1790e-05\n",
      "Epoch 2678/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2661 - val_accuracy: 0.8947 - val_loss: 2.2200 - learning_rate: 1.1790e-05\n",
      "Epoch 2679/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2200 - learning_rate: 1.1790e-05\n",
      "Epoch 2680/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2757 - val_accuracy: 0.8940 - val_loss: 2.2200 - learning_rate: 1.1790e-05\n",
      "Epoch 2681/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2693 - val_accuracy: 0.8940 - val_loss: 2.2200 - learning_rate: 1.1790e-05\n",
      "Epoch 2682/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2692 - val_accuracy: 0.8940 - val_loss: 2.2201 - learning_rate: 1.1790e-05\n",
      "Epoch 2683/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2547 - val_accuracy: 0.8940 - val_loss: 2.2201 - learning_rate: 1.1790e-05\n",
      "Epoch 2684/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2733 - val_accuracy: 0.8940 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2685/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2673 - val_accuracy: 0.8940 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2686/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2687/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2201 - learning_rate: 1.1790e-05\n",
      "Epoch 2688/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9146 - loss: 0.2690 - val_accuracy: 0.8940 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2689/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2724 - val_accuracy: 0.8940 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2690/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2672 - val_accuracy: 0.8940 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2691/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2643 - val_accuracy: 0.8940 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2692/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2693/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2694/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2616 - val_accuracy: 0.8940 - val_loss: 2.2202 - learning_rate: 1.1790e-05\n",
      "Epoch 2695/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2696/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2692 - val_accuracy: 0.8940 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2697/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2757 - val_accuracy: 0.8940 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2698/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2687 - val_accuracy: 0.8940 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2699/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2683 - val_accuracy: 0.8940 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2700/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2552 \n",
      "Epoch 2700: ReduceLROnPlateau reducing learning rate to 1.0611167726892746e-05.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.1790e-05\n",
      "Epoch 2701/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2702/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2621 - val_accuracy: 0.8940 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2703/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2711 - val_accuracy: 0.8940 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2704/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2705/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2706/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2707/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2708/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2709/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2710/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2711/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2712/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2713/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2714/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2715/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2716/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2717/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2718/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9054 - loss: 0.2907 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2719/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2720/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2203 - learning_rate: 1.0611e-05\n",
      "Epoch 2721/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2722/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2723/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2204 - learning_rate: 1.0611e-05\n",
      "Epoch 2724/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2206 - learning_rate: 1.0611e-05\n",
      "Epoch 2725/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9172 - loss: 0.2583 - val_accuracy: 0.8947 - val_loss: 2.2206 - learning_rate: 1.0611e-05\n",
      "Epoch 2726/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2206 - learning_rate: 1.0611e-05\n",
      "Epoch 2727/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2205 - learning_rate: 1.0611e-05\n",
      "Epoch 2728/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2206 - learning_rate: 1.0611e-05\n",
      "Epoch 2729/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2205 - learning_rate: 1.0611e-05\n",
      "Epoch 2730/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.2206 - learning_rate: 1.0611e-05\n",
      "Epoch 2731/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2661 - val_accuracy: 0.8947 - val_loss: 2.2206 - learning_rate: 1.0611e-05\n",
      "Epoch 2732/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2207 - learning_rate: 1.0611e-05\n",
      "Epoch 2733/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9112 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2208 - learning_rate: 1.0611e-05\n",
      "Epoch 2734/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2842 - val_accuracy: 0.8947 - val_loss: 2.2208 - learning_rate: 1.0611e-05\n",
      "Epoch 2735/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9109 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2208 - learning_rate: 1.0611e-05\n",
      "Epoch 2736/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 1.0611e-05\n",
      "Epoch 2737/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2574 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 1.0611e-05\n",
      "Epoch 2738/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 1.0611e-05\n",
      "Epoch 2739/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9072 - loss: 0.2893 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 1.0611e-05\n",
      "Epoch 2740/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2710 \n",
      "Epoch 2740: ReduceLROnPlateau reducing learning rate to 9.550050708639902e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 1.0611e-05\n",
      "Epoch 2741/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2742/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2743/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2744/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2604 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2745/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2746/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9183 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2208 - learning_rate: 9.5501e-06\n",
      "Epoch 2747/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2208 - learning_rate: 9.5501e-06\n",
      "Epoch 2748/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2749/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.2208 - learning_rate: 9.5501e-06\n",
      "Epoch 2750/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2751/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2752/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2593 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2753/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9103 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2754/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2755/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2756/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2211 - learning_rate: 9.5501e-06\n",
      "Epoch 2757/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2597 - val_accuracy: 0.8947 - val_loss: 2.2209 - learning_rate: 9.5501e-06\n",
      "Epoch 2758/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2759/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2760/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2761/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2211 - learning_rate: 9.5501e-06\n",
      "Epoch 2762/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2763/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2211 - learning_rate: 9.5501e-06\n",
      "Epoch 2764/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2210 - learning_rate: 9.5501e-06\n",
      "Epoch 2765/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2826 - val_accuracy: 0.8947 - val_loss: 2.2211 - learning_rate: 9.5501e-06\n",
      "Epoch 2766/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2211 - learning_rate: 9.5501e-06\n",
      "Epoch 2767/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2656 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2768/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2769/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2770/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2594 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2771/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2211 - learning_rate: 9.5501e-06\n",
      "Epoch 2772/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2773/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2774/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2775/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2211 - learning_rate: 9.5501e-06\n",
      "Epoch 2776/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9145 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2777/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2778/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2213 - learning_rate: 9.5501e-06\n",
      "Epoch 2779/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2212 - learning_rate: 9.5501e-06\n",
      "Epoch 2780/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9050 - loss: 0.2735 \n",
      "Epoch 2780: ReduceLROnPlateau reducing learning rate to 8.595045801484958e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2845 - val_accuracy: 0.8947 - val_loss: 2.2213 - learning_rate: 9.5501e-06\n",
      "Epoch 2781/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2213 - learning_rate: 8.5950e-06\n",
      "Epoch 2782/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2213 - learning_rate: 8.5950e-06\n",
      "Epoch 2783/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2213 - learning_rate: 8.5950e-06\n",
      "Epoch 2784/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2213 - learning_rate: 8.5950e-06\n",
      "Epoch 2785/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2214 - learning_rate: 8.5950e-06\n",
      "Epoch 2786/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2214 - learning_rate: 8.5950e-06\n",
      "Epoch 2787/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9153 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2214 - learning_rate: 8.5950e-06\n",
      "Epoch 2788/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2214 - learning_rate: 8.5950e-06\n",
      "Epoch 2789/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2820 - val_accuracy: 0.8947 - val_loss: 2.2214 - learning_rate: 8.5950e-06\n",
      "Epoch 2790/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2834 - val_accuracy: 0.8947 - val_loss: 2.2214 - learning_rate: 8.5950e-06\n",
      "Epoch 2791/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2215 - learning_rate: 8.5950e-06\n",
      "Epoch 2792/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2594 - val_accuracy: 0.8947 - val_loss: 2.2214 - learning_rate: 8.5950e-06\n",
      "Epoch 2793/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2215 - learning_rate: 8.5950e-06\n",
      "Epoch 2794/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2588 - val_accuracy: 0.8947 - val_loss: 2.2215 - learning_rate: 8.5950e-06\n",
      "Epoch 2795/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2215 - learning_rate: 8.5950e-06\n",
      "Epoch 2796/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2215 - learning_rate: 8.5950e-06\n",
      "Epoch 2797/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2215 - learning_rate: 8.5950e-06\n",
      "Epoch 2798/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2597 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2799/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2800/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2801/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2652 - val_accuracy: 0.8940 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2802/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2803/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2804/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2839 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2805/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2820 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2806/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2216 - learning_rate: 8.5950e-06\n",
      "Epoch 2807/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2808/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2809/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2810/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2811/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2812/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2813/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9208 - loss: 0.2617 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2814/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2218 - learning_rate: 8.5950e-06\n",
      "Epoch 2815/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2218 - learning_rate: 8.5950e-06\n",
      "Epoch 2816/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2593 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2817/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2818/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2819/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9141 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2820/5000\n",
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9131 - loss: 0.2728  \n",
      "Epoch 2820: ReduceLROnPlateau reducing learning rate to 7.735541385045509e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 8.5950e-06\n",
      "Epoch 2821/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2848 - val_accuracy: 0.8947 - val_loss: 2.2218 - learning_rate: 7.7355e-06\n",
      "Epoch 2822/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9110 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2217 - learning_rate: 7.7355e-06\n",
      "Epoch 2823/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2218 - learning_rate: 7.7355e-06\n",
      "Epoch 2824/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2218 - learning_rate: 7.7355e-06\n",
      "Epoch 2825/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2218 - learning_rate: 7.7355e-06\n",
      "Epoch 2826/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2219 - learning_rate: 7.7355e-06\n",
      "Epoch 2827/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2219 - learning_rate: 7.7355e-06\n",
      "Epoch 2828/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2219 - learning_rate: 7.7355e-06\n",
      "Epoch 2829/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2219 - learning_rate: 7.7355e-06\n",
      "Epoch 2830/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2219 - learning_rate: 7.7355e-06\n",
      "Epoch 2831/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2832/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2833/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2219 - learning_rate: 7.7355e-06\n",
      "Epoch 2834/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2835/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2836/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2837/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2838/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2839/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2840/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9082 - loss: 0.2844 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2841/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2842/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9237 - loss: 0.2525 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2843/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9172 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2844/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2845/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9130 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2846/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2847/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2848/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2849/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9085 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2220 - learning_rate: 7.7355e-06\n",
      "Epoch 2850/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2570 - val_accuracy: 0.8947 - val_loss: 2.2221 - learning_rate: 7.7355e-06\n",
      "Epoch 2851/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2649 - val_accuracy: 0.8947 - val_loss: 2.2222 - learning_rate: 7.7355e-06\n",
      "Epoch 2852/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9133 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2222 - learning_rate: 7.7355e-06\n",
      "Epoch 2853/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2222 - learning_rate: 7.7355e-06\n",
      "Epoch 2854/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2222 - learning_rate: 7.7355e-06\n",
      "Epoch 2855/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2222 - learning_rate: 7.7355e-06\n",
      "Epoch 2856/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2222 - learning_rate: 7.7355e-06\n",
      "Epoch 2857/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2486 - val_accuracy: 0.8947 - val_loss: 2.2222 - learning_rate: 7.7355e-06\n",
      "Epoch 2858/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2835 - val_accuracy: 0.8947 - val_loss: 2.2223 - learning_rate: 7.7355e-06\n",
      "Epoch 2859/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2223 - learning_rate: 7.7355e-06\n",
      "Epoch 2860/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9167 - loss: 0.2592\n",
      "Epoch 2860: ReduceLROnPlateau reducing learning rate to 6.961987492104527e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 7.7355e-06\n",
      "Epoch 2861/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2223 - learning_rate: 6.9620e-06\n",
      "Epoch 2862/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2223 - learning_rate: 6.9620e-06\n",
      "Epoch 2863/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2594 - val_accuracy: 0.8947 - val_loss: 2.2223 - learning_rate: 6.9620e-06\n",
      "Epoch 2864/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2865/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2223 - learning_rate: 6.9620e-06\n",
      "Epoch 2866/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2867/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2868/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2869/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9107 - loss: 0.2865 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2870/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9196 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2871/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2872/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2605 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2873/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2874/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2875/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2876/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2551 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2877/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2878/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9175 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2879/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2593 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2880/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2881/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9202 - loss: 0.2520 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2882/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2843 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2883/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9095 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2224 - learning_rate: 6.9620e-06\n",
      "Epoch 2884/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2885/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2847 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2886/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2887/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2888/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2889/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2226 - learning_rate: 6.9620e-06\n",
      "Epoch 2890/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2622 - val_accuracy: 0.8947 - val_loss: 2.2225 - learning_rate: 6.9620e-06\n",
      "Epoch 2891/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.2226 - learning_rate: 6.9620e-06\n",
      "Epoch 2892/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2226 - learning_rate: 6.9620e-06\n",
      "Epoch 2893/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9195 - loss: 0.2605 - val_accuracy: 0.8947 - val_loss: 2.2226 - learning_rate: 6.9620e-06\n",
      "Epoch 2894/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2226 - learning_rate: 6.9620e-06\n",
      "Epoch 2895/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2226 - learning_rate: 6.9620e-06\n",
      "Epoch 2896/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2226 - learning_rate: 6.9620e-06\n",
      "Epoch 2897/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2649 - val_accuracy: 0.8947 - val_loss: 2.2227 - learning_rate: 6.9620e-06\n",
      "Epoch 2898/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.2227 - learning_rate: 6.9620e-06\n",
      "Epoch 2899/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2844 - val_accuracy: 0.8947 - val_loss: 2.2227 - learning_rate: 6.9620e-06\n",
      "Epoch 2900/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8908 - loss: 0.3160 \n",
      "Epoch 2900: ReduceLROnPlateau reducing learning rate to 6.265788579185028e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2227 - learning_rate: 6.9620e-06\n",
      "Epoch 2901/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2227 - learning_rate: 6.2658e-06\n",
      "Epoch 2902/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2228 - learning_rate: 6.2658e-06\n",
      "Epoch 2903/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2612 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2904/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2228 - learning_rate: 6.2658e-06\n",
      "Epoch 2905/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2228 - learning_rate: 6.2658e-06\n",
      "Epoch 2906/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2907/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2908/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9113 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2909/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2910/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2805 - val_accuracy: 0.8947 - val_loss: 2.2230 - learning_rate: 6.2658e-06\n",
      "Epoch 2911/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2912/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2913/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2914/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2915/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2228 - learning_rate: 6.2658e-06\n",
      "Epoch 2916/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2917/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2918/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2604 - val_accuracy: 0.8947 - val_loss: 2.2228 - learning_rate: 6.2658e-06\n",
      "Epoch 2919/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2229 - learning_rate: 6.2658e-06\n",
      "Epoch 2920/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2230 - learning_rate: 6.2658e-06\n",
      "Epoch 2921/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2230 - learning_rate: 6.2658e-06\n",
      "Epoch 2922/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2230 - learning_rate: 6.2658e-06\n",
      "Epoch 2923/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2563 - val_accuracy: 0.8947 - val_loss: 2.2231 - learning_rate: 6.2658e-06\n",
      "Epoch 2924/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2621 - val_accuracy: 0.8947 - val_loss: 2.2231 - learning_rate: 6.2658e-06\n",
      "Epoch 2925/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2731 - val_accuracy: 0.8947 - val_loss: 2.2230 - learning_rate: 6.2658e-06\n",
      "Epoch 2926/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2231 - learning_rate: 6.2658e-06\n",
      "Epoch 2927/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2231 - learning_rate: 6.2658e-06\n",
      "Epoch 2928/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2929/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2930/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2931/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2932/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2933/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2934/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2935/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2936/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2231 - learning_rate: 6.2658e-06\n",
      "Epoch 2937/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2938/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2939/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2940/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.8925 - loss: 0.3195 \n",
      "Epoch 2940: ReduceLROnPlateau reducing learning rate to 5.639209803121048e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9088 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 6.2658e-06\n",
      "Epoch 2941/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2942/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2943/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2944/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2945/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2946/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2611 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2947/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2948/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2949/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2950/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2232 - learning_rate: 5.6392e-06\n",
      "Epoch 2951/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2952/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2953/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2954/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2955/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2956/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2957/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2600 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2958/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2597 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2959/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2960/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2961/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2233 - learning_rate: 5.6392e-06\n",
      "Epoch 2962/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2963/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2964/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2965/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2966/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2967/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2968/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2969/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2970/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2589 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2971/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2972/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2973/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2974/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2975/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2976/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2234 - learning_rate: 5.6392e-06\n",
      "Epoch 2977/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.6392e-06\n",
      "Epoch 2978/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.6392e-06\n",
      "Epoch 2979/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.6392e-06\n",
      "Epoch 2980/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9200 - loss: 0.2671 \n",
      "Epoch 2980: ReduceLROnPlateau reducing learning rate to 5.075289027445251e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2645 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.6392e-06\n",
      "Epoch 2981/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2982/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2983/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2984/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2985/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2986/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2987/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2988/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2989/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2990/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2991/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2992/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2993/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9072 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2235 - learning_rate: 5.0753e-06\n",
      "Epoch 2994/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2995/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2996/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2997/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2998/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 2999/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3000/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3001/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.2843 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3002/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3003/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3004/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9180 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3005/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3006/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3007/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3008/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3009/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3010/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3011/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3012/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3013/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3014/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3015/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3016/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2236 - learning_rate: 5.0753e-06\n",
      "Epoch 3017/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3018/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3019/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 5.0753e-06\n",
      "Epoch 3020/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9025 - loss: 0.2886 \n",
      "Epoch 3020: ReduceLROnPlateau reducing learning rate to 4.567760288409772e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2237 - learning_rate: 5.0753e-06\n",
      "Epoch 3021/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9155 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3022/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3023/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3024/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9081 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3025/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3026/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3027/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2617 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3028/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3029/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3030/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3031/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3032/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3033/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3034/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3035/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3036/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3037/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3038/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9189 - loss: 0.2624 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3039/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3040/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2543 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3041/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3042/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2238 - learning_rate: 4.5678e-06\n",
      "Epoch 3043/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3044/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2572 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3045/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3046/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3047/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3048/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3049/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3050/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.2239 - learning_rate: 4.5678e-06\n",
      "Epoch 3051/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3052/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3053/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3054/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2568 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3055/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3056/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3057/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9134 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3058/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3059/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.5678e-06\n",
      "Epoch 3060/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.2371 \n",
      "Epoch 3060: ReduceLROnPlateau reducing learning rate to 4.110984218641534e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.5678e-06\n",
      "Epoch 3061/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2240 - learning_rate: 4.1110e-06\n",
      "Epoch 3062/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3063/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2857 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3064/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3065/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3066/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3067/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9173 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3068/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9144 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3069/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3070/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3071/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2241 - learning_rate: 4.1110e-06\n",
      "Epoch 3072/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3073/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3074/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3075/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3076/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3077/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3078/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3079/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3080/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3081/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3082/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3083/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3084/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9236 - loss: 0.2461 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3085/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3086/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3087/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3088/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3089/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3090/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9123 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3091/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3092/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3093/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3094/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3095/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3096/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3097/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3098/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3099/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3100/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 852us/step - accuracy: 0.9125 - loss: 0.2714\n",
      "Epoch 3100: ReduceLROnPlateau reducing learning rate to 3.6998858377046417e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 4.1110e-06\n",
      "Epoch 3101/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3102/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9153 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3103/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3104/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2843 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3105/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3106/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3107/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3108/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3109/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2628 - val_accuracy: 0.8947 - val_loss: 2.2242 - learning_rate: 3.6999e-06\n",
      "Epoch 3110/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3111/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3112/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3113/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3114/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3115/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3116/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3117/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3118/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3119/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3120/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2616 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3121/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3122/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3123/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2546 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3124/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3125/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3126/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3127/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2598 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3128/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3129/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3130/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3131/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3132/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3133/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3134/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3135/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3136/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.6999e-06\n",
      "Epoch 3137/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.6999e-06\n",
      "Epoch 3138/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.6999e-06\n",
      "Epoch 3139/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2616 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3140/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9150 - loss: 0.2836 \n",
      "Epoch 3140: ReduceLROnPlateau reducing learning rate to 3.3298972539341776e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2243 - learning_rate: 3.6999e-06\n",
      "Epoch 3141/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3142/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3143/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3144/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3145/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3146/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9070 - loss: 0.2879 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3147/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3148/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3149/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3150/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3151/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3152/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3153/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3154/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3155/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3156/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3157/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3158/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3159/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3160/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3161/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3162/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3163/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3164/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2620 - val_accuracy: 0.8947 - val_loss: 2.2244 - learning_rate: 3.3299e-06\n",
      "Epoch 3165/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3166/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3167/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3168/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3169/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2594 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3170/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3171/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3172/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3173/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3174/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3175/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 3.3299e-06\n",
      "Epoch 3176/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2649 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 3.3299e-06\n",
      "Epoch 3177/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3178/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2616 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 3.3299e-06\n",
      "Epoch 3179/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 3.3299e-06\n",
      "Epoch 3180/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9275 - loss: 0.2304 \n",
      "Epoch 3180: ReduceLROnPlateau reducing learning rate to 2.99690752854076e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2587 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 3.3299e-06\n",
      "Epoch 3181/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3182/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9081 - loss: 0.2825 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3183/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2597 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3184/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3185/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3186/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9153 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3187/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3188/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3189/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3190/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3191/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3192/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3193/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9122 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 2.9969e-06\n",
      "Epoch 3194/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2245 - learning_rate: 2.9969e-06\n",
      "Epoch 3195/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3196/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3197/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3198/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9174 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3199/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3200/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3201/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3202/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2612 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3203/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3204/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9195 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3205/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3206/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3207/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3208/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3209/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3210/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.9969e-06\n",
      "Epoch 3211/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3212/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3213/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3214/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9121 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3215/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3216/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9084 - loss: 0.2817 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.9969e-06\n",
      "Epoch 3217/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.9969e-06\n",
      "Epoch 3218/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3219/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2582 - val_accuracy: 0.8947 - val_loss: 2.2246 - learning_rate: 2.9969e-06\n",
      "Epoch 3220/5000\n",
      "\u001b[1m 3/24\u001b[0m \u001b[32m━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.3114\n",
      "Epoch 3220: ReduceLROnPlateau reducing learning rate to 2.697216837077576e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9047 - loss: 0.2837 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.9969e-06\n",
      "Epoch 3221/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3222/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3223/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3224/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3225/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3226/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3227/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2611 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3228/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3229/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3230/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3231/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9134 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3232/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3233/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3234/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3235/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3236/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3237/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3238/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3239/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2817 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3240/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2637 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3241/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3242/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3243/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2247 - learning_rate: 2.6972e-06\n",
      "Epoch 3244/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3245/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3246/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3247/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3248/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3249/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2580 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3250/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3251/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9143 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3252/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3253/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3254/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3255/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3256/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3257/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3258/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3259/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3260/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8958 - loss: 0.2658 \n",
      "Epoch 3260: ReduceLROnPlateau reducing learning rate to 2.427495132906188e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2604 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.6972e-06\n",
      "Epoch 3261/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3262/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3263/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3264/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3265/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3266/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3267/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3268/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2731 - val_accuracy: 0.8947 - val_loss: 2.2248 - learning_rate: 2.4275e-06\n",
      "Epoch 3269/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9177 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3270/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3271/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3272/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3273/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2651 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3274/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3275/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9132 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3276/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2592 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3277/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3278/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3279/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2873 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3280/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2565 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3281/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3282/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3283/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2603 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3284/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3285/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3286/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3287/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3288/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3289/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9203 - loss: 0.2590 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3290/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3291/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3292/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3293/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3294/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3295/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3296/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3297/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3298/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3299/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9110 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.4275e-06\n",
      "Epoch 3300/5000\n",
      "\u001b[1m 5/24\u001b[0m \u001b[32m━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2503\n",
      "Epoch 3300: ReduceLROnPlateau reducing learning rate to 2.184745517297415e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.4275e-06\n",
      "Epoch 3301/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3302/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.1847e-06\n",
      "Epoch 3303/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3304/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.1847e-06\n",
      "Epoch 3305/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3306/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2249 - learning_rate: 2.1847e-06\n",
      "Epoch 3307/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3308/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3309/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3310/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3311/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3312/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3313/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3314/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3315/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3316/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3317/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9130 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3318/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9143 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3319/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3320/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3321/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3322/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3323/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9119 - loss: 0.2821 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3324/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3325/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3326/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9108 - loss: 0.2837 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3327/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3328/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2867 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3329/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3330/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3331/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3332/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3333/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3334/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3335/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2250 - learning_rate: 2.1847e-06\n",
      "Epoch 3336/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 2.1847e-06\n",
      "Epoch 3337/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 2.1847e-06\n",
      "Epoch 3338/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 2.1847e-06\n",
      "Epoch 3339/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9158 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 2.1847e-06\n",
      "Epoch 3340/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9208 - loss: 0.2302 \n",
      "Epoch 3340: ReduceLROnPlateau reducing learning rate to 1.9662708837131506e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 2.1847e-06\n",
      "Epoch 3341/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3342/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3343/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3344/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3345/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3346/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2621 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3347/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3348/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3349/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3350/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3351/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3352/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2645 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3353/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2637 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3354/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3355/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3356/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3357/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3358/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3359/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3360/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3361/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3362/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3363/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9116 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3364/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.2898 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3365/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3366/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3367/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3368/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3369/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3370/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9176 - loss: 0.2624 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3371/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2848 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3372/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9096 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3373/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3374/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3375/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2251 - learning_rate: 1.9663e-06\n",
      "Epoch 3376/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3377/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3378/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3379/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3380/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9225 - loss: 0.2673\n",
      "Epoch 3380: ReduceLROnPlateau reducing learning rate to 1.769643836269097e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.9663e-06\n",
      "Epoch 3381/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3382/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3383/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3384/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3385/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.2819 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3386/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3387/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3388/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3389/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3390/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2852 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3391/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3392/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3393/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9049 - loss: 0.2881 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3394/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9076 - loss: 0.2910 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3395/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3396/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3397/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3398/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3399/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3400/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3401/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3402/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3403/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3404/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3405/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3406/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9165 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3407/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9128 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3408/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3409/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3410/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3411/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3412/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3413/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3414/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2252 - learning_rate: 1.7696e-06\n",
      "Epoch 3415/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3416/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3417/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9129 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3418/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3419/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2731 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3420/5000\n",
      "\u001b[1m 4/24\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2828 \n",
      "Epoch 3420: ReduceLROnPlateau reducing learning rate to 1.5926794731058181e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.7696e-06\n",
      "Epoch 3421/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3422/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2839 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3423/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3424/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3425/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9169 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3426/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3427/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2613 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3428/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3429/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3430/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3431/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3432/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3433/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2253 - learning_rate: 1.5927e-06\n",
      "Epoch 3434/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3435/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3436/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3437/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9041 - loss: 0.2939 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3438/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3439/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2579 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3440/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3441/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2589 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3442/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3443/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2568 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3444/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3445/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9118 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3446/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3447/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9207 - loss: 0.2600 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3448/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3449/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3450/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3451/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3452/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3453/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3454/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3455/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3456/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3457/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2608 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3458/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9216 - loss: 0.2496 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3459/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3460/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9100 - loss: 0.3111 \n",
      "Epoch 3460: ReduceLROnPlateau reducing learning rate to 1.433411546258867e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.2254 - learning_rate: 1.5927e-06\n",
      "Epoch 3461/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3462/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3463/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3464/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9200 - loss: 0.2569 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3465/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3466/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3467/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3468/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3469/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3470/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3471/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3472/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3473/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3474/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3475/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3476/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9215 - loss: 0.2498 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3477/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3478/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3479/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3480/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3481/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2645 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3482/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3483/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3484/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3485/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3486/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2598 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3487/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3488/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3489/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3490/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3491/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3492/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3493/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3494/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3495/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9163 - loss: 0.2567 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3496/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3497/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3498/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3499/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.4334e-06\n",
      "Epoch 3500/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 871us/step - accuracy: 0.9158 - loss: 0.2554\n",
      "Epoch 3500: ReduceLROnPlateau reducing learning rate to 1.2900703609375342e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.4334e-06\n",
      "Epoch 3501/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2255 - learning_rate: 1.2901e-06\n",
      "Epoch 3502/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3503/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3504/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9091 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3505/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3506/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3507/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3508/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3509/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3510/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2887 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3511/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3512/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3513/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9136 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3514/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3515/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3516/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3517/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3518/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3519/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2509 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3520/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3521/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3522/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9129 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3523/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3524/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2817 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3525/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9136 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3526/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3527/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2820 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3528/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3529/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3530/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3531/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3532/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3533/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3534/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3535/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3536/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9180 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3537/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3538/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3539/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3540/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9300 - loss: 0.2281 \n",
      "Epoch 3540: ReduceLROnPlateau reducing learning rate to 1.161063335075596e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.2901e-06\n",
      "Epoch 3541/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3542/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3543/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3544/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3545/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3546/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3547/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3548/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3549/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3550/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3551/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9165 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3552/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3553/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3554/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3555/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3556/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3557/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3558/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2844 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3559/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3560/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3561/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3562/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3563/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2628 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3564/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3565/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3566/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3567/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2598 - val_accuracy: 0.8947 - val_loss: 2.2256 - learning_rate: 1.1611e-06\n",
      "Epoch 3568/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3569/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2849 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3570/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9111 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3571/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3572/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2834 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3573/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3574/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2622 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3575/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3576/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3577/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3578/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3579/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3580/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9250 - loss: 0.2350 \n",
      "Epoch 3580: ReduceLROnPlateau reducing learning rate to 1.0449569913362212e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.1611e-06\n",
      "Epoch 3581/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9085 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3582/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3583/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3584/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2656 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3585/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3586/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3587/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3588/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3589/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9058 - loss: 0.2876 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3590/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9071 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3591/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3592/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3593/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3594/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3595/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9071 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3596/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3597/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3598/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2589 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3599/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3600/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3601/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3602/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3603/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3604/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3605/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3606/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3607/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2839 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3608/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3609/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2860 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3610/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3611/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3612/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3613/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3614/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2842 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3615/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3616/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3617/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3618/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3619/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9157 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3620/5000\n",
      "\u001b[1m 2/24\u001b[0m \u001b[32m━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9242 - loss: 0.2341\n",
      "Epoch 3620: ReduceLROnPlateau reducing learning rate to 1e-06.\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0450e-06\n",
      "Epoch 3621/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3622/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3623/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3624/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3625/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2811 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3626/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3627/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2637 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3628/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3629/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9094 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3630/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3631/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3632/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9061 - loss: 0.2943 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3633/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3634/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2582 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3635/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3636/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3637/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3638/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3639/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3640/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3641/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3642/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3643/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3644/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3645/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3646/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3647/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3648/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2257 - learning_rate: 1.0000e-06\n",
      "Epoch 3649/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3650/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3651/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3652/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2603 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3653/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3654/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3655/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3656/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9144 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3657/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3658/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2621 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3659/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3660/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3661/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3662/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3663/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3664/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3665/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3666/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9122 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3667/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3668/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3669/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3670/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3671/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3672/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3673/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3674/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3675/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3676/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3677/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3678/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3679/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3680/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3681/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3682/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3683/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3684/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3685/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3686/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3687/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2568 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3688/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3689/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3690/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2820 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3691/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3692/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3693/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2812 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3694/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2618 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3695/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3696/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3697/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9156 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3698/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3699/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3700/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3701/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3702/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3703/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3704/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2683 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3705/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2600 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3706/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9133 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3707/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2560 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3708/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3709/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9115 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3710/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3711/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.2622 - val_accuracy: 0.8947 - val_loss: 2.2258 - learning_rate: 1.0000e-06\n",
      "Epoch 3712/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9117 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3713/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3714/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2637 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3715/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3716/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2661 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3717/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3718/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3719/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2799 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3720/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3721/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2891 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3722/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3723/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3724/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3725/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3726/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2639 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3727/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3728/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3729/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3730/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3731/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3732/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3733/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3734/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3735/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3736/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3737/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3738/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2731 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3739/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2940 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3740/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3741/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3742/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3743/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2620 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3744/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3745/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3746/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3747/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3748/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9121 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3749/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3750/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2599 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3751/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3752/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3753/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3754/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9168 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3755/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3756/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3757/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3758/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3759/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3760/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2859 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3761/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3762/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3763/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9120 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3764/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2259 - learning_rate: 1.0000e-06\n",
      "Epoch 3765/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2596 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3766/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3767/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3768/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9152 - loss: 0.2683 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3769/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9105 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3770/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3771/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9169 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3772/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2819 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3773/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2628 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3774/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3775/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9080 - loss: 0.2845 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3776/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3777/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3778/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3779/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9191 - loss: 0.2622 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3780/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3781/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3782/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3783/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3784/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3785/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2584 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3786/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3787/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9132 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3788/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3789/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2610 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3790/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3791/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3792/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3793/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3794/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3795/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2651 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3796/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3797/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9177 - loss: 0.2579 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3798/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2596 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3799/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9099 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3800/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3801/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2834 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3802/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2812 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3803/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3804/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3805/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9069 - loss: 0.2934 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3806/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3807/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2835 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3808/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9194 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3809/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3810/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3811/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3812/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3813/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9188 - loss: 0.2607 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3814/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2881 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3815/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3816/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3817/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3818/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3819/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2564 - val_accuracy: 0.8947 - val_loss: 2.2260 - learning_rate: 1.0000e-06\n",
      "Epoch 3820/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3821/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3822/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9087 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3823/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3824/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2824 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3825/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3826/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3827/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3828/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3829/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3830/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3831/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9106 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3832/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3833/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3834/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3835/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3836/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3837/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2821 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3838/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3839/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3840/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3841/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9120 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3842/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3843/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3844/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2844 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3845/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3846/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2617 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3847/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3848/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3849/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3850/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3851/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3852/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3853/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3854/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3855/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3856/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2596 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3857/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3858/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9158 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3859/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3860/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9148 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3861/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2530 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3862/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2878 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3863/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3864/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3865/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3866/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3867/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3868/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3869/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3870/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3871/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3872/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3873/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3874/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3875/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3876/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9116 - loss: 0.2811 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3877/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3878/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3879/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2840 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3880/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3881/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3882/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2612 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3883/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3884/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3885/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3886/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3887/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3888/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3889/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2261 - learning_rate: 1.0000e-06\n",
      "Epoch 3890/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3891/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3892/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3893/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3894/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9104 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3895/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2811 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3896/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3897/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2853 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3898/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3899/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2906 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3900/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3901/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9163 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3902/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2584 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3903/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3904/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3905/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3906/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3907/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3908/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3909/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3910/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3911/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3912/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3913/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3914/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3915/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3916/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3917/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9201 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3918/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3919/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3920/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3921/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2590 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3922/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3923/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3924/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3925/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3926/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3927/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3928/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2596 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3929/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3930/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3931/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2863 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3932/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2628 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3933/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2822 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3934/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3935/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2262 - learning_rate: 1.0000e-06\n",
      "Epoch 3936/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3937/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3938/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3939/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3940/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3941/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3942/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3943/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3944/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9145 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3945/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3946/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3947/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3948/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3949/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3950/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3951/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3952/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2552 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3953/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2824 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3954/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3955/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3956/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3957/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3958/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3959/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3960/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9157 - loss: 0.2618 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3961/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3962/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3963/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3964/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9178 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3965/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3966/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3967/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3968/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9160 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3969/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3970/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3971/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3972/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3973/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3974/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3975/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3976/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9142 - loss: 0.2656 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3977/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3978/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9114 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3979/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2603 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3980/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3981/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3982/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9222 - loss: 0.2583 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3983/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3984/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3985/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3986/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2637 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3987/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3988/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9130 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3989/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3990/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3991/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3992/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2847 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3993/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3994/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3995/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3996/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2586 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3997/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3998/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 3999/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4000/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4001/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4002/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9174 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4003/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4004/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4005/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9088 - loss: 0.2866 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4006/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2683 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4007/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4008/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2586 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4009/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4010/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4011/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9105 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4012/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4013/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4014/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4015/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4016/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4017/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4018/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4019/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4020/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2822 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4021/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4022/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4023/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2817 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4024/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4025/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2883 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4026/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4027/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4028/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2595 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4029/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9156 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4030/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4031/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2596 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4032/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4033/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4034/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4035/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2860 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4036/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4037/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9160 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4038/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4039/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4040/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2890 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4041/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4042/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4043/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4044/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4045/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4046/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4047/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4048/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4049/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4050/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4051/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4052/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2825 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4053/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4054/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4055/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9100 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4056/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2889 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4057/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2811 - val_accuracy: 0.8947 - val_loss: 2.2263 - learning_rate: 1.0000e-06\n",
      "Epoch 4058/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4059/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9129 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4060/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4061/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4062/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4063/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4064/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9147 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4065/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4066/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4067/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4068/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2789 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4069/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4070/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4071/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4072/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9164 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4073/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9050 - loss: 0.2960 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4074/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4075/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4076/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.2906 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4077/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4078/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9192 - loss: 0.2550 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4079/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4080/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4081/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4082/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4083/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4084/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4085/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4086/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4087/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4088/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2612 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4089/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9141 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4090/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4091/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4092/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4093/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4094/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2680 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4095/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4096/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9091 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4097/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4098/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2615 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4099/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4100/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4101/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4102/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4103/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4104/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4105/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4106/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4107/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4108/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4109/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4110/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4111/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9142 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4112/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4113/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4114/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4115/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2616 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4116/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4117/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2810 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4118/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4119/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4120/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9062 - loss: 0.2871 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4121/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9189 - loss: 0.2572 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4122/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4123/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2854 - val_accuracy: 0.8947 - val_loss: 2.2264 - learning_rate: 1.0000e-06\n",
      "Epoch 4124/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4125/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4126/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4127/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9093 - loss: 0.2875 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4128/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4129/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4130/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9140 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4131/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4132/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4133/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4134/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4135/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4136/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4137/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9177 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4138/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2817 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4139/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4140/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4141/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4142/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4143/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4144/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2855 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4145/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4146/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4147/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4148/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4149/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4150/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2565 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4151/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9204 - loss: 0.2603 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4152/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9125 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4153/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9104 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4154/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9130 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4155/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4156/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4157/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4158/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2820 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4159/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9104 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4160/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4161/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4162/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4163/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4164/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4165/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9175 - loss: 0.2645 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4166/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4167/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4168/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4169/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4170/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4171/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4172/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2570 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4173/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4174/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4175/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4176/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9077 - loss: 0.2893 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4177/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4178/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4179/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4180/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4181/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9143 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4182/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2610 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4183/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4184/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9120 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4185/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4186/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9057 - loss: 0.2881 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4187/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2545 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4188/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4189/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4190/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4191/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9115 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4192/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9206 - loss: 0.2576 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4193/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4194/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4195/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2265 - learning_rate: 1.0000e-06\n",
      "Epoch 4196/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4197/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4198/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4199/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4200/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9142 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4201/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4202/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4203/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2683 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4204/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4205/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4206/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2825 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4207/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9119 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4208/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4209/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2607 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4210/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4211/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4212/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4213/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4214/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2811 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4215/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2605 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4216/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9095 - loss: 0.2829 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4217/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4218/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4219/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9178 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4220/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4221/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4222/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4223/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4224/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9099 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4225/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4226/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4227/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4228/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9211 - loss: 0.2569 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4229/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4230/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4231/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4232/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9169 - loss: 0.2612 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4233/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4234/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9164 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4235/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4236/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9136 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4237/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4238/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9133 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4239/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9155 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4240/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4241/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9149 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4242/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9152 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4243/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4244/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4245/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4246/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4247/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4248/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2656 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4249/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4250/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4251/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4252/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9104 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4253/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4254/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4255/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4256/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4257/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4258/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9122 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4259/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4260/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4261/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4262/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9124 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4263/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9182 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4264/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4265/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4266/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2846 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4267/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4268/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9175 - loss: 0.2625 - val_accuracy: 0.8947 - val_loss: 2.2266 - learning_rate: 1.0000e-06\n",
      "Epoch 4269/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4270/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4271/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4272/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2605 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4273/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4274/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4275/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4276/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2825 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4277/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2580 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4278/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4279/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4280/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4281/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4282/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2612 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4283/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4284/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4285/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4286/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4287/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4288/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4289/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4290/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4291/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4292/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9193 - loss: 0.2599 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4293/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4294/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4295/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4296/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4297/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2863 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4298/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4299/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4300/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4301/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9190 - loss: 0.2576 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4302/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4303/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4304/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9208 - loss: 0.2518 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4305/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4306/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2547 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4307/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4308/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4309/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4310/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4311/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4312/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4313/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4314/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4315/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4316/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4317/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9088 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4318/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4319/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9139 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4320/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9179 - loss: 0.2604 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4321/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4322/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4323/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9144 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4324/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4325/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9072 - loss: 0.2819 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4326/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4327/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4328/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4329/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4330/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4331/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4332/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4333/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2553 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4334/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9116 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4335/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4336/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2601 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4337/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4338/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4339/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4340/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4341/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2855 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4342/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4343/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4344/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9114 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4345/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4346/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9150 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4347/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4348/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2851 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4349/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4350/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4351/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9154 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4352/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4353/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9101 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4354/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9187 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4355/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4356/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4357/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4358/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4359/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9164 - loss: 0.2622 - val_accuracy: 0.8947 - val_loss: 2.2267 - learning_rate: 1.0000e-06\n",
      "Epoch 4360/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4361/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4362/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9095 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4363/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4364/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4365/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4366/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9139 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4367/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4368/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4369/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4370/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4371/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2620 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4372/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4373/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4374/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2726 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4375/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2898 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4376/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9160 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4377/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4378/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4379/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4380/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4381/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4382/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4383/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9192 - loss: 0.2566 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4384/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.2847 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4385/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4386/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4387/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4388/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4389/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4390/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4391/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4392/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4393/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4394/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9087 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4395/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4396/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4397/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4398/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4399/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9150 - loss: 0.2622 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4400/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2603 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4401/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4402/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4403/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4404/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4405/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4406/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4407/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4408/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2842 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4409/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4410/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4411/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4412/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4413/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4414/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4415/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4416/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4417/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2713 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4418/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4419/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4420/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4421/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4422/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4423/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4424/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9075 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4425/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4426/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4427/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4428/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4429/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2760 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4430/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9130 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4431/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2778 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4432/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9097 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4433/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4434/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2508 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4435/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4436/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4437/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4438/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4439/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4440/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4441/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4442/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4443/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4444/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4445/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4446/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4447/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2837 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4448/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2797 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4449/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2268 - learning_rate: 1.0000e-06\n",
      "Epoch 4450/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9103 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4451/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4452/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4453/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4454/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4455/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2661 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4456/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4457/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4458/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4459/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4460/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9160 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4461/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4462/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4463/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.2624 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4464/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4465/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9053 - loss: 0.2845 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4466/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4467/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2605 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4468/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4469/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4470/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4471/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2939 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4472/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2704 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4473/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4474/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4475/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9085 - loss: 0.2896 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4476/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4477/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9201 - loss: 0.2594 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4478/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4479/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2826 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4480/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2862 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4481/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9113 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4482/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4483/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4484/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4485/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4486/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4487/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4488/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2825 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4489/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2683 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4490/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4491/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4492/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9081 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4493/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4494/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4495/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9204 - loss: 0.2545 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4496/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4497/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9118 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4498/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2710 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4499/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4500/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2782 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4501/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4502/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9137 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4503/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4504/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4505/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9183 - loss: 0.2582 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4506/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2771 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4507/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9116 - loss: 0.2800 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4508/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9043 - loss: 0.2865 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4509/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2779 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4510/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4511/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9137 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4512/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9105 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4513/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4514/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4515/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9124 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4516/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4517/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9102 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4518/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4519/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4520/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.2539 - val_accuracy: 0.8947 - val_loss: 2.2269 - learning_rate: 1.0000e-06\n",
      "Epoch 4521/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9202 - loss: 0.2629 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4522/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2844 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4523/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9181 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4524/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9094 - loss: 0.2843 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4525/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4526/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4527/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4528/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4529/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2620 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4530/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9151 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4531/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2627 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4532/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2805 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4533/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4534/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9194 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4535/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9128 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4536/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2607 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4537/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4538/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4539/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9149 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4540/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9180 - loss: 0.2617 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4541/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9121 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4542/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9053 - loss: 0.2939 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4543/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4544/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4545/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4546/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4547/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4548/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.2596 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4549/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9141 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4550/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9117 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4551/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4552/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2702 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4553/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9181 - loss: 0.2557 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4554/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4555/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4556/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4557/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4558/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4559/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4560/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4561/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9108 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4562/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9166 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4563/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4564/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9088 - loss: 0.2853 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4565/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9094 - loss: 0.2754 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4566/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2758 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4567/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4568/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4569/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9113 - loss: 0.2822 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4570/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9090 - loss: 0.2788 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4571/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9174 - loss: 0.2575 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4572/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4573/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4574/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4575/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4576/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2786 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4577/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4578/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4579/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4580/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9067 - loss: 0.2891 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4581/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4582/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4583/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4584/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4585/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9098 - loss: 0.2853 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4586/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4587/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9202 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4588/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4589/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4590/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4591/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9112 - loss: 0.2781 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4592/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4593/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2832 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4594/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4595/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2753 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4596/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2740 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4597/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4598/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4599/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4600/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9128 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4601/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4602/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4603/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4604/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4605/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9090 - loss: 0.2827 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4606/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2775 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4607/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9092 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4608/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9167 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4609/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9188 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4610/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4611/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4612/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2796 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4613/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4614/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9076 - loss: 0.2884 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4615/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9166 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4616/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4617/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4618/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2270 - learning_rate: 1.0000e-06\n",
      "Epoch 4619/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2725 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4620/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4621/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4622/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4623/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4624/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4625/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2663 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4626/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9138 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4627/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9148 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4628/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2791 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4629/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.2536 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4630/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4631/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4632/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9192 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4633/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4634/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9114 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4635/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4636/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4637/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9069 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4638/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2807 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4639/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4640/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4641/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4642/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9167 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4643/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9135 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4644/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2610 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4645/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9078 - loss: 0.2848 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4646/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4647/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9168 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4648/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9118 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4649/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9111 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4650/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9170 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4651/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4652/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2588 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4653/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9179 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4654/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2685 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4655/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4656/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4657/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4658/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9109 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4659/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4660/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4661/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4662/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2594 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4663/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9109 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4664/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4665/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9078 - loss: 0.2933 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4666/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4667/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4668/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4669/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2641 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4670/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4671/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2659 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4672/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9145 - loss: 0.2678 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4673/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4674/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9135 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4675/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4676/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4677/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9140 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4678/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9155 - loss: 0.2621 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4679/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9113 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4680/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2610 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4681/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4682/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2623 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4683/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9142 - loss: 0.2626 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4684/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9056 - loss: 0.2883 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4685/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4686/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9186 - loss: 0.2651 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4687/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2777 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4688/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9107 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4689/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4690/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4691/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9187 - loss: 0.2593 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4692/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9155 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4693/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9101 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4694/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4695/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2831 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4696/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4697/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2665 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4698/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9083 - loss: 0.2801 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4699/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4700/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4701/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9096 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4702/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.2554 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4703/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2631 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4704/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4705/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 0.2815 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4706/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9197 - loss: 0.2599 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4707/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2802 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4708/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4709/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2652 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4710/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9103 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4711/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2697 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4712/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4713/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2766 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4714/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2813 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4715/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4716/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4717/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4718/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4719/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2559 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4720/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2686 - val_accuracy: 0.8947 - val_loss: 2.2271 - learning_rate: 1.0000e-06\n",
      "Epoch 4721/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2759 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4722/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4723/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2657 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4724/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4725/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4726/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2855 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4727/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4728/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9162 - loss: 0.2655 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4729/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9152 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4730/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4731/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2628 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4732/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2817 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4733/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9117 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4734/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9120 - loss: 0.2812 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4735/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2653 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4736/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9119 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4737/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4738/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4739/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4740/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2792 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4741/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9133 - loss: 0.2722 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4742/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4743/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4744/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2587 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4745/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9188 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4746/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2749 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4747/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2724 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4748/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2804 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4749/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2729 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4750/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2656 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4751/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4752/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2884 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4753/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4754/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4755/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2772 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4756/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4757/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9136 - loss: 0.2708 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4758/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4759/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4760/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4761/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4762/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9126 - loss: 0.2783 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4763/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9171 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4764/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9193 - loss: 0.2586 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4765/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4766/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4767/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2774 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4768/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2739 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4769/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4770/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4771/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2727 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4772/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9161 - loss: 0.2673 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4773/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4774/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4775/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4776/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4777/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9121 - loss: 0.2690 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4778/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4779/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4780/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9101 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4781/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4782/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4783/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2674 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4784/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9104 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4785/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9094 - loss: 0.2790 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4786/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2592 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4787/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2649 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4788/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2805 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4789/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9079 - loss: 0.2862 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4790/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9075 - loss: 0.2826 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4791/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2757 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4792/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9186 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4793/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9123 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4794/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4795/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2846 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4796/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2643 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4797/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4798/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2795 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4799/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9109 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4800/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2272 - learning_rate: 1.0000e-06\n",
      "Epoch 4801/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2784 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4802/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4803/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2672 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4804/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2594 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4805/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4806/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9064 - loss: 0.2821 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4807/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9170 - loss: 0.2606 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4808/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2679 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4809/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.2585 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4810/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2638 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4811/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2588 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4812/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9086 - loss: 0.2854 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4813/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2723 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4814/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9124 - loss: 0.2756 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4815/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9149 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4816/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9131 - loss: 0.2794 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4817/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9151 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4818/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2751 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4819/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4820/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4821/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2682 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4822/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4823/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4824/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2681 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4825/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4826/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2787 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4827/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4828/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2824 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4829/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4830/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2731 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4831/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4832/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2770 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4833/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2658 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4834/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9186 - loss: 0.2604 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4835/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2747 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4836/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9184 - loss: 0.2661 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4837/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2689 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4838/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9125 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4839/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4840/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9100 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4841/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4842/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9169 - loss: 0.2600 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4843/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9168 - loss: 0.2670 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4844/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9123 - loss: 0.2828 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4845/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4846/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4847/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2557 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4848/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4849/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2768 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4850/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2618 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4851/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9103 - loss: 0.2793 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4852/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9174 - loss: 0.2603 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4853/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2617 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4854/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9103 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4855/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2826 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4856/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4857/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9107 - loss: 0.2773 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4858/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2693 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4859/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9141 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4860/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9124 - loss: 0.2701 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4861/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2755 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4862/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2572 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4863/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9146 - loss: 0.2649 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4864/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9168 - loss: 0.2541 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4865/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4866/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9160 - loss: 0.2705 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4867/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2716 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4868/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2603 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4869/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9140 - loss: 0.2738 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4870/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4871/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.2676 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4872/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4873/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9155 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4874/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9084 - loss: 0.2890 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4875/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9111 - loss: 0.2798 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4876/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9133 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4877/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9161 - loss: 0.2677 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4878/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2715 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4879/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9184 - loss: 0.2576 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4880/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2732 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4881/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9165 - loss: 0.2609 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4882/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9147 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4883/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9151 - loss: 0.2737 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4884/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4885/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4886/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9071 - loss: 0.2872 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4887/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9141 - loss: 0.2687 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4888/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2636 - val_accuracy: 0.8947 - val_loss: 2.2273 - learning_rate: 1.0000e-06\n",
      "Epoch 4889/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9110 - loss: 0.2742 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4890/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9068 - loss: 0.2914 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4891/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9133 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4892/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9152 - loss: 0.2706 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4893/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9135 - loss: 0.2667 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4894/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9122 - loss: 0.2707 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4895/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9127 - loss: 0.2785 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4896/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9137 - loss: 0.2712 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4897/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9142 - loss: 0.2642 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4898/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9144 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4899/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9084 - loss: 0.2803 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4900/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9132 - loss: 0.2743 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4901/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9127 - loss: 0.2728 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4902/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9134 - loss: 0.2806 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4903/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9070 - loss: 0.2853 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4904/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9091 - loss: 0.2811 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4905/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9113 - loss: 0.2767 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4906/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9149 - loss: 0.2719 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4907/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2709 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4908/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2698 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4909/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2632 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4910/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9197 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4911/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9182 - loss: 0.2634 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4912/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9113 - loss: 0.2765 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4913/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9110 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4914/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2752 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4915/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.2593 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4916/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.2545 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4917/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2633 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4918/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9165 - loss: 0.2614 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4919/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9126 - loss: 0.2703 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4920/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4921/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9157 - loss: 0.2644 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4922/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4923/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9172 - loss: 0.2666 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4924/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4925/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9138 - loss: 0.2692 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4926/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9132 - loss: 0.2734 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4927/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9092 - loss: 0.2822 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4928/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2718 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4929/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9055 - loss: 0.2865 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4930/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9102 - loss: 0.2816 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4931/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9129 - loss: 0.2733 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4932/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9141 - loss: 0.2654 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4933/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9127 - loss: 0.2776 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4934/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9148 - loss: 0.2598 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4935/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9136 - loss: 0.2648 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4936/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.2762 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4937/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9118 - loss: 0.2769 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4938/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9145 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4939/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9145 - loss: 0.2696 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4940/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9077 - loss: 0.2832 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4941/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9123 - loss: 0.2746 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4942/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9068 - loss: 0.2880 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4943/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9074 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4944/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9120 - loss: 0.2809 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4945/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2646 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4946/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9137 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4947/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2763 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4948/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9171 - loss: 0.2628 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4949/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.2741 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4950/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9156 - loss: 0.2669 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4951/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2605 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4952/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2750 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4953/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9176 - loss: 0.2578 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4954/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2699 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4955/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9140 - loss: 0.2647 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4956/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2721 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4957/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2589 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4958/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9169 - loss: 0.2662 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4959/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2684 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4960/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.2650 - val_accuracy: 0.8947 - val_loss: 2.2274 - learning_rate: 1.0000e-06\n",
      "Epoch 4961/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2814 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4962/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9181 - loss: 0.2619 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4963/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9172 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4964/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9162 - loss: 0.2579 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4965/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.2847 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4966/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9107 - loss: 0.2761 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4967/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9138 - loss: 0.2730 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4968/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9161 - loss: 0.2668 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4969/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9119 - loss: 0.2717 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4970/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9118 - loss: 0.2764 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4971/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9166 - loss: 0.2604 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4972/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9164 - loss: 0.2695 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4973/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9147 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4974/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9153 - loss: 0.2664 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4975/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9112 - loss: 0.2711 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4976/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9125 - loss: 0.2744 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4977/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9134 - loss: 0.2736 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4978/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9131 - loss: 0.2675 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4979/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9097 - loss: 0.2735 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4980/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9152 - loss: 0.2640 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4981/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9080 - loss: 0.2824 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4982/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9121 - loss: 0.2714 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4983/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9162 - loss: 0.2602 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4984/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9089 - loss: 0.2818 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4985/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9139 - loss: 0.2745 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4986/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9098 - loss: 0.2720 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4987/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9105 - loss: 0.2808 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4988/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9146 - loss: 0.2671 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4989/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9203 - loss: 0.2528 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4990/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9128 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4991/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9125 - loss: 0.2694 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4992/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9158 - loss: 0.2630 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4993/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9159 - loss: 0.2660 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4994/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9144 - loss: 0.2700 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4995/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9117 - loss: 0.2780 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4996/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9159 - loss: 0.2635 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4997/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2823 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4998/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9170 - loss: 0.2688 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 4999/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9135 - loss: 0.2748 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "Epoch 5000/5000\n",
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9173 - loss: 0.2691 - val_accuracy: 0.8947 - val_loss: 2.2275 - learning_rate: 1.0000e-06\n",
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 2.1249\n",
      "Test Loss: 2.195863962173462, Test Accuracy: 0.8859999775886536\n"
     ]
    }
   ],
   "source": [
    "# 0.8820000290870667\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, Nadam, RMSprop\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load and preprocess data\n",
    "sample = pd.read_csv(\"data/newSample.csv\")\n",
    "data = sample.drop(columns=['start_date', 'start_time', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "x = data.drop(columns=['IoTMac'])\n",
    "y = data['IoTMac']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(x)\n",
    "\n",
    "# Encode the target variable (y) for multi-class classification\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_normalized, y_encoded, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build the ANN model for multi-class classification\n",
    "model = Sequential()\n",
    "model.add(Dense(100, input_dim=X_train.shape[1], activation='relu'))\n",
    "# model.add(Dense(32, activation='relu'))\n",
    "# model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(len(encoder.classes_), activation='softmax'))  # Output layer for multi-class classification\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
    "\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.9, patience=40, min_lr=1e-6, verbose=1)\n",
    "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=5000, batch_size=300, callbacks=[ reduce_lr])\n",
    "\n",
    "# Train the model\n",
    "# history = model.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=200, batch_size=64, callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 530us/step - accuracy: 0.8762 - loss: 10.2235\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[10.888484954833984, 0.8773333430290222]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392us/step - accuracy: 0.8796 - loss: 5.2361\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[5.566239356994629, 0.8820000290870667]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 391us/step - accuracy: 0.8849 - loss: 14.8840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[15.73741626739502, 0.8859999775886536]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model3.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 453us/step - accuracy: 0.9078 - loss: 16.5388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[17.658363342285156, 0.9120000004768372]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9102 - loss: 48.7380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[53.128746032714844, 0.9133333563804626]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model5.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiran/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 43\u001b[0m\n\u001b[1;32m     36\u001b[0m param_grid \u001b[39m=\u001b[39m {\n\u001b[1;32m     37\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m, \u001b[39m10\u001b[39m, \u001b[39m100\u001b[39m],\n\u001b[1;32m     38\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mgamma\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mscale\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mauto\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m0.01\u001b[39m, \u001b[39m0.1\u001b[39m, \u001b[39m1\u001b[39m],\n\u001b[1;32m     39\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mkernel\u001b[39m\u001b[39m'\u001b[39m: [\u001b[39m'\u001b[39m\u001b[39mlinear\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrbf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mpoly\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msigmoid\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m     40\u001b[0m }\n\u001b[1;32m     42\u001b[0m grid_search \u001b[39m=\u001b[39m GridSearchCV(svm\u001b[39m.\u001b[39mSVC(decision_function_shape\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39movr\u001b[39m\u001b[39m'\u001b[39m), param_grid, cv\u001b[39m=\u001b[39m\u001b[39m5\u001b[39m, scoring\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 43\u001b[0m grid_search\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[1;32m     45\u001b[0m best_params \u001b[39m=\u001b[39m grid_search\u001b[39m.\u001b[39mbest_params_\n\u001b[1;32m     46\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBest Hyperparameters: \u001b[39m\u001b[39m{\u001b[39;00mbest_params\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1019\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, **params)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_results(\n\u001b[1;32m   1014\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m   1015\u001b[0m     )\n\u001b[1;32m   1017\u001b[0m     \u001b[39mreturn\u001b[39;00m results\n\u001b[0;32m-> 1019\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_search(evaluate_candidates)\n\u001b[1;32m   1021\u001b[0m \u001b[39m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[39m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m first_test_score \u001b[39m=\u001b[39m all_out[\u001b[39m0\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mtest_scores\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:1573\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1571\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_run_search\u001b[39m(\u001b[39mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1572\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1573\u001b[0m     evaluate_candidates(ParameterGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_grid))\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_search.py:965\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    958\u001b[0m     \u001b[39mprint\u001b[39m(\n\u001b[1;32m    959\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFitting \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m folds for each of \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m candidates,\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    960\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m totalling \u001b[39m\u001b[39m{2}\u001b[39;00m\u001b[39m fits\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m    961\u001b[0m             n_splits, n_candidates, n_candidates \u001b[39m*\u001b[39m n_splits\n\u001b[1;32m    962\u001b[0m         )\n\u001b[1;32m    963\u001b[0m     )\n\u001b[0;32m--> 965\u001b[0m out \u001b[39m=\u001b[39m parallel(\n\u001b[1;32m    966\u001b[0m     delayed(_fit_and_score)(\n\u001b[1;32m    967\u001b[0m         clone(base_estimator),\n\u001b[1;32m    968\u001b[0m         X,\n\u001b[1;32m    969\u001b[0m         y,\n\u001b[1;32m    970\u001b[0m         train\u001b[39m=\u001b[39;49mtrain,\n\u001b[1;32m    971\u001b[0m         test\u001b[39m=\u001b[39;49mtest,\n\u001b[1;32m    972\u001b[0m         parameters\u001b[39m=\u001b[39;49mparameters,\n\u001b[1;32m    973\u001b[0m         split_progress\u001b[39m=\u001b[39;49m(split_idx, n_splits),\n\u001b[1;32m    974\u001b[0m         candidate_progress\u001b[39m=\u001b[39;49m(cand_idx, n_candidates),\n\u001b[1;32m    975\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_and_score_kwargs,\n\u001b[1;32m    976\u001b[0m     )\n\u001b[1;32m    977\u001b[0m     \u001b[39mfor\u001b[39;49;00m (cand_idx, parameters), (split_idx, (train, test)) \u001b[39min\u001b[39;49;00m product(\n\u001b[1;32m    978\u001b[0m         \u001b[39menumerate\u001b[39;49m(candidate_params),\n\u001b[1;32m    979\u001b[0m         \u001b[39menumerate\u001b[39;49m(cv\u001b[39m.\u001b[39;49msplit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mrouted_params\u001b[39m.\u001b[39;49msplitter\u001b[39m.\u001b[39;49msplit)),\n\u001b[1;32m    980\u001b[0m     )\n\u001b[1;32m    981\u001b[0m )\n\u001b[1;32m    983\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(out) \u001b[39m<\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    984\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    985\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNo fits were performed. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    986\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWas the CV iterator empty? \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    987\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mWere there no candidates?\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    988\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:74\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     69\u001b[0m config \u001b[39m=\u001b[39m get_config()\n\u001b[1;32m     70\u001b[0m iterable_with_config \u001b[39m=\u001b[39m (\n\u001b[1;32m     71\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     72\u001b[0m     \u001b[39mfor\u001b[39;00m delayed_func, args, kwargs \u001b[39min\u001b[39;00m iterable\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(iterable_with_config)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1918\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1916\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_sequential_output(iterable)\n\u001b[1;32m   1917\u001b[0m     \u001b[39mnext\u001b[39m(output)\n\u001b[0;32m-> 1918\u001b[0m     \u001b[39mreturn\u001b[39;00m output \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreturn_generator \u001b[39melse\u001b[39;00m \u001b[39mlist\u001b[39;49m(output)\n\u001b[1;32m   1920\u001b[0m \u001b[39m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[1;32m   1921\u001b[0m \u001b[39m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[1;32m   1922\u001b[0m \u001b[39m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[1;32m   1923\u001b[0m \u001b[39m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[1;32m   1924\u001b[0m \u001b[39m# callback.\u001b[39;00m\n\u001b[1;32m   1925\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/joblib/parallel.py:1847\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1845\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_batches \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1846\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_dispatched_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m-> 1847\u001b[0m res \u001b[39m=\u001b[39m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1848\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_completed_tasks \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m   1849\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_progress()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/utils/parallel.py:136\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     config \u001b[39m=\u001b[39m {}\n\u001b[1;32m    135\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mconfig):\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_validation.py:888\u001b[0m, in \u001b[0;36m_fit_and_score\u001b[0;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, score_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[1;32m    886\u001b[0m         estimator\u001b[39m.\u001b[39mfit(X_train, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m    887\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 888\u001b[0m         estimator\u001b[39m.\u001b[39;49mfit(X_train, y_train, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params)\n\u001b[1;32m    890\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n\u001b[1;32m    891\u001b[0m     \u001b[39m# Note fit time as time until error\u001b[39;00m\n\u001b[1;32m    892\u001b[0m     fit_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start_time\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1466\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[1;32m   1468\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m   1469\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1471\u001b[0m     )\n\u001b[1;32m   1472\u001b[0m ):\n\u001b[0;32m-> 1473\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:250\u001b[0m, in \u001b[0;36mBaseLibSVM.fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m[LibSVM]\u001b[39m\u001b[39m\"\u001b[39m, end\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    249\u001b[0m seed \u001b[39m=\u001b[39m rnd\u001b[39m.\u001b[39mrandint(np\u001b[39m.\u001b[39miinfo(\u001b[39m\"\u001b[39m\u001b[39mi\u001b[39m\u001b[39m\"\u001b[39m)\u001b[39m.\u001b[39mmax)\n\u001b[0;32m--> 250\u001b[0m fit(X, y, sample_weight, solver_type, kernel, random_seed\u001b[39m=\u001b[39;49mseed)\n\u001b[1;32m    251\u001b[0m \u001b[39m# see comment on the other call to np.iinfo in this file\u001b[39;00m\n\u001b[1;32m    253\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape_fit_ \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(X, \u001b[39m\"\u001b[39m\u001b[39mshape\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39melse\u001b[39;00m (n_samples,)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/sklearn/svm/_base.py:328\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_fit\u001b[0;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[1;32m    314\u001b[0m libsvm\u001b[39m.\u001b[39mset_verbosity_wrap(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mverbose)\n\u001b[1;32m    316\u001b[0m \u001b[39m# we don't pass **self.get_params() to allow subclasses to\u001b[39;00m\n\u001b[1;32m    317\u001b[0m \u001b[39m# add other parameters to __init__\u001b[39;00m\n\u001b[1;32m    318\u001b[0m (\n\u001b[1;32m    319\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_,\n\u001b[1;32m    320\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msupport_vectors_,\n\u001b[1;32m    321\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_n_support,\n\u001b[1;32m    322\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdual_coef_,\n\u001b[1;32m    323\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_,\n\u001b[1;32m    324\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probA,\n\u001b[1;32m    325\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_probB,\n\u001b[1;32m    326\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_status_,\n\u001b[1;32m    327\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_iter,\n\u001b[0;32m--> 328\u001b[0m ) \u001b[39m=\u001b[39m libsvm\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m    329\u001b[0m     X,\n\u001b[1;32m    330\u001b[0m     y,\n\u001b[1;32m    331\u001b[0m     svm_type\u001b[39m=\u001b[39;49msolver_type,\n\u001b[1;32m    332\u001b[0m     sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m    333\u001b[0m     class_weight\u001b[39m=\u001b[39;49m\u001b[39mgetattr\u001b[39;49m(\u001b[39mself\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mclass_weight_\u001b[39;49m\u001b[39m\"\u001b[39;49m, np\u001b[39m.\u001b[39;49mempty(\u001b[39m0\u001b[39;49m)),\n\u001b[1;32m    334\u001b[0m     kernel\u001b[39m=\u001b[39;49mkernel,\n\u001b[1;32m    335\u001b[0m     C\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mC,\n\u001b[1;32m    336\u001b[0m     nu\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnu,\n\u001b[1;32m    337\u001b[0m     probability\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprobability,\n\u001b[1;32m    338\u001b[0m     degree\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdegree,\n\u001b[1;32m    339\u001b[0m     shrinking\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinking,\n\u001b[1;32m    340\u001b[0m     tol\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtol,\n\u001b[1;32m    341\u001b[0m     cache_size\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcache_size,\n\u001b[1;32m    342\u001b[0m     coef0\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcoef0,\n\u001b[1;32m    343\u001b[0m     gamma\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_gamma,\n\u001b[1;32m    344\u001b[0m     epsilon\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepsilon,\n\u001b[1;32m    345\u001b[0m     max_iter\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_iter,\n\u001b[1;32m    346\u001b[0m     random_seed\u001b[39m=\u001b[39;49mrandom_seed,\n\u001b[1;32m    347\u001b[0m )\n\u001b[1;32m    349\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warn_from_fit_status()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load and preprocess data\n",
    "sample = pd.read_csv(\"data/newSample.csv\")\n",
    "data = sample.drop(columns=['start_date', 'start_time', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "x = data.drop(columns=['IoTMac'])\n",
    "y = data['IoTMac']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(x)\n",
    "\n",
    "# Encode the target variable (y) for multi-class classification\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1],\n",
    "    'kernel': ['linear', 'rbf', 'poly', 'sigmoid']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm.SVC(decision_function_shape='ovr'), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "clf = svm.SVC(**best_params)\n",
    "# clf = svm.SVC(decision_function_shape='ovr')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "for f in cmatrix:\n",
    "    f += 1\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "sns.heatmap(cmatrix, annot=False, cmap='coolwarm', norm=LogNorm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiran/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 5, 'gamma': 1000, 'kernel': 'rbf'}\n",
      "Accuracy: 0.92350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load and preprocess data\n",
    "sample = pd.read_csv(\"data/newSample.csv\")\n",
    "data = sample.drop(columns=['start_date', 'start_time', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "x = data.drop(columns=['IoTMac'])\n",
    "y = data['IoTMac']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(x)\n",
    "\n",
    "# Encode the target variable (y) for multi-class classification\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [5, 10, 15],\n",
    "    'gamma': [100, 1000, 10000],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm.SVC(decision_function_shape='ovr'), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "clf = svm.SVC(**best_params)\n",
    "# clf = svm.SVC(C=9, gamma=985, kernel='rbf')\n",
    "# clf = svm.SVC(decision_function_shape='ovr')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "for f in cmatrix:\n",
    "    f += 1\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "sns.heatmap(cmatrix, annot=False, cmap='coolwarm', norm=LogNorm())\n",
    "\n",
    "# 0.82700 - poly\n",
    "# 0.85450 - rbf - gamma = 10000\n",
    "# 0.92350, rbf, C = 5, gamma = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model name</th>\n",
       "      <th>10000 sample accuracy</th>\n",
       "      <th>100000 sample accuracy</th>\n",
       "      <th>full dataset accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>random forest</td>\n",
       "      <td>93.800%</td>\n",
       "      <td>94.845%</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gradient boosting</td>\n",
       "      <td>approx 94.7%</td>\n",
       "      <td>approx 95.9%</td>\n",
       "      <td>too slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.421%</td>\n",
       "      <td>too slow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>naive bayes</td>\n",
       "      <td>approx 26%</td>\n",
       "      <td>not enough memory</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          model name  10000 sample accuracy  100000 sample accuracy  \\\n",
       "0      random forest                93.800%                 94.845%   \n",
       "1  gradient boosting           approx 94.7%            approx 95.9%   \n",
       "2                KNN                    NaN                 91.421%   \n",
       "3        naive bayes             approx 26%       not enough memory   \n",
       "\n",
       "   full dataset accuracy  \n",
       "0                    NaN  \n",
       "1               too slow  \n",
       "2               too slow  \n",
       "3                    NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "accuracy_csv = pd.read_csv(\"accuracy.csv\")\n",
    "accuracy_csv.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kiran/Library/Python/3.9/lib/python/site-packages/sklearn/model_selection/_split.py:776: UserWarning: The least populated class in y has only 3 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n",
      "/Users/kiran/Library/Python/3.9/lib/python/site-packages/numpy/ma/core.py:2820: RuntimeWarning: invalid value encountered in cast\n",
      "  _data = np.array(data, dtype=dtype, copy=copy,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 7, 'gamma': 900, 'kernel': 'rbf'}\n",
      "Accuracy: 0.92350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load and preprocess data\n",
    "sample = pd.read_csv(\"data/newSample.csv\")\n",
    "data = sample.drop(columns=['start_date', 'start_time', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "x = data.drop(columns=['IoTMac'])\n",
    "y = data['IoTMac']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(x)\n",
    "\n",
    "# Encode the target variable (y) for multi-class classification\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Hyperparameter tuning using GridSearchCV\n",
    "param_grid = {\n",
    "    'C': [3, 5, 7],\n",
    "    'gamma': [900, 1000, 1100, 1200],\n",
    "    'kernel': ['rbf']\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(svm.SVC(decision_function_shape='ovr'), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params = grid_search.best_params_\n",
    "print(f'Best Hyperparameters: {best_params}')\n",
    "\n",
    "clf = svm.SVC(**best_params)\n",
    "# clf = svm.SVC(C=9, gamma=985, kernel='rbf')\n",
    "# clf = svm.SVC(decision_function_shape='ovr')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "for f in cmatrix:\n",
    "    f += 1\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "sns.heatmap(cmatrix, annot=False, cmap='coolwarm', norm=LogNorm())\n",
    "\n",
    "# 0.82700 - poly\n",
    "# 0.85450 - rbf - gamma = 10000\n",
    "# 0.92350, rbf, C = 5, gamma = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.92350\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "seed = 42\n",
    "\n",
    "# Load and preprocess data\n",
    "sample = pd.read_csv(\"data/newSample.csv\")\n",
    "data = sample.drop(columns=['start_date', 'start_time', 'IoTIP', 'IoTPort', 'hostIP', 'hostPort', 'BytesCount', 'reversePacketCount', 'reverseBytesCount', 'reverseMaxPktSize', 'reverseStdevIAT', 'reverseAvgPacketSize', 'reverseFlowExists', 'broadcast'])\n",
    "\n",
    "# Define input features (X) and target (y)\n",
    "x = data.drop(columns=['IoTMac'])\n",
    "y = data['IoTMac']\n",
    "\n",
    "# Convert categorical variables into dummy/indicator variables\n",
    "X = pd.get_dummies(x)\n",
    "\n",
    "# Encode the target variable (y) for multi-class classification\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y)\n",
    "\n",
    "\n",
    "# Normalize the input data\n",
    "scaler = StandardScaler()\n",
    "X_normalized = scaler.fit_transform(X)\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_normalized, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "clf = svm.SVC(C=5, gamma=1000, kernel='rbf')\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f'Accuracy: {accuracy:.5f}')\n",
    "cmatrix = confusion_matrix(y_test, y_pred)\n",
    "for f in cmatrix:\n",
    "    f += 1\n",
    "\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "from matplotlib.colors import LogNorm\n",
    "sns.heatmap(cmatrix, annot=False, cmap='coolwarm', norm=LogNorm())\n",
    "\n",
    "# 0.82700 - poly\n",
    "# 0.85450 - rbf - gamma = 10000\n",
    "# 0.92350, rbf, C = 5, gamma = 1000"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
